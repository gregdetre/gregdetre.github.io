<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><!-- InstanceBegin template="/Templates/minimalist.dwt" codeOutsideHTMLIsLocked="false" -->
<head>
<!-- InstanceBeginEditable name="doctitle" --> 
<title>Greg Detre</title>
<!-- InstanceEndEditable --> 
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<!-- InstanceBeginEditable name="head" --> <!-- InstanceEndEditable --> 
<style type="text/css">
<!--
-->
</style>
<link href="/media/minimalist.css" rel="stylesheet" type="text/css">
</head>

<body>
<h1><!-- InstanceBeginEditable name="TitleRegion" --><font color="#000000"><font size="6">Vague 
  AI musings and plans</font></font><!-- InstanceEndEditable --></h1>
<!-- InstanceBeginEditable name="EditRegion" -->
<div class=Section1> 
  <p class=MsoNormal align=right style='text-align:right'>Last updated: Friday, 
    07 December, 2001</p>

  <p class=MsoNormal align=left style='margin-top:2.0pt;text-align:left'><span
class=MsoHyperlink><span style='font-variant:normal !important;text-transform:
uppercase'><a href="#_Toc7457519">AI Manifesto<span style='color:purple;
display:none;text-decoration:none'>__ </span><span
style='color:purple;display:none;text-decoration:none'>1</span></a></span></span></p>

<p class=MsoToc2><span class=MsoHyperlink><a href="#_Toc7457520">Assumptions<span
style='color:navy;display:none;text-decoration:none'>_ </span><span style='color:navy;display:none;text-decoration:none'>2</span></a></span></p>

<p class=MsoToc3><span class=MsoHyperlink><a href="#_Toc7457521">Highly
alternative forms of language<span style='color:teal;display:none;text-decoration:
none'>_ </span><span
style='color:teal;display:none;text-decoration:none'>4</span></a></span></p>

<p class=MsoToc3><span class=MsoHyperlink><a href="#_Toc7457522">What must we
share with an intelligent alien?<span style='color:teal;display:none;
text-decoration:none'>_ </span><span
style='color:teal;display:none;text-decoration:none'>4</span></a></span></p>

<p class=MsoToc2><span class=MsoHyperlink><a href="#_Toc7457523">Obsolete<span
style='color:navy;display:none;text-decoration:none'>_ </span><span style='color:navy;display:none;text-decoration:none'>4</span></a></span></p>

<p class=MsoToc3><span class=MsoHyperlink><a href="#_Toc7457524">Structure<span
style='color:teal;display:none;text-decoration:none'>_ </span><span style='color:teal;display:none;text-decoration:none'>4</span></a></span></p>

<p class=MsoToc3><span class=MsoHyperlink><a href="#_Toc7457525">Timing<span
style='color:teal;display:none;text-decoration:none'>_ </span><span style='color:teal;display:none;text-decoration:none'>5</span></a></span></p>

<p class=MsoToc3><span class=MsoHyperlink><a href="#_Toc7457526">NN-builder<span
style='color:teal;display:none;text-decoration:none'>_ </span><span style='color:teal;display:none;text-decoration:none'>5</span></a></span></p>

<p class=MsoToc3><span class=MsoHyperlink><a href="#_Toc7457527">Experiments to
run<span style='color:teal;display:none;text-decoration:none'>_ </span><span style='color:teal;display:none;text-decoration:none'>5</span></a></span></p>

<p class=MsoToc3><span class=MsoHyperlink><a href="#_Toc7457528">To do<span
style='color:teal;display:none;text-decoration:none'>_ </span><span style='color:teal;display:none;text-decoration:none'>5</span></a></span></p>

<p class=MsoToc1><span class=MsoHyperlink><span style='font-variant:normal !important;
text-transform:uppercase'><a href="#_Toc7457529">From random ideas<span
style='color:purple;display:none;text-decoration:none'>_ </span><span style='color:purple;display:none;text-decoration:none'>5</span></a></span></span></p>

<p class=MsoToc2><span class=MsoHyperlink><a href="#_Toc7457530">Cognitive
science<span style='color:navy;display:none;text-decoration:none'>_ </span><span style='color:navy;display:none;text-decoration:none'>5</span></a></span></p>

<p class=MsoToc3><span class=MsoHyperlink><a href="#_Toc7457531">Connectionism<span
style='color:teal;display:none;text-decoration:none'>__ </span><span style='color:teal;display:none;text-decoration:none'>6</span></a></span></p>

<p class=MsoToc3><span class=MsoHyperlink><a href="#_Toc7457532">Brains<span
style='color:teal;display:none;text-decoration:none'>_ </span><span style='color:teal;display:none;text-decoration:none'>10</span></a></span></p>

<p class=MsoToc3><span class=MsoHyperlink><a href="#_Toc7457533">Language<span
style='color:teal;display:none;text-decoration:none'>_ </span><span style='color:teal;display:none;text-decoration:none'>10</span></a></span></p>

<p class=MsoToc3><span class=MsoHyperlink><a href="#_Toc7457534">Evolutionary
theory<span style='color:teal;display:none;text-decoration:none'>_ </span><span style='color:teal;display:none;text-decoration:none'>10</span></a></span></p>

<p class=MsoToc3><span class=MsoHyperlink><a href="#_Toc7457535">Intelligence<span
style='color:teal;display:none;text-decoration:none'>_ </span><span style='color:teal;display:none;text-decoration:none'>11</span></a></span></p>

<p class=MsoToc3><span class=MsoHyperlink><a href="#_Toc7457536">Humour<span
style='color:teal;display:none;text-decoration:none'>_ </span><span style='color:teal;display:none;text-decoration:none'>11</span></a></span></p>

<p class=MsoToc2><span class=MsoHyperlink><a href="#_Toc7457537">Mind/body<span
style='color:navy;display:none;text-decoration:none'>_ </span><span style='color:navy;display:none;text-decoration:none'>11</span></a></span></p>

<p class=MsoToc3><span class=MsoHyperlink><a href="#_Toc7457538">Consciousness<span
style='color:teal;display:none;text-decoration:none'>_ </span><span style='color:teal;display:none;text-decoration:none'>15</span></a></span></p>

<p class=MsoToc2><span class=MsoHyperlink><a href="#_Toc7457539">PhD +
commercial ideas<span style='color:navy;display:none;text-decoration:none'>_ </span><span style='color:navy;display:none;text-decoration:none'>18</span></a></span></p>

<p class=MsoToc3><span class=MsoHyperlink><a href="#_Toc7457540">Enhanced Find
Files program<span style='color:teal;display:none;text-decoration:none'>__ </span><span style='color:teal;display:none;text-decoration:none'>18</span></a></span></p>

<p class=MsoToc3><span class=MsoHyperlink><a href="#_Toc7457541">My NN system &#8211;
topographic designer + runnable implementation<span style='color:teal;
display:none;text-decoration:none'>_ </span><span
style='color:teal;display:none;text-decoration:none'>19</span></a></span></p>

<p class=MsoToc3><span class=MsoHyperlink><a href="#_Toc7457542">Quake bot<span
style='color:teal;display:none;text-decoration:none'> </span><span style='color:teal;display:none;text-decoration:none'>22</span></a></span></p>

<p class=MsoToc3><span class=MsoHyperlink><a href="#_Toc7457543">Go<span
style='color:teal;display:none;text-decoration:none'>_ </span><span style='color:teal;display:none;text-decoration:none'>23</span></a></span></p>

<p class=MsoToc3><span class=MsoHyperlink><a href="#_Toc7457544">Problems to
consider<span style='color:teal;display:none;text-decoration:none'>_ </span><span style='color:teal;display:none;text-decoration:none'>23</span></a></span></p>

<p class=MsoToc3><span class=MsoHyperlink><a href="#_Toc7457545">Thought-organiser<span
style='color:teal;display:none;text-decoration:none'>_ </span><span style='color:teal;display:none;text-decoration:none'>23</span></a></span></p>

<p class=MsoToc3><span class=MsoHyperlink><a href="#_Toc7457546">Misc<span
style='color:teal;display:none;text-decoration:none'>_ </span><span style='color:teal;display:none;text-decoration:none'>24</span></a></span></p>

<p class=MsoToc3><span class=MsoHyperlink><a href="#_Toc7457547">Principles of
nature<span style='color:teal;display:none;text-decoration:none'>_ </span><span style='color:teal;display:none;text-decoration:none'>24</span></a></span></p>

<p class=MsoToc2><span class=MsoHyperlink><a href="#_Toc7457548">Benefits/future
of transhuman AI<span style='color:navy;display:none;text-decoration:none'> </span><span style='color:navy;display:none;text-decoration:none'>25</span></a></span></p>

<p class=MsoToc2><span class=MsoHyperlink><a href="#_Toc7457549">Technology
ideas<span style='color:navy;display:none;text-decoration:none'>_ </span><span style='color:navy;display:none;text-decoration:none'>25</span></a></span></p>

<p class=MsoToc2><span class=MsoHyperlink><a href="#_Toc7457550">New categories<span
style='color:navy;display:none;text-decoration:none'>_ </span><span style='color:navy;display:none;text-decoration:none'>25</span></a></span></p>

<p class=MsoToc3><span class=MsoHyperlink><a href="#_Toc7457551">Evolution<span
style='color:teal;display:none;text-decoration:none'>_ </span><span style='color:teal;display:none;text-decoration:none'>25</span></a></span></p>

<p class=MsoToc3><span class=MsoHyperlink><a href="#_Toc7457552">Intelligence<span
style='color:teal;display:none;text-decoration:none'>_ </span><span style='color:teal;display:none;text-decoration:none'>25</span></a></span></p>

<p class=MsoToc3><span class=MsoHyperlink><a href="#_Toc7457553">NNs<span
style='color:teal;display:none;text-decoration:none'>_ </span><span style='color:teal;display:none;text-decoration:none'>25</span></a></span></p>

<p class=MsoToc3><span class=MsoHyperlink><a href="#_Toc7457554">Language<span
style='color:teal;display:none;text-decoration:none'>_ </span><span style='color:teal;display:none;text-decoration:none'>25</span></a></span></p>

<p class=MsoToc3><span class=MsoHyperlink><a href="#_Toc7457555">Environ/language<span
style='color:teal;display:none;text-decoration:none'>_ </span><span style='color:teal;display:none;text-decoration:none'>42</span></a></span></p>

<p class=MsoToc2><span class=MsoHyperlink><a href="#_Toc7457556">Language arena<span
style='color:navy;display:none;text-decoration:none'>_ </span><span style='color:navy;display:none;text-decoration:none'>46</span></a></span></p>

<p class=MsoToc2><span class=MsoHyperlink><a href="#_Toc7457557">Unsorted<span
style='color:navy;display:none;text-decoration:none'>_ </span><span style='color:navy;display:none;text-decoration:none'>59</span></a></span></p>

  <p class=MsoNormal align=left style='margin-top:2.0pt;text-align:left'>&nbsp;</p>

<h2><a name="_Toc7457520">Assumptions</a></h2>

<p class=MsoNormal>consciousness is not (methodologically) important to AI &#8211; we
can pretend it doesn't exist, and at a certain point will probably just say
that it suddenly does, and we can't predict how/what we&#8217;ll conclude exactly
about it till then</p>

<p class=MsoNormal>there is little information/computation contributed below a
certain level of physiological coarseness (i.e. if we don't model that
fine-grained computation, it will be incorporated somehow at a higher level)</p>

<p class=MsoNormal>much of what we seek to model about the brain can be
produced within today-like/near-future technology</p>

<p class=MsoNormal>spiking is important(???) &#8211; everywhere??? synchronicity???
something else about the APs themselves??? (see Berger Liaw speech recognition???)</p>

<p class=MsoNormal>language is not just another generic cognitive process, but
requires an (evolved) specialisation (to some degree)</p>

<p class=MsoNormal>language reflects the syntax/structure of the environment</p>

<p class=MsoNormal style='margin-left:17.85pt'>the subject-object conceptual
scheme arises inevitably for agents out of their very environment-syntax</p>

<p class=MsoNormal>the purposes of language are two-fold: communication; and
shaping the form and power of one's own thoughts</p>

<p class=MsoNormal style='margin-left:17.85pt'>what&#8217;s the adaptive value of
communication???</p>

<p class=MsoNormal style='margin-left:17.85pt'>why do they gabble???</p>

<p class=MsoNormal style='margin-left:17.85pt'>perhaps sign language/semaphore
(= less complicated motor output)??? perhaps it started as shouting with
different levels of urgency</p>

<p class=MsoNormal>embodiment, to some degree is important - senses and motor
are bound up together, and interacting and being affected by the environment is
vital to learning - feedback</p>

<p class=MsoNormal style='margin-top:0in'>language is the tip of the cognitive iceberg;
human-like language is impossible without human-like experience and limitations</p>

<p class=MsoNormal>sense of self is an emergent phenomenon</p>

<p class=MsoNormal>self-organisation is the key, and highly commercialisable</p>

<p class=MsoNormal>free will = multiple drafts</p>

<p class=MsoNormal>we should take our lead from nature, but not her details -
in marr's words, the computational theory and probably most of the algorithms
should have biological parallels, but not the implementation (hardware or
software) at all</p>

<p class=MsoNormal>wherever possible, we should aim to replicate experimental
data</p>

<p class=MsoNormal>most of nature's solutions are parallel</p>

<p class=MsoNormal>robustness is vital &#8211; vitality is robust</p>

<p class=MsoNormal>low-level neural structures are not evolutionarily
specified, but arise out of a combination of developmental (spatial and timing)
constraints, structure in the environment and learning &#8211; interactionism &#8211; but
interactionism can produce surprisingly specific and stereotyped results</p>

<p class=MsoNormal>defined functional or spatial areas (modules) are the
exception</p>

<p class=MsoNormal>life isn't discrete, it doesn't have discrete processes,
partly because they&#8217;re fault-intolerant, and partly because it makes the parts
of the system less informationally open to each other (and you never know which
stage of computation will be useful to another process)</p>

<p class=MsoNormal>one of the special things about connectionism is that the
processing and the representation are contained within the same mechanism/structure</p>

<p class=MsoNormal>the fundamental life-processes and much of nature utilises
similar basic features</p>

<p class=MsoNormal>there is something special about the brain&#8217;s physical
implementation that gives rise to consciousness???</p>

<p class=MsoNormal>consciousness = computation???_ = epiphenomenal???</p>

<p class=MsoNormal>consciousness definitely does not play a significant role in
low-level processes</p>

<p class=MsoNormal>we have no way of knowing whether consciousness is an
epiphenomenon, i.e. whether it has a causal role, even for the highest-level
processes</p>

<p class=MsoNormal>empathy/sympathy derives from a theory of mind (and a rich
internal model of the world and agents), an aversion to pain and living in a
dangerous environment (i.e. being limited and mortal)</p>

<p class=MsoNormal>compassion??? = sympathy + intelligence</p>

<p class=MsoNormal>we have nothing (little???) to fear from highly-embodied
robots of superior intelligence??? as long as they have similar emotions??? &#8211;
even if we do have something to fear, it&#8217;s for the (utilitarian) best???</p>

<p class=MsoNormal><span style='color:blue'>in most cases, the best and
lowest-level explanation of certain complex brain states and neuronal ensembles
will be in high-level, non-neural, i.e. psychological terms, just as we have
been doing</span></p>

<p class=MsoNormal>agree with Pinker + Jackendorff that to at least some
extent, our grammar + modes of expression follow more basic themes related to
the way in which we function in the world (see thesis notes)</p>

<p class=MsoNormal>major problems in connectionism at the moment:</p>

<p class=MsoNormal style='margin-left:17.85pt'>need to figure out more when we
need to be biologically plausible and when just inspired &#8211; what the lowest
important level of computation is, and for what type of problem, what
information is lost when you just look at APs, and what further information is
lost if you just look at mean rates etc.</p>

<p class=MsoNormal style='margin-left:17.85pt'>consider different types of
neurotransmitters (including fixed-weight inhibition), neuromodulators,
hormones etc.</p>

<p class=MsoNormal style='margin-left:17.85pt'>reward systems as part of
unsupervised learning</p>

<p class=MsoNormal style='margin-left:17.85pt'>architectural, timing, spatial,
neuron-type constraints as interactionist epigenetic variables</p>

<p class=MsoNormal style='margin-left:17.85pt'>incorporating multi-input,
-type, -purpose, -function, -coarseness of representations</p>

<p class=MsoNormal style='margin-left:17.85pt'>sequential, variable-input-size,
continuous, contextualised input with similar type of output</p>

<p class=MsoNormal style='margin-left:17.85pt'>learning rules that don't
require specific, layered homogenous architectures</p>

<p class=MsoNormal>presumably, the faculty by which language communities
emerge/arise (e.g. children forming full-fledged creoles) utilises more or less
the same processes by which we learn a given language</p>

<p class=MsoNormal>for the most part our brains operate in sequential, real
time, clamped conditions</p>

<p class=MsoNormal>life (and maybe the universe) likes to segregate levels</p>

<p class=MsoNormal style='margin-left:17.85pt'>e.g. quantum and classical,
physical/chemical/biological</p>

<p class=MsoNormal style='margin-left:17.85pt'>witness how the way our brains
work on a high level is unrecognisably different the way they work on a low
level (e.g. the fact that our auditory system does fourier transforms standing
on its head, but we find it hard &#8211; wouldn't it be fun to momentarily disconnect
our ears, and then feed ourselves calculations through a mini-electrode?!?)</p>

<p class=MsoNormal style='margin-left:35.7pt'>we are singularly ill-equipped
for understanding ourselves</p>

<p class=MsoNormal>you know how greenbeard genes are brigands (???), because
they highjack the evolutionary process for themselves at the expense of the
rest of the genome??? might it be the same if one part of our brain was able to
control (through man-made electrical stimulation) other parts???</p>

<p class=MsoNormal>is increased understanding and manipulation of our brain
processes going to alleviate or worsen our worries about free will???</p>

<h3><a name="_Toc7457521">Highly alternative forms of language</a></h3>

<p class=MsoNormal>how about 2 words, each highly inflected</p>

<p class=MsoNormal>the verb is the centre of transformational grammar</p>

<p class=MsoNormal>lying (or the ability to form counterfactuals) is the sign
of meaning</p>

<p class=MsoNormal>how about music (chords, pitch/volume) as an analogy</p>

<p class=MsoNormal>our language is discrete, formed of sentence units &#8211; how
about a continuous language, like an always-on verbal report?</p>

<p class=MsoNormal>subject-objects vs participants</p>

<h3><a name="_Toc7457522">What must we share with an intelligent alien?</a></h3>

<p class=MsoNormal>evolution (of some description) &#8211; search through space</p>

<p class=MsoNormal>will life on another planet be distinguishable??? isn't this
the ultimate conclusion of Gaia, that life as a process can't be singled out,
that life exists on exactly the same level as (e.g.) the weather???</p>

<p class=MsoNormal>&nbsp;</p>

<h2><a name="_Toc7457523">Obsolete</a></h2>

<h3><a name="_Toc7457524">Structure</a></h3>

<p class=MsoNormal>aims</p>

<p class=MsoNormal style='margin-top:4.0pt'>principles of nature +
self-organisation</p>

<p class=MsoNormal style='margin-top:4.0pt'>my nn-builder</p>

<p class=MsoNormal style='margin-top:4.0pt'>language</p>

<p class=MsoNormal style='margin-top:4.0pt'>experiments to run</p>

<p class=MsoNormal style='margin-top:4.0pt'>consciousness</p>

<p class=MsoNormal style='margin-top:4.0pt'>AI ethics</p>

<h3><a name="_Toc7457525">Timing</a></h3>

<p class=MsoNormal>2 weeks design + learning C++</p>

<p class=MsoNormal>1 month main data structures and core processes</p>

<p class=MsoNormal>2 months on toolkits, symbolic modules, interfacing,
neuron-group functionality, GUI</p>

<p class=MsoNormal>3 months on simulations + experiments</p>

<h3><a name="_Toc7457526">NN-builder</a></h3>

<h3><a name="_Toc7457527">Experiments to run</a></h3>

<h3><a name="_Toc7457528">To do</a></h3>

<p class=MsoNormal>separate methodological, evolutionary, commercialisable,
what&#8217;s important and what&#8217;s contingent to biology/humans, observations,
hopes/simplifications</p>

<p class=MsoNormal>for infant language acquisition, see Altmann notes, ch 4, 5,
and probably earlier</p>

<p class=MsoNormal>see wordnet 5 papers</p>

<p class=MsoNormal>read up on pidgins + creoles, get hold of corpus</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<h1><a name="_Toc7457529">From random ideas</a></h1>

<h2><a name="_Toc7457530">Cognitive science</a></h2>

<p class=MsoNormal>let&#8217;s say I agree with everything in Brooks (&#8216;AI through
building robots&#8217;) about the need for a complex, real environment that the AI
has to perceive and do the abstracting from itself without a human interpreter,
and that there is a need for a certain degree of modularity but we don&#8217;t yet
know at all how to structure that modularity &#8211; he argues that we need to start
from simpler systems and work our way up to more complex systems &#8211; might there
be an environment in which we could build a <i>simple, language-using</i>
creature, just as he&#8217;s building insects with simple real-world-suited
perceptual capacities&#8230;???</p>

<p class=MsoNormal>what&#8217;s Steve Grand&#8217;s point that Stringer was talking about
related to the coarseness of the model of the VR world model you use???</p>

<p class=MsoNormal style='text-autospace:none'>what will the goal/label of AI
be over the next century - what can i realistically hope to achieve???</p>

<p class=MsoNormal style='margin-left:.25in;text-autospace:none'>consciousness,
probably not, esp not an understanding of it - that's a problem outside science
and the methodologies of NNs and programming etc.</p>

<p class=MsoNormal style='margin-left:.25in;text-autospace:none'>understanding
- hmmm</p>

<p class=MsoNormal style='margin-left:.25in;text-autospace:none'>intelligence -
getting there</p>

<p class=MsoNormal style='margin-left:.25in;text-autospace:none'>autonomy, in
real-life situations =&gt; 2 domains of AI - robots/objects +
words/speech/communication/info-processing - will robots + readers be difficult
to unify???</p>

<h3><a name="_Toc7457531">Connectionism</a></h3>

<p class=MsoNormal>might there be some sort of interaction effect that makes
the combination of evolution and connectionism particularly powerful??? hence
metanet being a new level above what we have</p>

<p class=MsoNormal>it seems like there&#8217;s a trade-off between accuracy of
neuronal model and number of neurons, so I should figure out which one matters
most</p>

<p class=MsoNormal>what about having hemispherical or only sparsely distributed
systems, which is more biologically plausible anyway, the functional
segregation might even be an advantage in some way, and would make it easier
for distributed processing</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>what about if I set up a bunch of little nets, and overlap
them, in different planes, so that they randomly share different neurons &#8211; the
input neuron from one could be the output neuron from another, some of whose
middle-layer neurons are the middle-layer of another net&#8230;</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>given the robustness of neural nets,
coping with lesions, degradations, different activation functions and firing
rates, diluted connectivity etc., and the fact that a single weight can be
considered to be playing a different role in the net depending on which pattern
is active and how much input it is getting, even without the weight itself
actually changing, why can&#8217;t a neuron play different roles at different layers
simultaneously in many neural nets??? I could train all these nets at once,
perhaps cycling through them all one by one or randomly (just like training
patterns offline).</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>what would be the advantage of
this??? well, it&#8217;s one way to add greater complexity and interactivity in our
nets. it might also allow them to self-organise in cool, unexpected ways. and
after all, the brain looks a mess, and this would create a mess, perhaps
they&#8217;ll be similar messes&#8230; plus, it would be economical with neurons.</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>how would I go about meshing all the
nets together??? well, I'd use a genetic algorithm to structure it somehow.
perhaps using tracer lines to map out vague directions and structures, with
parameters like connectivity and distance of connections which would vary in
different places. back to the idea of local parameters, and different
localised-effect neurotransmitters/modulators.</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>how am I going to represent the
networks such that a program can do all this??? perhaps I need to make it all
object-orientated after all&#8230;</p>

<p class=MsoNormal>somehow though, the system has to be able to see things on
different levels, see modules in the chaos (it is difficult to know whether the
brain organises itself in delineable modules&nbsp;or not), and see neural
networks at the systems-level too</p>

<p class=MsoNormal>does the brain organise into modules at a low level???</p>

<p class=MsoNormal>can you see nodes and networks at every level of the
brain???</p>

<p class=MsoNormal>can you put a fractal dimensionality on the brain???</p>

<p class=MsoNormal>to what extent are the parameters of different areas of the
brain hard-wired???</p>

<p class=MsoNormal>if a network is already self-organised, is learning made
easier than it would otherwise be, i.e. can you use less-powerful
biologically-plausible learning rules to learn and modify already-organised
networks that wouldn&#8217;t be powerful enough to organise them from scratch???</p>

<p class=MsoNormal>what&#8217;s the difference between a NN and molecules??? what is
it about the (computational???) properties of our brains that elevate them
above a grey sludgy computer??? Hofstadter would say it&#8217;s something special
about the computation, while Searle would say it&#8217;s physiological &#8211; does one
make more sense than the other???</p>

<p class=MsoNormal>do I believe that the precise, universal columnar
organisation of the cortex could be specified in the very broad way that Elman
et al. believe??? I suppose the reorganisation that the somatosensory cortex
can undergo so quickly would seem to suggest that it is just local
self-organisation responsible, unless the mechanism that lays down the initial
structure (self-organising) needs to specify more information than the
re-organising mechanism???</p>

<p class=MsoNormal>do NNs generate possibilities and then discard them serially
like Deep Blue or is it just a slow constraint satisfaction???</p>

<p class=MsoNormal>how important is the whole fast/slow-adapting thing???
eliminates redundancy &#8211; could be done second-order like in visual system rather
than first-order like rapidly-adapting mechanoreceptors??? kind of like a
differentiating function???</p>

<p class=MsoNormal>can neurons do scaling (like for my competitive nets)???</p>

<p class=MsoNormal>given finite computational time, you have 4 variables to
trade off:</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:.25in;margin-bottom:.0001pt'>level of detail of modelling of the
neuronal mechanism</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:.25in;margin-bottom:.0001pt'>how close together (i.e. finely
sliced) the time steps are</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:.25in;margin-bottom:.0001pt'>how many time steps</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:.25in;margin-bottom:.0001pt'>how many neurons</p>

<p class=MsoNormal style='text-autospace:none'>is there a number of
nodes/neurons that corresponds to the ideal solution to a given problem???</p>

<p class=MsoNormal style='text-autospace:none'>the big problem, may be one of
computability, translating distributed connectionist representations to
*stable*, written or digital public ones</p>

<p class=MsoNormal style='text-autospace:none'>can we imagine sets of nodes
that we can implant into a fully-functioning NN, wo disrupting it - would they
then be removable???</p>

<p class=MsoNormal style='text-autospace:none'>can NNs jump, or are they
gradual??? are they capable of saltatory learning??? (eg paradigm shifts???)</p>

<p class=MsoNormal style='text-autospace:none'>rather than always trying to see
a distributed rep in terms of words/propositions, can we not imagine a more
intuitive level to view it - perhaps a visual representation of it, like Egan's
Mr Volition patch - could we learn to interpret a NN w our own brain-NN???</p>

<p class=MsoNormal style='text-autospace:none'>what sort of NN low-level language
might i imagine???</p>

<p class=MsoNormal style='text-autospace:none'>could we measure the
power/flexibility of a system/NN??? would that power/flexibility increase
exponentially???</p>

<p class=MsoNormal style='text-autospace:none'>what about a battery of standard
NN tests which we could apply, as a sort of NN IQ test???</p>

<p class=MsoNormal style='text-autospace:none'>NN knowledge representations are
inherently UNSTABLE - they change as you give them more data - you need to be
able to archive them, and concatenate NNs so that you could add specialised
modules to your garden variety house Net</p>

<p class=MsoNormal style='text-autospace:none'>representation - rolls defn in
terms of being able to play with it - what about representation as an inferior
but handy version of the real object (eg the representational theory of
perception)</p>

<p class=MsoNormal>CA - kind of like PQs, or a v impoverished NN</p>

<p class=MsoNormal style='text-autospace:none'>what patterns do we play with
now, that might ultimately </p>

<p class=MsoNormal style='text-autospace:none'>see causation/emergence in terms
of the Game of Life???</p>

<p class=MsoNormal>neurotransmitters/modulators in terms of NNs???</p>

<p class=MsoNormal style='margin-top:0in;text-autospace:none'>&nbsp;</p>

<p class=MsoNormal style='margin-top:0in;text-autospace:none'>conception of a
number</p>

<p class=MsoNormal style='margin-top:0in;text-autospace:none'>counting (in
binary)</p>

<p class=MsoNormal style='margin-top:0in;text-autospace:none'>can a network
handle syntaxx/sequence</p>

<p class=MsoNormal style='margin-top:0in;text-autospace:none'>what would a
language be like if sentences were delivered all in one go</p>

<p class=MsoNormal style='margin-top:0in;text-autospace:none'>are there any restricted
domains, eg blocksworld</p>

<p class=MsoNormal style='margin-top:0in;text-autospace:none'>NN communication
protocol</p>

<p class=MsoNormal style='margin-top:0in;text-autospace:none'>how much
bandwidth would a distributed NN require?</p>

<p class=MsoNormal style='margin-top:0in;text-autospace:none'>what about within
our peer-to-peer network?</p>

<p class=MsoNormal style='margin-top:0in;text-autospace:none'>best base for
base conversion</p>

<p class=MsoNormal style='margin-top:0in;text-autospace:none'>&nbsp;</p>

<p class=MsoNormal style='margin-top:0in;text-autospace:none'>for a fully
connected net, have an array of structures of arrays</p>

<p class=MsoNormal style='margin-top:0in;text-autospace:none'>each neuron is
listed in a one-dimensional array, 'neurons[n]</p>

<p class=MsoNormal style='margin-top:0in;text-autospace:none'>each element in
neurons[n] is a structure</p>

<p class=MsoNormal style='margin-top:0in;text-autospace:none'>each structure
contains a two-dimensional array, 'synapses[n-1][2]'</p>

<p class=MsoNormal style='margin-top:0in;text-autospace:none'>because each
neuron is connected to every other neuron once, there are n-1 connections out
from each neuron</p>

<p class=MsoNormal style='margin-top:0in;text-autospace:none'>&nbsp;</p>

<p class=MsoNormal style='margin-top:0in;text-autospace:none'>does it make a
diffce that it's fully connected??? - adds computational expense, but saves you
having to figure out what to connect where in advance. perhaps this vague
directional sprouting could be an evolved feature, ie expressed by/contained in
the genes</p>

<p class=MsoNormal style='margin-top:0in;text-autospace:none'>&nbsp;</p>

<p class=MsoNormal style='margin-top:0in;text-autospace:none'>is there any way
to make sections of a NN stable??? what are the diff types of non-learning
fixed NNs??? how can you confine the knowledge representation to a specific
area/distribution of a NN???</p>

<p class=MsoNormal>if a chimp learned to play the recorder to Grade 2 standard,
would we say it could play the recorder??? obviously, it can&#8217;t play as well as
humans, and maybe it could only play by ear, but it can play (to an extent),
surely??? it must be the case with animal language &#8211; they lack syntax (just as
our recorder-playing chimp couldn&#8217;t read music), which is clearly one of the
most important aspects of language/recorder-playing, but there is still clearly
some major evidence of language/recorder-playing, albeit to a sub-human level</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>recurrent connections - digital + analogue at the same
time???</p>

<p class=MsoNormal>nested vectors</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>include placeholder function for threshold + firing
evaluation (refractory period)</p>

<p class=MsoNormal>temporal summation</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>could you use backpropagation in an autoassociator???</p>

<p class=MsoNormal>what are the most powerful (even non-biologically plausible)
learning algorithms available for an autoassociator???</p>

<p class=MsoNormal>they use a bias rather than threshold because it works with
any function, is easy for notation - but most of all, it allows the threshold
to vary from neuron to neuron and vary as its weight is modified by the
backprop algorithm just like a normal neuron...???</p>

<p class=MsoNormal>is the bias neuron in the input layer??? do the connections
from input layer neurons have weights...???</p>

<p class=MsoNormal>is that 'n'-like symbol pronounced eta???</p>

<p class=MsoNormal>how is momentum related to the learning coefficient???</p>

<p class=MsoNormal>what's the chain rule??? - it's where you can chain
derivatives together</p>

<p class=MsoNormal>should i be able to understand the calculus with a-level
maths???</p>

<p class=MsoNormal>what's the 'operator precedence' of a sigma???</p>

<p class=MsoNormal>how are spiking networks different to rate networks???</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>could you not hardwire selected areas/architectures that
backprop doesn&#8217;t work for &#8211; could you solve simon stringer&#8217;s problem with
GAs???</p>

<p class=MsoNormal>&nbsp;</p>

<h5>Architectures</h5>

<p class=MsoNormal>can you have a Kohonen net that can grow new branches (sort
of like a hybrid adaptive resonance thing)???</p>

<p class=MsoNormal><span style='layout-grid-mode:line'>fractal thicketing &#8211;
Jorn Barger</span></p>

<h5>Alternatives to NNs</h5>

<p class=MsoNormal>CAs???</p>

<p class=MsoNormal>coarser/finer grain of lowest level, i.e. more/less
complicated base units</p>

<p class=MsoNormal>consider the trade-off between number of neurons/connections
(raw power) and temporal and mechanism resolution (real-word simulation) &#8211; how
many timesteps vs accuracy of activation function, neurotransmitters +
chemical/electrical transduction etc.</p>

<p class=MsoNormal>kernel systems?????</p>

<p class=MsoNormal>one only has to try identifying an unfamiliar scene viewed
through a cardboard tube to see that object recognition relies critically on a
sense of scale, perspective, context and large-scale boundaries, and that for a
computer to look at the thing piecemeal serially in any fashion is fruitless.
the same applies to OCR scanners and possibly lexical processing</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Stringer's continuous attractors aren't just a means of
controlling the activity in the NN in an arbitrary manner (as with a joystick),
but also a way of modelling the environment</p>

<p class=MsoNormal>4 pillars of object-orientated programming: encapsulation,
data-hiding, inheritance and polymorphism &#8211; how many if any of these do
connectionist systems have??? could it be that escaping from this paradigm is
essential/informative???</p>

<h3><a name="_Toc7457532">Brains</a></h3>

<p class=MsoNormal>how do our brains 'slow down' enough to methodically
test/generate individual hypotheses??? CANNs??? similar to counting???</p>

<p class=MsoNormal>why is the cortex all furrowed - to maximise surface area -
why didn't it just grow thick and outwards???</p>

<h3><a name="_Toc7457533">Language</a></h3>

<p class=MsoNormal>carmen, have any primates learnt any syntax in ASL? eg using
pronouns by pointing to diff locations in space to represent a given person</p>

<p class=MsoNormal>duality: symbols &amp; syntax, objects &amp; rules, entities
&amp; relationships = meaning</p>

<p class=MsoNormal>what happens if we see the whole world like a language &#8211;
it&#8217;s symbols (individuatable objects discriminable and divisible at numerous
levels, whether visual, neural representations, conscious experience, or
whatever), bound and made sense of in a syntax (our understanding of how the
world works, how those object-symbols interact and integrate)???</p>

<p class=MsoNormal>let&#8217;s say I am looking to build a neural representation of
syntax in the world and in language &#8211; does this emerge naturally out of (the
self-organisation of) neural networks, or does it require extra deliberation???</p>

<h3><a name="_Toc7457534">Evolutionary theory</a></h3>

<p class=MsoNormal><span style='layout-grid-mode:line'>homeostasis is necessary
in life</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>evolution as a means of
exploring the hypothesis space - so would a transformation of the hypothesis
space would require a change in the actual mechanism of evolution itself?</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>the assumption is that
the basic principles governing living systems are independent of the substrate
- is the same true for conscious systems? is consciousness a 'system'?</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>mutations under natural
selection act like a natural Maxwell Demon, keeping mutations that increase the
information about the environment, and discarding those that don't - what's a
Maxwell demon? - hypothetical: has the power to direct individual atoms,
potentially -&gt; perpetual motion, but in fact would himself be doing more
work than creating</span></p>

<p class=MsoNormal>an environment that evolves like a genetic algorithm. but do
the agents within it evolve too, or stay static? what limits can you place on
the evolution of an environment? you could have complex (hand-coded???) agents
who are good at doing something, and just as you introduce parasites (which are
agents to themselves and the environment, but just more environment to our
original hero agents) to make the agents' job harder, you can evolve the
environment to incrementally make the agents' jobs harder, by making the trees
fall down faster or the plants mobile or the hills steeper ...</p>

<p class=MsoNormal>because evolution is not teleological, it gives us a means
of bridging the explanatory gap by (incrementally) exploring the problem space
in dimensions that we aren't perhaps aware of - that is how evolution managed
to come up with mind, and life, and self-organised distributed representation,
and maybe phenomenology - by exploiting the properties of the physical world in
all the ways that those properties are exhibited, i.e. all the ways that
physical laws affect the 'survival' of an organisation of matter that we call
'animals'</p>

<p class=MsoNormal>evolution as kind of like a brute force search algorithm???
but that does something clever extra, or looks in an extra-thorough way in
extra places??? </p>

<p class=MsoNormal>if Hamilton&#8217;s equation is right, wouldn&#8217;t you expect twins
to make decisions that factor in the other twin equally???</p>

<h3><a name="_Toc7457535">Intelligence</a></h3>

<p class=MsoNormal>all we need to enter the next stage of robot evolution is to
work on them being able to metabolise our environment for growth +
self-replication</p>

<p class=MsoNormal>criteria of intelligence - they dream of faster (+
larger???), not qualitatively different thinking</p>

<h3><a name="_Toc7457536">Humour</a></h3>

<p class=MsoNormal>could humour be related to lying???</p>

<p class=MsoNormal>is there a particular brain state/pattern that might
correspond to humour (that would show up on a PET scan or an Egan-patch)</p>

<h2><a name="_Toc7457537">Mind/body</a></h2>

<p class=MsoNormal>what&#8217;s the difference between the mind-body problem and the
problem of consciousness???</p>

<p class=MsoNormal>mind as computer (software/hardware)</p>

<p class=MsoNormal>_____ - internal transduction at every point?</p>

<p class=MsoNormal>_____ - is the chip a single state, as opposed to
collections of modules (as in the brain)?</p>

<p class=MsoNormal>_____ - a computer can't modify itself - at least, not its
hardware</p>

<p class=MsoNormal>_____ - does hardware have an environment?</p>

<p class=MsoNormal>_____ - both have certain innate mechs, e.g. to understand
their own coding (and regulation?)</p>

<p class=MsoNormal>mechanism vs determinism?</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>does Dennett adequately account for the phenomenology of
experience any more than any functionalist account does? in fact, surely the
ease of a computational implementation of the Multiple Drafts theory is
evidence that it is essentially functionalist</p>

<p class=MsoNormal>other than the fact that there is little sense of the mental
having states</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>what's the difference between beliefs, intentions and
desires?</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>how does godel's theorem -&gt; non-determinism?</p>

<p class=MsoNormal>phenomenology - purpose = to induce us to do as our body
tells us, i.e. take the phenomenological signs more seriously</p>

<p class=MsoNormal>_____ act on them more freely</p>

<p class=MsoNormal>_____ phenomenology isn't necessary for rational behaviour</p>

<p class=MsoNormal>the strength of the qualia is necessary to tell the
difference between sense input and memory? (richard gregory)</p>

<p class=MsoNormal>australian zombies are behaviourally and constitutionally
the same as humans</p>

<p class=MsoNormal>normal zombies are behaviourally the same as humans, but not
necessarily human biological organisms constitued of tissue and living brain</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>how might we distinguish high computation from low
computation at an atomic level??? what is computation??? is it like
information??? can you talk about computation without an observer to impose
&#8216;order&#8217; or a viewpoint, or teleology, on the processes??? a string of numbers
that turns out to be the fibonnacci sequence &#8211; is it the fibonnacci sequence
independent of any minds???</p>

<p class=MsoNormal>what does philosophy of mind have to tell us about thought
processes, values + beliefs</p>

<p class=MsoNormal>what does it mean to talk about functionalism as the
relation between functional/mental states - what is a mental 'state'???</p>

<p class=MsoNormal>henry segerman - consciousness *is* complexity of processing
- a brain is conscious in an emergent way by dint of its numerous neurons and
their multiplexity of connections to each other. but wouldn't a river or a rock
then be conscious, since the level of activity on an atomic level is no
different between brains and beans. in fact, we can only speak of the brain as
complex on a cellular level. on an atomic level, it may be no denser or more
energetic or more diverse chemically than a bowl of soup.</p>

<p class=MsoNormal>yes, it may be that consciousness arises panpsychically out
of everything, but we can only interpret something to be (humanly) conscious if
we can make sense of its behaviour. indeed, we will never even be sure that
humanly-behaving zombies are conscious, though to henry, the question wouldn't
have any meaning - since consciousness *is* the process. there is no way to
exhibit human-level complexity of behaviour without being conscious. </p>

<p class=MsoNormal>he needs to address the hard problem of why we have qualia,
where they come from, why they appear to have a contingent relationship to
whatever explanation we come up with, and why physicalist objective
perspectives are unable to account for them</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>what is memory? memory consists of two things - the data
itself, that becomes information when interpreted by a memory reader - thus,
dna is nothing but strings of molecules until the cell performs operations on
them (chemical reactions) which instantiate their content. without a process
which acts on the contents of memory, the reader, the memory data are just the
result of all the atomic physical processes that have led up to the current
state.</p>

<p class=MsoNormal>binary digits are not information until the assembler works
on them</p>

<p class=MsoNormal>the synaptic connections in our brains are complicated,
because a neural network does not have a separate memory in the way that the
traditional von Neumann machine does (as separate from the processing
component, e.g. the CPU/RAM distinction in a modern PC)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>the answer to Henry's incidental question is: depends
whether you can adequately simulate whatever that new physics is in your
computer</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>how does telepathy affect the subjective/objective
distinction?</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>if we focus our efforts on finding a testable
criterion/measure of consciousness, even if it's a little inadequate around the
edges, then we could start up a discipline of mental systems, which works on
quantifying the consciousness of a system and figuring out what goes into
making that consciousness</p>

<p class=MsoNormal>what was susan greenfield's quantification of consciousness?</p>

<p class=MsoNormal>Henry is proposing consciousness is a gestalt process</p>

<p class=MsoNormal>gestalt - grasp problem all together, work out solution
mentally before breaking into bits </p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>i'm anti-reductionist by tom nagel's description, cos i
believe that a radical new understanding of physical laws is necessary to
bridge the explanatory gap - that is not to say that i don't think that
physical science of an expanded and probably paradigmatically different kind
cannot one day come very much closer. but i don't understand how you could call
any variant of functionalism or especially anomalous monism *scientific*. i
still don't even understand how they could work.</p>

<p class=MsoNormal>is there a name for henry's 'consciousness emerges from the
process, *is* the process, is just stuff happening'? functionalism, sort of -
yes, it's looking at the functional organisation in action. surely at the very
least these theories would need to talk more about what it is about the
functional organisation/process that gives rise to consciousness, or at least
address the question of whether all processes, i.e. everything, is conscious,
and if not, then what is?</p>

<p class=MsoNormal>indeed it is this predictive power that identifies a
scientific theory, its objective, verifiable/testable hypotheses, quantifiable,
reproducible measurements are necessary for that</p>

<p class=MsoNormal>without this sort of dividing line separating functional
processes that give rise to consciousness and those that don't, you actually do
end up a panpsychist, don't you?</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>in the functional reorganisation model in speech perception,
why would our sensitivity to phonemes outside our language increase, when there
would have been no adaptive value in being better able to learn a second
language (as an adult) in a tribal world</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>atoms as a low-level ephemeral neural network</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Henry S - amnesia would be something to fear. Yes, but not
because youd feel pain. Amnesia to the extent of being able to swap minds is neural
connections in a blender. thats death. </p>

<p class=MsoNormal>HenryS: no fears of pain are going to reach through that
sort of amnesia</p>

<p class=MsoNormal>HenryS: this stuff reminds me of the safety deposit box.
(greg egan)</p>

<p class=MsoNormal>HenryS: &quot;the principle that one's fears can extend to
future pain whatever psychological changes precede it seems positively
straightforward&quot; (p63). I disagree. I dont care what happens to my body
once I'm dead, which is what i am with erased brain.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>HenryS: i mean yes theres a nonzero probability that the
table could quantum tunnel out of the room, but its not going to happen</p>

<p class=MsoNormal>HenryS: real life (tm)</p>

<p class=MsoNormal>Grog: well, if our radically revised conception of matter
allowed us to glimpse an understanding of the hard problem of consciousness,
then that could change our Real Life in lots of ways</p>

<p class=MsoNormal>HenryS: mmm...possibly</p>

<p class=MsoNormal>Grog: that's what he's edging towards</p>

<p class=MsoNormal>HenryS: my opinion - theres not enough weirdness in conc to
warrant huge piles of new physics</p>

<p class=MsoNormal>HenryS: i could be wrong of course</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>g: experiential/phenomenological content, what it's like to
be me, qualia - how all of that is privileged, subjective, non-localised,
non-extended, anomalous, qualitatively inexplicable and unimaginable as being
the same as matter in its common sense form as it appears to us</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>what about if you could implant neuron-transistors in your
brain, expand your connectivity, and add new lobes??? imagine a guy who does
this, but starts to experience strange effects, a la travolta in phenomenon.
eventually, he is forced to reload his backup at time of mind-expansion, but
this means losing everything he has become in the intervening months. the short
story is written in the form of a letter he writes to himself, detailing what
happened, how he feels, what he learned, and the memories he is resigning
himself to now lose.</p>

<p class=MsoNormal>is the brain a formal system?</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>it would make sense to say that processing -&gt; conscious
experience, since higher levels of the brain are most conscious, and the brain
is the most conscious of all known processing mechanisms. but what is it about
processing, and how can we define processing in this way, so that we can even
imagine how it might lead to conscious experience</p>

<p class=MsoNormal>what if it turned out that we couldn&#8217;t get rid of pain just
by shutting off brain centres that C-fibres travel to, or even cutting off the
C-fibres &#8211; what if there was an all-over body selfness marker that delineates
our physical presence giving rise to pain when intruded&#8230; - like the MHC???</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Or if we've used futuristic evolutionary techniques to
physically build our computer-personality, we might not even know exactly what
it is about the robot brain that is important that we need to save... I'm not
so sure if that makes sense. I'm imagining some scenario where we use a
combination of genetic algorithms and real chemicals to 'evolve' an entire organism
in super-accelerated time.</p>

<h3><a name="_Toc7457538">Consciousness</a></h3>

<p class=MsoNormal>if my arm suddenly raises up, where does that come in
heterophenomenological evidence &#8211; does it depend on high up in the nervous
system the twitch is initiated???</p>

<p class=MsoNormal>what is computation??? is it quantifiable??? is there
anything in the natural world that cannot be described in terms of its
computation??? is computation a purely functionalist criterion??? how is it
related to computability??? what is computability???</p>

<p class=MsoNormal>Dennett&#8217;s multiple drafts model is too high-level &#8211; talk of
specialised functional units breaks down when we are simply talking about
neurons as a clump performing processing &#8211; I suppose that clump is a &#8216;draft&#8217;
though&#8230;???</p>

<p class=MsoNormal>Rolls points out that the only actions that we cannot even
imagine performing unconsciously are those involving self-awareness, or
reference to oneself, and so he thinks that there must be something about such
self-referential higher-order thoughts that gives rise to consciousness.</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:.5in;margin-bottom:.0001pt'>self-referential isn&#8217;t the same as
higher-order though, is it???</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:.5in;margin-bottom:.0001pt'>how can you pin down what you mean by
self-reference???</p>

<p class=MsoNormal>how might we make sense of the mental not being causally
inert???</p>

<p class=MsoNormal>what&#8217;s the frame problem???</p>

<p class=MsoNormal>does &#8216;qualia&#8217; mean just sensations, or does it include all
thoughts and consciousness???</p>

<p class=MsoNormal>if the qualia are an emergent process, aren&#8217;t they causally
inert??? does it make sense in materialism/identity theory to tlak of
epiphenomenalism &#8211; no, surely???</p>

<p class=MsoNormal>following on from the question about blindsight, and why
some computational processes give rise to consciousness while others don&#8217;t,
might we be able (in the future) to play around with this???</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:.5in;margin-bottom:.0001pt'>for instance, we could try physically
distancing 2 aspects of the same computation to see whether that affects how
they are bound in consciousness, or add in redundancy, or something</p>

<p class=MsoNormal>when identity theorists try and say that identity between
qualia and brain states is a necessary <i>a posteriori</i> truth, rather like
lightning and electrical discharge, and water and H<sub>2</sub>O, aren&#8217;t they
missing the point that what makes lightning somehow more than just electrical
discharge, and water somehow more, phenomenally, than just H<sub>2</sub>O, is
the act of the perceiver, the qualia-mentality that we impose as truly
phenomenologically conscious beings &#8211; that is, though we could say that there
is a (systematic???) relationship (and I am here avoiding calling this an
identity) between &#8216;lightning&#8217; as we see it and electrical discharge (for
instance) in the same way that there is an identity between qualia and brain
states, this would tell us nothing about what that relationship is &#8211; there
still remains an explanatory gap between both pairs &#8211; I am contesting the
necessity of such a mind-brain identity, since there is nothing in what we have
experienced that necessitates mind should arise from brain in the way it does</p>

<p class=MsoNormal style='margin-left:.25in'>what does Nagel have to say in
response to this???</p>

<p class=MsoNormal style='text-autospace:none'>can we historicise theories of
consciousness, to see where they're all pointing??? consciousness,
intelligence, Turing test, functionalism etc.???</p>

<p class=MsoNormal style='text-autospace:none'>write essay on consciousness
from the point of view of the Chinese room??? what is Searle trying to combat
there???</p>

<p class=MsoNormal style='text-autospace:none'>see consc as a bubble in the
world - but viewed f 3D, show it to be a twist in teh topograph - weird
inside-out topographical bottle, like mobius strip in space</p>

<p class=MsoNormal>fMRI scans on change blindness</p>

<p class=MsoNormal>do i believe in functionalism???</p>

<p class=MsoNormal>_____ well, not entirely - i think it's *probably*/likely to
be right, and i can't see how pure materialism could be right, but then i can't
entirely see how functionalism is right either???</p>

<h5>Phenomenological properties of consciousness</h5>

<p class=MsoNormal style='margin-left:.25in'>intelligence, difficulty of
concept (intricacy, size, novelty)</p>

<p class=MsoNormal style='margin-left:.25in'>reason as the supreme (+ most
desirable) mode of comprehension</p>

<p class=MsoNormal style='margin-left:.25in'>mind-space</p>

<p class=MsoNormal style='margin-left:.25in'>mind-time</p>

<p class=MsoNormal style='margin-left:.25in'>analog I/metaphorical me &#8211; the I
that knows the me</p>

<p class=MsoNormal style='margin-left:.25in'>language</p>

<p class=MsoNormal style='margin-left:.25in'>anomalous, impinged on by experience
from &#8216;outside&#8217;</p>

<p class=MsoNormal style='margin-left:.25in'>irrepressible thoughts, paradox of
thinking about thinking &#8211; wherein the thoughts well from within I know not</p>

<p class=MsoNormal style='margin-left:.25in'>'necessary'-seeming rationality vs
truth</p>

<p class=MsoNormal style='margin-left:.25in'>computation</p>

<p class=MsoNormal style='margin-left:.25in'>deterministic world</p>

<p class=MsoNormal style='margin-left:.25in'>irreducible qualia (intensity,
quality, type)</p>

<p class=MsoNormal style='margin-left:.25in'>continuum of modalities</p>

<p class=MsoNormal style='margin-left:.25in'>distributed representation</p>

<p class=MsoNormal style='margin-left:.25in'>systematic 2-way relation to
bodily states</p>

<p class=MsoNormal style='margin-left:.25in'>fainter memories (passing through
the sieve of my mind, catching for a while, some stick, most drift through into
the void)</p>

<p class=MsoNormal style='margin-left:.25in'>comparison, combination and
abstraction &#8211; pattern-matching, generalising everything we see &#8211; cannot see the
original stream of experience, only the structured stream</p>

<p class=MsoNormal style='margin-left:.25in'>unity of apperception/bundle
theory</p>

<p class=MsoNormal style='margin-left:.25in'>agency + volition, decisions, the
ontological(???) possibility of counterfactuals = FW</p>

<p class=MsoNormal style='margin-left:.25in'>desires + goals</p>

<p class=MsoNormal style='margin-left:.25in'>emotions vs motivations + humour,
beauty, aesthetics/sublime etc.</p>

<p class=MsoNormal style='margin-left:.25in'>value</p>

<p class=MsoNormal style='margin-left:.25in'>subjectivity, privileged -
incorporate the knower into the known, the subjectivity of the distributed
representation</p>

<p class=MsoNormal style='margin-left:.25in'>incommunicable directly, language
as compression, filtration + formulation medium</p>

<p class=MsoNormal style='margin-left:.25in'>mind as swirling maelstrom,
private language argument, cannot safely compartmentalise a sensation any more
than you can segment off a piece of water from the sea without a complete
physical enclosure (which our minds cannot erect)</p>

<p class=MsoNormal style='margin-left:.25in'>bi/multi-camerality, mind
watching/instructing mind, multiple drafts</p>

<p class=MsoNormal style='margin-left:.25in'>freudian unconscious</p>

<p class=MsoNormal style='margin-left:.25in'>aspects/segments/functions of the
mind &#8211; e.g. reason/spirit/appetites</p>

<p class=MsoNormal style='margin-left:.25in'>mind appears to emerge out of
matter, yet is qualitatively different (rather than simply being viewed on a
different level)</p>

<p class=MsoNormal style='margin-left:.25in'>mind appears to be gradual, a
continuum of mentality</p>

<p class=MsoNormal style='margin-left:.25in'>personal identity seems to be more
than just the neurons, but that may be an illusion</p>

<p class=MsoNormal style='margin-left:.25in'>how is personal identity
preserved, if our neurons are changing and dying moment by moment vs replacing
them one by one with transistors</p>

<p class=MsoNormal style='margin-left:.25in'>only know that there is mind
outside us by interpreting outward behaviour as mindful - problem of other
minds</p>

<p class=MsoNormal style='margin-left:.25in'>quantum mechanics &#8211; any relevance
to personal identity</p>

<p class=MsoNormal style='margin-left:.25in'>12 categories &#8230; xxx</p>

<p class=MsoNormal style='margin-left:.25in'>we can never agree on things</p>

<p class=MsoNormal style='margin-left:.25in'>will to power &#8211; coursing through
our every conscious moment</p>

<p class=MsoNormal style='margin-left:.25in'>effort &#8211; to think, remember, talk</p>

<p class=MsoNormal style='margin-left:.25in'>cannot quiet the mind &#8211; even as
you pull out the plug, there&#8217;s just as much water pouring back in</p>

<p class=MsoNormal style='margin-left:.25in'>self-restraint</p>

<p class=MsoNormal style='margin-left:.25in'>empathy, sympathy/compassion,
morality</p>

<p class=MsoNormal style='margin-left:.25in'>pain</p>

<p class=MsoNormal style='margin-left:.25in'>time passing &#8211; slows + speeds up &#8211;
dure</p>

<p class=MsoNormal style='margin-left:.25in'>imagistic</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal><span style='font-size:9.0pt'>There are three basic themes.
The first is that the human mind is bifold - as much a product of memes or
cultural evolution as of the biology of brains. The second is that brain
processing takes time - about half a second to develop a settled
&quot;frame&quot; of consciousness. The third is that the brain is dynamic -
the standard computational model of brain processing fails for reasons that are
only just starting to become widely appreciated. </span></p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>can I set up a complete set of opposing propositions about
the mind??? probably not, and there&#8217;s no reason to think that mind will be a
dualistic problem, so much as a multitude of views about it</p>

<p class=MsoNormal>what could a complete theory of mind and explanation
(bridge) of the mind-body problem look/be like??? if it&#8217;s not conceivable, does
that mean that an explanation is not conceivable??? is that tautologous???</p>

<h5>What is the most plausible, coherent view of consciousness that we can now
form???</h5>

<p class=MsoNormal>epiphenomenalist, functionalist, panpsychist type???
identity theory</p>

<p class=MsoNormal>free will, intentionality and consciousness are part of the
whole set of loaded, anachronistic pre-connectionist terms that we will
eventually discard</p>

<p class=MsoNormal>are there any better metaphors for mind, cognition and NNs
than are currently available???</p>

<p class=MsoNormal>what happens if I decide that consciousness is not
epiphenomenal???</p>

<h2><a name="_Toc7457539">PhD + commercial ideas</a></h2>

<h3><a name="_Toc7457540">Enhanced Find Files program</a></h3>

<p class=MsoNormal>search inside text, htm, doc, pdf</p>

<p class=MsoNormal style='margin-top:2.0pt'>build on Win 9x Find Files</p>

<p class=MsoNormal style='margin-top:2.0pt'>added criteria</p>

<p class=MsoNormal style='margin-top:2.0pt'>results like a search engine or
like Find Files</p>

<p class=MsoNormal style='margin-top:2.0pt'>highlights roughly where in the
file</p>

<p class=MsoNormal style='margin-top:2.0pt'>offers preview window</p>

<p class=MsoNormal style='margin-top:2.0pt'>&nbsp;</p>

<p class=MsoNormal style='margin-top:0in'>multiple passes (stored index +
recent re-check, re-ranking as it goes, searches around specified locus areas,
in important directories)</p>

<p class=MsoNormal style='margin-top:2.0pt'>previewing + quick view</p>

<p class=MsoNormal style='margin-top:2.0pt'>pause, save, refine the search</p>

<p class=MsoNormal style='margin-top:2.0pt'>set up search areas, topics</p>

<p class=MsoNormal style='margin-top:2.0pt'>prioritise and link criteria,
operators + precedence</p>

<p class=MsoNormal style='margin-top:2.0pt'>a sort of mind-mappy interface,
present and navigate throught results like Visual thesaurus???, as well as
&#8216;streams&#8217;</p>

<p class=MsoNormal style='margin-top:2.0pt'>index all the words in each file -
when indexing, compare each word with commonality in Brown&#8217;s corpus &#8211; problems
with proper names that are common words, e.g. Brown, Smith</p>

<p class=MsoNormal style='margin-top:2.0pt'>compress the index???</p>

<p class=MsoNormal style='margin-top:2.0pt'>faster if write in assembler???</p>

<p class=MsoNormal style='margin-top:2.0pt'>connectionist index</p>

<p class=MsoNormal style='margin-top:2.0pt'>continue checking at low priority
in the background, e.g. in non-specified places</p>

<p class=MsoNormal style='margin-top:2.0pt'>various cycles: occurring words,
words in relation specified in find criteria, priority of search
areas/dates/types, commonality of words, natural language understanding,
concept connectionism, search elsewhere in history of past searches/collated
index, filenames, continuous monitoring of new files, links like Google</p>

<p class=MsoNormal style='margin-top:2.0pt'>how might a NN help???</p>

<p class=MsoNormal style='margin-top:2.0pt'>continuously monitors open
documents, prioritises recent documents &#8211; notices which documents you&#8217;ve got
open together</p>

<p class=MsoNormal style='margin-top:4.0pt'>searches on the basis of the
fastest criteria, e.g. file names, then file contents etc.</p>

<h3><a name="_Toc7457541">My NN system &#8211; topographic designer + runnable
implementation</a></h3>

<h5>Topographising</h5>

<p class=MsoNormal>Every neuron is its own object, with properties like
activation function, threshold, resistance to lesioning??? etc.</p>

<p class=MsoNormal>A group is also an object. It consists of a list of neurons
which belong to it (a neuron can belong to more than one group). Belonging to a
group doesn't necessarily mean that you're connected to any of the other
neurons in that group.</p>

<p class=MsoNormal>I can define a group. There's no distinction made between
input neurons and hidden neurons and output neurons at this stage. However, the
input neurons are considered to be simply any neurons that have inputs from
outside the group (so an input neuron in one group may be a hidden/output neuron
in another, and vice versa), and hidden and output neurons are similarly
defined relative to that group. (arguably of course, one can talk in terms of
network-wide input, hidden and output neurons too - remember in fact that the
network is itself also a (super-)group). In this way, one neuron could be both
an input and an output neuron (though not, of course, also a hidden neuron). I
might recruit a bunch of neurons into a group, some of which have inputs from
outside the group and some have outputs to outside the group. But these input
and output neurons within the group might not actually be connected to each
other at all - in this way, group boundaries need not necessarily follow
functional boundaries, though they probably will in most cases.</p>

<p class=MsoNormal style='margin-left:.25in'>I need to be able to define the
inter-group connections in terms of the inputs to a group or in terms of the
outputs from another group - this requires a non-group-centred (i.e.
Network/neuron-centred) representation of the total synaptic organisation. I
imagine this means that if i'm looking at a given group as a programmer/user,
it has to continually refresh by checking through all the neurons in the
network to see which neurons are connected in - this means that it will always
be up to date, though it will be slow - however, when the network is actually
running, this won't be relevant, because the network runs by cycling through
the neurons and completely ignores group boundaries</p>

<p class=MsoNormal>At the end of all this, it has to check to see whether
neurons which are members of more than group have been given competing
instructions.</p>

<p class=MsoNormal style='margin-left:.25in'>What sort of default instructions
might there be???</p>

<p class=MsoNormal style='margin-left:.5in'>e.g. It might broadly specify a
connectivity pattern tween neurons - but then some neurons will be connected to
those and more. If so, could some pairs of neurons be connected together more
than once??? Does this happen in the brain???</p>

<p class=MsoNormal>The other reason for doing this is so that I can integrate
symbolic modules. Every group object can have one or more symbolic modules
attached. You specify which neurons these link into/out of, and how they affect
or are affected by these neurons&#8217; activities. For instance, in the case of the
group which consists of input neurons and output neurons that are not actually
connected to each other at all (it&#8217;s not necessary that they remain
unconnected, but it&#8217;s simpler to assume they are for the sake of the example),
I might have a symbolic module that does a parity check on the input neurons,
and alters the output neurons correspondingly. In this way, the symbolic module
can act as a bridge between neurons.</p>

<p class=MsoNormal style='margin-left:.25in'>Ideally, one day we&#8217;ll know how
this might be implemented through a combination of genetic, developmental and
learning processes, but in the meantime, we&#8217;re most interested in is the
functional goings on. Of course, those striving for biological plausibility
needn&#8217;t implement symbolic modules (except maybe just for convenience/speed, if
they&#8217;re absolutely certain that they could employ a functionally-identical set
of neurons in its place).</p>

<p class=MsoNormal>Of course, the symbolic module could link in and back out to
the same neurons, e.g. For scaling a vector.</p>

<p class=MsoNormal style='margin-left:.25in'>Incidentally, this will be how
sensory inputs and motor outputs will be represented &#8211; the network input
neurons will have a symbolic module which could be a quakec interface, a number
generator, a database of images, text, a video camera or whatever. Likewise,
the symbolic module linked to the network output neurons could translate into
keystrokes for quake, motor commands to muscles, irc-style text or whatever.</p>

<p class=MsoNormal>You could also use this symbolic module system for compiling
reports. You create a special group containing all the neurons you&#8217;re
interested in. You write a special symbolic module that outputs the information
about those neurons to a file in a prespecified format, and then at the end of
the day, it&#8217;ll automatically create a log of all and only the information you
need, without affecting those neurons&#8217; activity</p>

<h6><span style='font-family:"Courier New"'>o<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>Data structures</h6>

<p class=MsoNormal>neuron-level description &#8211; complete splurge of all the
neuron objects</p>

<p class=MsoNormal style='margin-left:.5in'>neuron unique ID, each neuron&#8217;s current
activity, it&#8217;s activation function, which neurons it has connections to and
their synaptic strengths &#8211; what about which neurons it has input from???</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:.5in;margin-bottom:.0001pt'>each neuron&#8217;s 3D coordinate,
length/distance of each connection</p>

<p class=MsoNormal>groups description &#8211; complete splurge of all the group
objects (including the network-wide super-group)</p>

<p class=MsoNormal style='margin-left:.5in'>group ID + optional name, list of
each group&#8217;s member neurons (by ID, or pointer???), attached symbolic functions
and which neurons they&#8217;re linked into/out of &#8211; how about segregating groups as all-symbolic
+ _non-symbolic???</p>

<p class=MsoNormal>symbolic modules description &#8211; complete splurge of all the
symbolic module objects</p>

<p class=MsoNormal style='margin-left:.5in'>symbolic module ID + optional name,
which bit of code to implement as the function, requirements for min/max/ratio
inputs/outputs, current parameters</p>

<p class=MsoNormal style='margin-left:.5in'>the symbolic modules are going to
have to take up an arbitrary amount of space too <span style='font-family:Wingdings'>L</span></p>

<p class=MsoNormal>genome &#8211; should just be a long numeric string (in
binary/quaternary/decanal base???),_ </p>

<p class=MsoNormal style='margin-left:.5in'>formulae for group-level synaptic
connectivity, ID pointers to library functions to implement the symbolic
modules, timing, extra section at the end with exactly prespecified connections
(this is the biologically implausible bit that I hope to phase out)</p>

<p class=MsoNormal style='margin-left:.5in'>the genome for the agent from which
all this has developed (non-Lamarckian, so presumably you don&#8217;t/can&#8217;t
translate/de-develop from the adult NN back to the genome)</p>

<p class=MsoNormal style='margin-left:.5in'>this will probably include
time-switches for when new areas should be added on, and how they&#8217;ll grow, how
many neurons over what time period, innervating roughly/exactly which groups
etc., which groups the new neurons will belong to etc.</p>

<h6><span style='font-family:"Courier New"'>o<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>File formats</h6>

<p class=MsoNormal>The neuron-level information should definitely be stored in
a CSV or plain text format so that the user can pause the network (or before it
starts), then hand-edit the state of the network in whatever way they like</p>

<p class=MsoNormal>In fact, maybe there should be a special extra file, called
user modifications, which gets looked at at a certain prespecified point in the
network&#8217;s running</p>

<p class=MsoNormal>If it&#8217;s all going to be encapsulated in the GA data
structure from day one, then assuming that the development/growth functionality
get implemented later, the topographising program will have to output all its
group-level synaptic equations (e.g. &#8216;connect every alternate neuron in group 1
to group 2&#8217;, or whatever) will have to be unpacked into the GA</p>

<p class=MsoNormal style='margin-left:.25in'>In fact, converting it all into GA
format before being implemented as a NN could be the cut-off point between
topography and session</p>

<h6><span style='font-family:"Courier New"'>o<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>Error checking</h6>

<p class=MsoNormal>that there is an input and output symbolic description, more
than one neuron, that queue position doesn&#8217;t exceed max neurons, no neuron is
connected to a non-existent neuron etc.</p>

<h5>Running the net</h5>

<h6><span style='font-family:"Courier New"'>o<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>Timing</h6>

<p class=MsoNormal>you could start off with enormous connectivity (anywhere
between 5-50% depending on whether it&#8217;s inter- or intra-group) (which still
restricts your synaptic space, but not very much) and prune every so often
(just wiping out all connections of less than a certain absolute weight, or
just the weakest x% of connections)</p>

<h6><span style='font-family:"Courier New"'>o<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>Data structures</h6>

<p class=MsoNormal>session description</p>

<p class=MsoNormal style='margin-left:.25in'>log of when created/modified,
current timestep, max timesteps (or condition for termination), queue state
(current position) and order (random, sequential etc.) of spike refresh,
specification of when to alter parameters of symbolic modules (e.g. to tell the
main input symbolic module to provide different/more difficult training set
etc.)</p>

<p class=MsoNormal>lesion log &#8211; what lesions have been performed where in the
network, and with what results</p>

<p class=MsoNormal>population description</p>

<p class=MsoNormal style='margin-left:.5in'>how many agents in the population,
list of which agents belong to this population</p>

<p class=MsoNormal>environment description</p>

<p class=MsoNormal style='margin-left:.5in'>list of populations,
schedule/record of changes in the environment that the agents will have to
respond to</p>

<h5>Experiments to run on this system</h5>

<p class=MsoNormal>wire it into Quake as a bot</p>

<p class=MsoNormal>video camera and a little trolley on wheels</p>

<h5>Misc</h5>

<p class=MsoNormal>how important is the whole fast/slow-adapting thing???
eliminates redundancy &#8211; could be done second-order like in visual system rather
than first-order like rapidly-adapting mechanoreceptors??? kind of like a
differentiating function???</p>

<p class=MsoNormal>can neurons do scaling (like for my competitive nets)???</p>

<p class=MsoNormal>allows you to slot in library to add what sort of extra
functionality???</p>

<p class=MsoNormal>express the stereotyped connections in terms of formulae
(parse in Polish notation???)</p>

<h5>Questions</h5>

<p class=MsoNormal>Is there any way to make the formal description of the whole
system abstract enough to be explored/monitored by either a meta-GA or a
meta-NN???</p>

<p class=MsoNormal>Is there a problem with having each synapse having its own
distance, because it&#8217;ll mean that a really long axon which branches at the very
end to reach loads of nearby neurons will have a very high total synapse
connection distance???</p>

<p class=MsoNormal style='margin-left:.25in'>The solution might be to have one
strong connection to a neuron at that end, and for it to be connected to all
the nearby neurons &#8211; but will this be difficult to express in my neuron topography
formulae/formulisms??? And how do I ensure that the connection stays strong???</p>

<p class=MsoNormal>Can I specify that a connection should stay strong??? Well,
I can just make sure that the only input that neuron has is that connection,
and then it&#8217;ll be bound to stay practically 100%, won&#8217;t it???</p>

<p class=MsoNormal>Find out how Cog mixes all the systems up</p>

<p class=MsoNormal>To what extent should I build in the GA and spatial
organisation stuff into the network from the beginning???</p>

<p class=MsoNormal style='margin-left:.25in'>I think that neurons should have
the spatial properties built in from the start, and everything should be
defined in terms of being just one agent object within a population, but
there&#8217;s no need to fully flesh it out</p>

<p class=MsoNormal style='margin-left:.25in'>The big problem is the GA, and the
extent to which the user can hand-code things, and the extent to which it can
all be specified in the GA &#8211; the GA data structure is going to be crucial</p>

<h3><a name="_Toc7457542">Quake bot</a></h3>

<p class=MsoNormal>Quake bots &#8211; hope will lead to forward planning, hiding and
interception, different techniques for different predators and weapons,
prioritisation (study behaviour by experimenting with counterfactuals),
different cognitive sub-modules, introduce very simple inter-bot communication
and hope to see arbitrary code (cf vervet grunts) evolve, cultural and social
learning, selfish genes (kin recognition???), deception</p>

<p class=MsoNormal>what would be a good forum for these experiments?</p>

<p class=MsoNormal style='margin-left:.25in'>quake has too high a processing
load, too difficult to integrate, too little interaction</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:.25in;margin-bottom:.0001pt'>prisoners&#8217; dilemma = far too simple</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:.25in;margin-bottom:.0001pt'>chaser/fleer</p>

<p class=MsoNormal>what about a quake game (using QuakeC???) where you teach
the AI 'forwards' by moving forwards and backwards similarly. it learns to
build up concepts by reference to procedures in its virtual reality</p>

<p class=MsoNormal style='margin-left:.25in'>or a family where one fires the
gun, one carries them around, and one gives the orders, with limited
communications interfaces between them</p>

<h3><a name="_Toc7457543">Go</a></h3>

<p class=MsoNormal>the thing about go is that it's always wheels within wheels.
on one level of play in a game, it's about 3 or 4 pieces fighting not to be
captured, because they're part of a large structure which is going to fall one
way or the other and these snake across the board writhing in between each
other, until you see battlegrounds emerging within the landscape of the whole
board. a markov chain in language is like this - in a way, we're choosing our
next word on the basis of the preceding word, or to fit in to a phrase (but
that phrase is NOT just constructed left-to-right - that's the problem with
markov chains ... ???), or to fit in with what has come before in the whole
sentence. that's why they are always more than one states, and the higher the
more powerful. do they have a 2- within a 3- within a 4-, or just a 4-??? could
we not try a similar strategy in go???</p>

<h3><a name="_Toc7457544">Problems to consider</a></h3>

<p class=MsoNormal>one of the problems i want to solve is the input problem</p>

<p class=MsoNormal style='margin-left:.25in'>if i don't have a rich enough feed
being organised into my AI, then my beautiful learning mechanism will have
nothing to feed itself on - nutrition</p>

<p class=MsoNormal style='margin-left:.25in'>cos i am not trying a high-level
symbolic orchestration of mind - cos that's not how nature does it, it can't be
done, if it could i can't, and if i could, then our sun will have exploded too
soon for me to finish</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal style='margin-top:0in;text-autospace:none'>environment</p>

<p class=MsoNormal style='margin-top:0in;text-autospace:none'>ability to modify
its body</p>

<p class=MsoNormal style='margin-top:0in;text-autospace:none'>_____ = the way
it interacts with its environment</p>

<p class=MsoNormal style='margin-top:0in;text-autospace:none'>level of
self-knowledge</p>

<p class=MsoNormal style='margin-top:0in;text-autospace:none'>complexity</p>

<p class=MsoNormal style='margin-top:0in;text-autospace:none'>internal
representation</p>

<p class=MsoNormal style='margin-top:0in;text-autospace:none'>language?</p>

<p class=MsoNormal style='margin-top:0in;text-autospace:none'>communication</p>

<h3><a name="_Toc7457545">Thought-organiser</a></h3>

<p class=MsoNormal>different ways in which thoughts associate</p>

<p class=MsoNormal style='margin-left:17.85pt'>hierarchy</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>introductions/abstracts, summary
explanations &#8211; macropaedia/micropaedia</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>detailed explanations</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>conclusions</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>related ideas </p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>objections, elaborations,
counter-arguments</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>parallel arguments/structures</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>similar content - author, subject etc.</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>bibliography, see also</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>definitions, dictionary </p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>examples, quotes, references,
weblinks</p>

<p class=MsoNormal>adaptive hypermedia</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>hyperlinks</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>all on screen at once</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>flung together mechanically on the
fly, tailored</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>hold mouse over to see the
information bubble up (Adobe)</p>

<p class=MsoNormal>3D visual thesaurus</p>

<p class=MsoNormal>navigate by:</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>history</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>hierarchy/detail</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>narrative/fixed sequence</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>&nbsp;</p>

<h3><a name="_Toc7457546">Misc</a></h3>

<p class=MsoNormal>could we not have this as a test for intelligence: whether
or not the AI can program its own AI which could pass its own Turing test -
this places the emphasis not on pretence, but on the necessary understanding
and real-world implementation to understand your own knowledge and pass it on
(probably with language).</p>

<p class=MsoNormal>a java backup program which automatically appends the .java
file to a text file, and allows you to cycle through old versions of your
program</p>

<p class=MsoNormal>modular neural net with lots of variables so you could build
it up as a boltzmann machine then simulated anneal it down to an other one once
the initial training was over</p>

<p class=MsoNormal>virtue theory as applied to AI</p>

<p class=MsoNormal>could you try video compression with a pattern associator -
train it with the UCS frame numbers 1-60 and the 320x200=64000 size CS and then
just run through the frame numbers to get out the CS frames back when you want
to play it</p>

<h3><a name="_Toc7457547">Principles of nature</a></h3>

<p class=MsoNormal>what is computation???</p>

<p class=MsoNormal>_(evolution, development, learning), mind (connectionism)
and evolution (DNA)</p>

<p class=MsoNormal>holism</p>

<p class=MsoNormal>homologous (neurons in the brain)</p>

<p class=MsoNormal>not easily functionally divisible &#8211; all jumbled up</p>

<p class=MsoNormal>ragged nodes &#8211; cellular automata, connectionism, organisms
in a population, DNA expression, nick&#8217;s concept connectionism, hofstadter&#8217;s
signal/symbol/sub-system ensembles, often not topographically discernible,
nebulous, inter-related, not quite continuous but still mingled (like paint
droplets), high- (or very very low-) dimensional???</p>

<p class=MsoNormal>interactionism</p>

<p class=MsoNormal>computationally modellable</p>

<p class=MsoNormal>homeostasis</p>

<p class=MsoNormal>information???</p>

<p class=MsoNormal>&nbsp;</p>

<h2><a name="_Toc7457548">Benefits/future of transhuman AI</a></h2>

<p class=MsoNormal>find out about the thesis that Greek democracy depended on
limited suffrage and a slave labour underclass &#8211; use this as an argument for AI
being the only way forward &#8211; Novalis???</p>

<p class=MsoNormal>&nbsp;</p>

<h2><a name="_Toc7457549">Technology ideas</a></h2>

<p class=MsoNormal>what about the idea that we plug our laptops into a jack on
our wrist, so that they can feed off our metabolism</p>

<p class=MsoNormal>&nbsp;</p>

<h2><a name="_Toc7457550">New categories</a></h2>

<h3><a name="_Toc7457551">Evolution</a></h3>

<p class=MsoNormal>what about the evolution of evolution?</p>

<p class=MsoNormal>social hierarchy (even in caveman times???) as an aspect of
sexual selection (like a social form of fancy nest-building)???</p>

<h3><a name="_Toc7457552">Intelligence</a></h3>

<p class=MsoNormal>Reece - intelligence <span style='font-size:10.0pt'>&#8776;</span>
familiarity with domain, confidence, motivation</p>

<h3><a name="_Toc7457553">NNs</a></h3>

<p class=MsoNormal>add training synapses for re-tooling, then they drop away
afterwards like scaffolding</p>

<p class=MsoNormal>can you use Countdown mathematical theory to figure out wh
function NNs are approximating???</p>

<p class=MsoNormal>can some neurons affect the learning function of others???
does the learning rate alter with time???</p>

<h3><a name="_Toc7457554">Language</a></h3>

<p class=MsoNormal>the fact that there are so many natural languages seems to
indicate that we form languages easily as a community, and (perhaps???) that we
form them *most* easily with a small, local community - perhaps we can learn
something from empirical evidence about the number of interactions/geography
etc. and how that relates to dialects and the ease with which languages merge,
grow</p>

<p class=MsoNormal>language as a species, dialects as sub-species???</p>

<p class=MsoNormal>is the process by which infants form syntactic categories
while placing words in those syntactic categories similar to the one by which
we mutually/communally create languages??? read up on pidgin stuff</p>

<p class=MsoNormal>forming syntactic categories as infants at the same time as
placing words in them is a typical unsupervised learning task</p>

<p class=MsoNormal>what about if you restrict yourself to a vocabulary of
&lt;1000 words, and you separate out all homonyms (eg have1, have2)</p>

<p class=MsoNormal>find out about the Chomskyan school that considers
deep/D-structure to *be* meaning - is that the same as saying that it is the LOT???</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>language is too fine-grained: a dog might 'expect his master
home soon' but we cannot say that the dog 'expects a painter called Tom [i.e.
his master] home soon' - this feels important - how can i try and develop a
limited-language in a limited domain along these lines???</p>

<p class=MsoNormal>_____ how about getting the pupil to observe various scenes,
and to try and describe them the way the teacher does, for rewards</p>

<p class=MsoNormal>_____ (cf Quine)</p>

<p class=MsoNormal>_____ is there a certain amount of complexity that can be
expressed w a given 3-word fixed-syntax/morphologised sentence???</p>

<p class=MsoNormal>_____ need for embodiment (language as mouth-musculature
related to body-musculature (behaviour) of which thought is concealed
musculature)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>describing a game of chess as an ideal, 3-word sentence
limited-domain </p>

<p class=MsoNormal>or, give them a task (against which their fitness is
measured), of communicating a certain amount of information about their
environment given a fixed/limited number of lang-tools (i.e. phonemes/morpheme
units)</p>

<p class=MsoNormal>____ 'communicate or die' scenario</p>

<p class=MsoNormal>_____ it effectively amounts to compressing the information
in the environment down by adopting conventions that allow you to represent
frequent events</p>

<p class=MsoNormal>_____ unfortunately, this method won't necessarily yield
nouns/verbs etc. but probably hybrids - and this is where nozak et al.'s paper
comes in - unless you increase the number of interacting objects and the number
of possible interactions exponentially, while keeping the number of types of
interaction (say) limited... for instance</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>pidgin vs creole???</p>

<p class=MsoNormal>pidgin as a perfect limited linguistic domain???</p>

<p class=MsoNormal>try and get a GA linguistic community to emulate the
formation/development of a creole???</p>

<p class=MsoNormal>would this require them all first having independent native
languages though???</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>we learn our first words by association - more than one
toddler has apparently believed that the word for a telephone is a 'hullo'</p>

<p class=MsoNormal>_____ what else might they wrongly associate???</p>

<p class=MsoNormal>which brings me onto the question of spellings of 'hullo' -
i had an early reader as a boy where they always spelt it with a 'u', and i
could never figure out why this otherwise normal boy </p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>what are the key arguments for/against an innate LAD, and
surely the answer is a compromise??? y, but it&#8217;s to do with how general our
ability for acquiring language is</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>interesting, if meaning is use, then it makes sense that
since &quot;the syntactic category is nothing more than a reflection of its
meaning they will not be listed separately&quot; (Altmann, pg 80)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>presumably the reason why duality is a fundamental part of
language relates to Nowak et al.'s work on the need for a combinatorial system
to express a complex (e.g. object/event) view of the world - but is there a
need for (more than) two levels of duality (at the phoneme/word level, and the
word/sentence level, and even finer grains, e.g. phoneme/morpheme,
phoneme/syllable)??? what would happen if all words were uniquely
distinguishable??? that would require a LOT of syllables, or longer sentences
filled with function words, or lots of compound words (like in German)</p>

<p class=MsoNormal>_____ is this an original/innovative means of simplifying
things??? well, not so much - the animal lang experimenters do teh same by
using a fixed vocabulary of symbols - but importantly, the experimenters are
communicating in a spoken natural language and the chimps only have the
keyboard</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>I doubt that it's that there are a finite number of
human-universal parameters that the baby sets according to the language - not
only do I not understand how that would evolve, since you'd think that races
would just evolve towards the same chosen parameters for all the languages in
that area - rather, I think that the fact that certain conventions clump
together is an epiphenomenon of the general language-learning process - mind
you, it wasn't that conventions clump but that each language seems to make a
number of binary, arbitrary decisions that Chomsky's parameters are about</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>it would be very interesting to see if any of the animals
were able to manage morphology (either in ASL or spoken), since morphology and
grammar seem two similar ways of achieving the same aim</p>

<p class=MsoNormal>similarly, you could say that just as syntax specifies the
meaning of the sentence, so does spelling signal the meaning of the word</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>is the issue of ambiguity interesting/important - it shows
that we process the sentence as we go along, but presumably there's little
ambiguity in a 3-word sentence - aha, but when they're LEARNING grammar, they
will not know whether the obj comes before or after the verb - hence the value
of knowing the meanings of the nouns so they can guess given what's happening</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>we appear to try and fit agents into roles as soon as we
encounter them, and revise our assumptions later if necessary - this fits my
idea that grammar is effectively (or grew out of) the sum of all the relations
contained with reference to words in the mental lexicon - we can't deal well
with role-less words - we're doing a complicated constraint satisfaction
exercise all the time</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>define the sentences my agents have in terms of their
characteristics</p>

<p class=MsoNormal>_____ eg the lang modality being fleeting, distal,
segmented/discrete???, line of sight??? etc.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>do i think there are added, or even diminished difficulties,
in trying to model the evolution of language in more writing-like (or
gesture-like) than speech-like modality???</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>how do you program in an innate representation/assumption
for the same thing not having two names???</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>the brain may well not have concepts in the way that we
think - the brain simply consists of a single brain state that we can
artificially try and break down and consider in discrete/component terms, but
ultimately a given concept may only be fully specifiable in terms of the
aggregate of all past/possible functional roles it could play</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>mental lexicon - better analogy than the OED would be a sort
of 'What's what' biography of objects/words???</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>is very an adverb??? do adverbs describe verbs??? do adverbs
also describe adjectives??? is there any way in English to describe adverbs???</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>perhaps the logical operators (and, not etc) would be quite
easy to learn - and from them, 'and' as a conjunction, and 'but' (and + not)
could follow. and then '-&gt;' (i.e. 'if') and then conditionals</p>

<p class=MsoNormal>basically come up with my own simple grammar, which i can
write a program to deploy like a simplistic governess/wet-nurse to an agent,
which can then learn it, be replicated, and then improve on it within a
community</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>pictionary as the new turing test</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:.25in;margin-bottom:.0001pt'>surely the problems about subcognition
would be even more extreme</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>how about waterfalls in a zigzag pattern of trace-ruled
neuronal activity representing continuous word-by-word input???</p>

<p class=MsoNormal>a 50-neuron input vector, with each neuron being just on or
off, could probably represent an enormous number of words/combinations</p>

<p class=MsoNormal>each word could be attached to a set of bit flags for part
of speech, plural etc.</p>

<p class=MsoNormal>the words could come in, 8 neurons or whatever at a time,
and fill up a buffer of 1000 neurons within which the entire sentence has to
fit &#8211; would that work with word order at all???</p>

<p class=MsoNormal>does Nowak et al.&#8217;s point about the difficulty of
communicating + storing enormous number of words work??? yes, because although
a 500-neuron binary vector = 2<sup>500</sup> = 10<sup>150</sup>, representing
is different from learning/storing/recalling and
communicating/attenuated/decoding etc.</p>

<p class=MsoNormal>the Nowak, Plotkin &amp; Jansen (2000) paper excludes Alex
the grey parrot from its discussion of complex animal vocalisation. curiously,
it seems happy to define syntax in terms of (discrete, combinable) components
which have their own meaning, which surely includes Kanzi etc.???</p>

<p class=MsoNormal>the paper doesn&#8217;t consider pre-language, where there is no
consensus on the words &#8211; but perhaps, there was no such time. the primeval sign
language symbol for danger is running away, the symbol for hawk is looking
worriedly into the sky etc. &#8211; hence the importance of embodiment, a real
environment, a fitness function imperative to learn language that relates to a
fitness function motivating behaviour, and tying language in with the other
senses as part of the whole gamut of signals with which we communicate</p>

<p class=MsoNormal>how big/sharp a transition is it to go from event-based
non-syntactic language to syntactic language??? can the two co-exist to some
degree for a while??? what&#8217;s curious is that you might think that common events
would frequently be broken down into object/action pairs, but at the same time,
there&#8217;s a strong force moving frequently correlated object/action pairs towards
their own name &#8211; I think that actually it&#8217;s when you get numerous/frequent
events which contain a similar factor that they get broken down, e.g. man
running, man walking, man being scared of beast, man eating <span
style='font-size:10.0pt;font-family:Symbol'></span> man +
running/walking/being scared/eating etc.</p>

<p class=MsoNormal>they don&#8217;t address the verb/adjective similarity, e.g.
runningMan, man running</p>

<p class=MsoNormal>does it make sense to talk of the world as containing
discrete number of objects or actions??? of course not, though the analysis is
presupposing a pre-linguistic abstraction mechanism to which the words refer. I
wonder whether it makes any difference that language shapes that abstraction
mechanism to fit its representational/communicable properties???</p>

<p class=MsoNormal>in fact, it implies at the end that one can (and many
animals do) have a syntactic understanding of the world without a syntactic
means of communicating</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>you can't divorce comprehension from generation - the two
are inter-related. would babies learn language if they weren't allowed to
babble, or even speak at all? no, i don't think so(???)</p>

<p class=MsoNormal>i want to create a simple environment, with particular
entities that are all different from each other, but that i can universalise
and label. i will represent the input from the environment to my agent in an
abstracted form, but the modality might be something like a bat's sonar, or a
visual pattern, or an n-dimensional co-ordinate. needs input, but you also need
output, interaction with your environment, embodiment. if i create a rich, but
still crude, representation/modality then i don't need to worry about vision,
though language is only as complex as the environment we need to represent.</p>

<p class=MsoNormal>leila thinks you can have a priv, internal mental language
that you can't communicate. apparently we disagree with this.</p>

<p class=MsoNormal>in order to communicate with language, then you need a
mental representation of language. this may or may not be the same as an
internal language - leila thinks they are the same.</p>

<p class=MsoNormal>you need consciousness in order to ascribe meaning to the
neural representations. you need consciousness in order to separate yourself
from teh environment</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>excerpt from Pinker demonstrating the need for cognitive
processes underlying linguistic ones: <i>Conceptual development, too, might
affect language development: if a child has not yet mastered a difficult
semantic distinction, such as the complex temporal relations involved in John
will have gone, he or she may be unable to master the syntax of the
construction dedicated to expressing it.</i></p>

<p class=MsoNormal>there needs to be a context in which a sentence is uttered
in order for the child to eventually be able to derive meaning from sound</p>

<p class=MsoNormal>if you&#8217;re going for biological plausibility, then negative
evidence shouldn&#8217;t play too strong a role in your learning &#8211; see Learnability
theorem</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>can you not just use a combination of positive evidence and
a continual pruning with ockham&#8217;s razor to discern the legitimate constructions
in a language, even without negative evidence???</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>language, apparently, is not quite like sight (in that you
need to coordinate your visual input relative to idiothetic signals and
voluntary action &#8211; e.g. the kitten strapped to a trolley and wheeled around who
never learned to see) (cf misc notes)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>these modalities i ascribe my agents in their evolving world
(the environment changes in terms of the features of the land, i.e. plants and
shape of the land and weather) as well as in terms of the competing enemies
(all of which should, really, see *themselves* as agents). anyway, how could i
evolve my agents language? i will give them a limited bandwidth and a set of
say 10 articulatory sounds, by which i will try to get them to evolve a LAD. by
this i mean that two agents will mutually come to ascribe a certain arbitrary
phoneme or combination of phonemes a meaning, and that eventually the continued
use of these certain phonemes in connection with certain objects/events will
cause the language community as a whole to adopt those 'words' (i.e. the usage
of those particular phonemes in a particular context). i would hope that
eventually each agent would come to be represented by a different
phoneme-combination (i.e. word, i.e. name) as well as being a member of the
overall species-group (word/name). it is only a hop, skip &amp; jump to a
noun-verb distinction. we could then see whether, over successive generations,
language became more complex (depending on whether they lived longer, whether
there were adaptive benefits to speaking it (eg pheremone trails and flocking
and group attacks)(i.e. each incremental step was both adaptive and increased
their innate linguistic aptitude), whether their neural networks could cope
with more complex language, whether their environment was hard enough to merit
it, whether the evolutionary mechanism could evolve their neural networks and
articulatory/auditory mechanisms to increase bandwidth on the part of speaker
&amp; listener), whether knowledge would be passed on to future generations by
being passed down to the next generation in speech, or even being stored in the
environment as communal memory in the form of writing, whether new languages
would develop if we take away their ears but give them expressive finger
gestures etc.</p>

<p class=MsoNormal>it all comes down to whether syntax can be represented
neurally.</p>

<p class=MsoNormal>their lifespans should increase after a number of
generations (ideally through evolution and not being killed so much), so that
the phylogenetic improvements in language-learning (e.g. larger NNs, increased
range of speech sounds, memory, the beginnings of a specific innate LAD) are a
precursor to the ontogenetic improvements (which i hope to see demonstrated in
the model, in line with the real life ones) - first single words, then
combining words, perhaps initially in common/fixed patterns, finally in larger
phrases - it might be that a language where word order is less important than
endings will evolve, or vice versa or something new - who knows, if it works,
what sort of language (or whether i'll be able to decipher it) will emerge?</p>

<p class=MsoNormal>there would also be some tangential value because this would
be a truly alien language, and it would be interesting in terms of
understanding whether or not human language acquisition stems from our
general-purpose cognitive abilities learning specialised linguistic
functionality, or whether we have an innate LAD - we could study how easily
humans were able to learn this new language, relative to our little
computerised agents at different levels of linguistic evolution.</p>

<p class=MsoNormal>ideally there should be some intermediate adaptive value to
being able to articulate the phonemes, e.g. any verbalisation whatsoever could
sound like an enemy's approaching war-cry, with different vocalisations coming
to represent different enemies. from here, where though???</p>

<p class=MsoNormal>perhaps this A-life experiment will investigate internal
models that the agents form, and how language and social organisation are
closely tied with trying to figure out what another agent will do</p>

<p class=MsoNormal>consider chains of discrete NNs - eg a NN which specifically
gets input from one modality - but this wouldn't evolve - that would be me playing
God, which will make it harder for me to simultaneously get the NN to associate
all these separate forms of input</p>

<p class=MsoNormal>they will have good ears and be short-sighted</p>

<p class=MsoNormal>what about if they communicate in tones, or some other
restricted discrete auditory units, rather than blended, analogue-ish???
infinitely variable acoustic signals (like human speech) &#8211; perhaps the letters
of the alphabet can be used to randomly represent their articulatory range,
from which their phonemic inventory will be drawn</p>

<p class=MsoNormal>i believe in a mentalese, because of the difficulties of
vocalising a thought in words, and also because an idea is somehow unitary and
on the verge of linguistic, but it is definitely represented differently to the
sequential nature of a sentence (which must be so necessarily because of the
serial stream of speech on which it depends).</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>part of the reason that you can't have comprehension without
generation or vice versa might come from evidence for the motor theory of
speech perception, where we represent language in terms of the articulatory
motor signals, and so when we hear someone speak, we are translating the
auditory signal into the motor signal representationn we would need to make the
same speech sounds ourselves. in which case, learning to understand language without
being able to speak would be impossible.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>experiment: put two alien intelligences into a sealed-off
environment. do they learn to communicate? can they solve a problem together
which requires co-operation?</p>

<p class=MsoNormal style='margin-left:17.85pt'>is there a difference between a
solitary and a social intelligence?</p>

<p class=MsoNormal style='margin-left:17.85pt'>problems to bear in mind:</p>

<p class=MsoNormal style='margin-left:35.7pt'>can't be humanocentric problem</p>

<p class=MsoNormal style='margin-left:35.7pt'>shouldn't be trial-and-error</p>

<p class=MsoNormal style='margin-left:35.7pt'>should they be baby or mature
programs</p>

<p class=MsoNormal style='margin-left:35.7pt'>if a human was being experimented
on by an alien, we might appear unintelligent. how could they be sure to see us
at our best? bring us up in captivity in a monitored sealed enriched
environment... they still might not see us at our best, as the race with the
potential to rule the Earth. it's not so much a case of physical or atmospheric
conditions - it's one of competition/co-operation with other people/animals
(usually of lower intelligence)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>how can I pare down the language input?</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>no noise</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>capital letters</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>full sentences</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>correct grammar</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>limited correct punctuation</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>vocabulary?</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>no poetic/non-literal language</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>limit to: statements, questions,
indirect speech actions?</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>highlight what is memorable/has
information-content, what isn&#8217;t</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>tagging, like ling-XML?</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>acquiring linguistic competence means acquiring a collection
of recursive grammatical rules</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>we could test for a LAD by teaching someone an unnatural
language, and then speaking only that language to a child</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>lemma? corpus theory/text?</p>

<p class=MsoNormal>orthographic</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>how rich does this virtual environment need to be?
multi-sensory, beautiful, means of communication with other agents</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>connectionist</p>

<p class=MsoNormal>multiple modalities (for association. semantics = the
abstraction from these less objective inputs) &#8211; the more the better &#8211; top level
</p>

<p class=MsoNormal>second level &#8211; wordnet</p>

<p class=MsoNormal>bottom level &#8211; meaning??</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>things i want my program to do</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>could i railroad my lingocritters towards english???</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>perhaps use simple reinforcement learning to reward babbling
on the right track</p>

<p class=MsoNormal>innate babbling mechanism</p>

<p class=MsoNormal>innate reward system/inclination to for babbling right</p>

<p class=MsoNormal>need to show how lang got started - how even a little bit of
lang is an adaptive thing</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>important semantic relations tween words</p>

<p class=MsoNormal>explore how the semantic and lexical relations emerge
together</p>

<p class=MsoNormal>probably minimise morphology, &lt;1000 word vocabulary,
short sentences, free word order???</p>

<p class=MsoNormal>perhaps focus on lots of events that have interchangeable
subjects + objects to hammer home the syntactic difference</p>

<p class=MsoNormal>reason for using 3 word sentences</p>

<p class=MsoNormal>_____ easier for humans + algorithms to produce</p>

<p class=MsoNormal>_____ interesting to see how expressive they can be</p>

<p class=MsoNormal style='margin-top:4.0pt'>___________ do you allow one
sentence to follow on from another/elaborate upon???</p>

<p class=MsoNormal>_____ fixed size input is much easier - can be stored safely
in a memory to be processed as a whole</p>

<p class=MsoNormal>___________ however, i think that creativity/productivity
(the fact that we can produce an infinite number of sentences of any length) is
a crucial fact about language, and indeed a crucial fact about the way that we
parse sentences (garden path theory focusing upon time constraints and online
processing), and about what we consider to be the more likely/easier way of
understanding a sentence</p>

<p class=MsoNormal>___________ fixed size sentences ignore this</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>possible environment:</p>

<p class=MsoNormal style='margin-left:17.85pt'>urban</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>natural</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>ocean</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>toroidal???</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>food, predators, conspecifics</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>disembodied</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>give internal instructions to body</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>lang translate into efference
instructions</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>easier if it's a homogenous environment, i.e. no special zones</p>

<p class=MsoNormal>would the creatures game environment be good?</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>how do they move away from pure observables to full
language???</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>proper names</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>nouns - basic common types of object</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>basic 1 or 2 place verbs</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>3 place verbs</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>nouns referring to internal state,
e.g. hunger, pain, fear</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>adjectives</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>semantic relations tween nouns</p>

<p class=MsoNormal style='margin-top:2.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>e.g. hypernyms, synonyms, antonyms</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>logical relations, e.g. and, not
(basic conjunctions)</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>basic word order/morphology</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>number</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>relative clauses</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>mystery:</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>beliefs, intentions and reasons</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>belief = simply acting as though you
have that belief (Dennett) &#8211; does that help???</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>causality</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>questions</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>non-observables/abstraction, e.g.
hunt, kill, food???</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>tense</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>pronouns</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>conditional, subjunctive</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>complicated conjunctions, e.g.
because, but, however</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>function words, counterfactuals</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>comparison</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>this requires a functioning/complex social system, complex
internal/nervous system, complex environment, complex brain + reward system,
need for cooperation (i.e. for the language to do something, and be helpful
even when it's in its simplest stages)</p>

<p class=MsoNormal>_____ should language be the only variable???</p>

<p class=MsoNormal>_____ use of language should allow greater numbers to be
sustained by the environment, i.e. should be directly linked to survivability</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>how can i be sure that the language they'll produce will map
onto human/English syntactic/semantic categories??? if it doesn't, will i be
able to tell what it's doing???</p>

<p class=MsoNormal>_____ well, if it's systematic, that's one clue to decoding
it - and if it spreads amongst a population and helps them survive, that
settles it</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>environment ideas:</p>

<p class=MsoNormal style='margin-left:17.85pt'>maze/building blocks - no one
individual can see much of the bigger picture</p>

<p class=MsoNormal style='margin-left:17.85pt'>ant/termite colony/hive???</p>

<p class=MsoNormal style='margin-left:17.85pt'>i want to get away from
space/direction too much, cos that places too many requirements on place cells
and the like - does that rule out honey bee dances etc.</p>

<p class=MsoNormal style='margin-left:35.7pt'>could i just have an algorithmic
motor system that takes in pre-specified signals, that the agent has to decode
from language, and acts appropriately, e.g. heading in a given direction???</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'>or a high-level pathfinding motor
system that just takes in destination-objects</p>

<p class=MsoNormal style='margin-left:35.7pt'>that still requires the agent to
know where it is and where it wants to be - too big (and non-linguistic) a
requirement</p>

<p class=MsoNormal style='margin-left:35.7pt'>reconsider Kant's (+
Strawson/Evans) args that we need space + time inherently</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>body language + gestures are just as big a problem as
language - avoid!</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>the nature/restraints/requirements of your environment will
determine structure, what&#8217;s easy and the course of acquisition of the language</p>

<p class=MsoNormal style='margin-left:17.85pt'>what about blocksworld??? that
would be good for relative clauses, adjectives, types of nouns</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>bad for events</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>weird, limited spatial aspect</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>bad for other agents, predators,
intentions</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>it could be just a domain, or one
aspect of the environment, I suppose</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>better for description than
interaction</p>

<p class=MsoNormal style='margin-left:35.7pt'>&nbsp;</p>

<p class=MsoNormal>like your hands following each other climbing up a ladder,
there&#8217;s no way for the cognitive ability to be 10 feet ahead of the linguistic,
or vice versa</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>internal (mentalese) language <span style='font-size:10.0pt;
font-family:Symbol'></span> motor interface (behaviour) vs external, public
(motor-voice)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>verbs are events &#8211; many/most events that are interesting are
actions &#8211; actions are usually successfully-executed intentions &#8211; intentions are
a combination of goals + means + reasons</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>or, actions = desires + reasons</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>either way, without that cognitive
structure, there&#8217;s no way that you&#8217;re going to notice/explain certain verbs,
because you won't structure the (your) world along those lines</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>e.g. take, give, hunt, want</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>does that mean that beliefs have to
come before the means of expressing it???</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>where do propositions fit in to all
this???</p>

<p class=MsoNormal style='margin-left:17.85pt'>alternatively, perhaps you can
define give as &#8216;first he had it and now he has it&#8217; etc. &#8211; but that&#8217;s not the
same, and it&#8217;s less rich, less explanatory/predictive</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>but it&#8217;s a start</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>could you start to abstract reasons
from lots of such observed behaviour???</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'>only if there were reasons (even if
implicit/innate etc.) to begin with</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'>only if you operated according to
similar reasons</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:71.4pt;margin-bottom:.0001pt'>comes back to folk psychology &#8211;
explain others&#8217; behaviour by laws or by simulating yourself in their shoes &#8230;</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:89.25pt;margin-bottom:.0001pt'>I think that the latter is a more
complex/richer version that grows out of the former</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>consider jaynes thesis</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>perhaps it&#8217;s necessary/very helpful to have some sort of
prosody-like extra cues besides just the words</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>especially if I&#8217;ve taken out all the
perceptual business and I&#8217;m feeding them a pure linguistic segmented channel</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>what&#8217;s this linguistic channel going
to look like &#8211; something like chinese ideograms, where each unit has meaning???</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>I don't like morphology, though I
somehow feel it would be easier to train a NN to slightly morphologise its words
than to do word order</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>having said that, morphology is a
kind of tag attached to the main stem, right??? and why not attach a tag that
gets interpreted into a sequence later by another module, and then gets fed
into the motor/ling-output model sequentially </p>

<p class=MsoNormal>how about tagging each word with the ling-channel equivalent
of volume/emphasis, so that proper names get heavily emphasised, then nouns,
then adjectives or verbs or whatever, and it will quickly evolve a
pre-linguistic perception/filter mechanism to prioritise processing of those &#8211;
the computational model equivalent of motherese </p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>how does the restructuring work that allows the agent to go
from proper names <span style='font-size:10.0pt;font-family:Symbol'></span>
type nouns <span style='font-size:10.0pt;font-family:Symbol'></span> an
adjective + noun phrase???</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>understanding &#8216;why&#8217; means being able to abstract reasons/intentions
from an event</p>

<p class=MsoNormal>intentions <span style='font-family:Symbol'></span>
agent-reasons</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>if the production of language is an uncompressed version of
a non-linguistic tightly-packed non-sequential ball of meaning that gets built
up inside your head, then you&#8217;d expect the limits of what we can say to be
somehow meaning- rather than grammar-constrained, which is more or less what
happens</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>we can produce grammatically
horribly complex sentences but the constraints are on what we can understand
conceptually, right??? or completely the opposite???</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>how important is a value(/money) concept to the whole
business??? of prioritising events/results??? how important is it to emotions,
how important is emotion to it, and how important is emotion to everything???</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>priorities/goals aren't represented
propositionally &#8211; they&#8217;re the sum total of behaviour (cf Dennett intentional
stance + definition of belief)</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>so I shouldn't worry about
programming in intentions, they&#8217;ll grow and become complex, indirect and
multi-layered naturally as behaviour becomes more complex (which is based on an
increasingly complex world model)</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>in the same way, do predictions (and
so conditionals, counterfactuals etc.) arise naturally too??? certainly, they
seem like a paradigm example of where language follows cognitive</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>if I want to predetermine certain
intentions, I can either somehow evolve the agents towards certain actions, get
the parents to teach children (both too hard), allow them to learn it in the
environment (would have to be fairly simple)</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>but, best of all, could I just have a
subconscious algorithmic system that intervenes and makes it do things without
it realising, and get it to somehow monitor and try and make sense of its own
behaviour separately from its intentions, and so post-rationalise its own
behaviour???</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>&nbsp;</p>

<p class=MsoNormal>the way that children inherently seem to form creoles (e.g.
out of pidgins) (whereas adults are only able to manage pidgin proto-languages)
seems to indicate that the language-learning faculty in an individual is
somehow linked to the collective language-forming faculty of a community &#8211;
could it be that language is emerged/evolved almost entirely by the children in
a community, who grow up to be native speakers???</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>certainly, it&#8217;s the youth who invent
the vocabulary and idioms of their generation</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>&nbsp;</p>

<p class=MsoNormal>the reason that we can have sex is so that if two
individuals both make separate discoveries, they can be merged, rather than
either getting one or the other benefit</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>how about this for a GA:</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>2 parents</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>have 10 children, each with one or
more crossover points at different positions</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>each child has 10
mutant-twin-variants with slight variations here and there to add variability</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>choose best two to be parents</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'>allows possibility of parents being
optimal</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>each generation gets a few bonus
genes, to increase complexity, so that they can do more than their parents
could</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>problem with this is that it starts
from just a single point on the genetic landscape then thoroughly explores all
around it</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>&nbsp;</p>

<p class=MsoNormal>I need to design my 1000 word language, by deciding on the
environment, its vocabulary, basic syntax, the senses + motor abilities of my
agent, and the protocol of the ling-channel</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal><span style='layout-grid-mode:line'>just like perception,
learning is an active 'intelligent' process - this is almost obvious, but not
quite - the point is that i don't just read a book, and having understood and
considered the words, comprehend the meaning, abstract and remember the content
and appreciate subtexts - i have to actively search out meaning and impose
structure</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>&nbsp;</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>there is a need to limit
the domain within which a new chatterbox operates. they've used virtual reality
environments, film, conversation, life stories, artificial intelligence itself
and the Loebner Prize - what about philosophy?</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>&nbsp;</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>the problem is that
there is no single type of thought. you can't just break it down to knowledge
hierarchies and sorting, casality, association, higher-order thoughts,
abstraction, visualisation, reversibility (in the piagetian sense), debate,
purposive problem solving (generating and considering options, deciding,
evaluating results), comparing, emotions - it's many many things - that's why
intelligence is an indefinable term</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>maybe we can model each
one of these, and somehow combine them - parallel neural nets or some such
thing. i'm pretty sure that central processing is modular in some sense though
(cf Fodor)</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>what would happen if we
put a program through the national curriculum</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>&nbsp;</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>what you feed the
program matters - if you just give it an encyclopaedia, it won't know anything
about Transformers or the fact that people hate waking up in the morning or any
one of a million little things that we take for granted</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>&nbsp;</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>it should be able to
interpret knowledge amassed in other sources into its knowledgebase (incl human
inputters, CYC, dictionaries, encyclopaedia, novels, images, sounds, video
footage and cameras etc.)</span></p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal><span style='layout-grid-mode:line'>maybe my program needs
implicit/explicit levels of memory - that's just a variation on the
probabilistic/stochastic(?) approach</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>&nbsp;</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>it does seem that it'll
be modular</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>maybe a low-level
learning model (neural net) is the way forward</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>i'm going to have to be
very careful what information i feed it</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>there's the
syntactic/semantic divide, similar to the interpretation (back and forth) vs
processing (eg in formal logic)</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>i may try and include
some predicate calculus, but i don't see how that will help</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>object-orientated - try
and reify abstract concepts, like happiness etc.</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>give it purpose - what's
the aim - to hold a conversation, to appear human, to learn more about it's
environment, not to be deleted as a failed program ...</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>&nbsp;</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>McCarthy: learning is
'constructing or modifying representations of what is being experienced'</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>&nbsp;</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>difference tween
derivational/inflectional morphemes?</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>&nbsp;</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>my grammatical parser
will have to work on a word (, phrase) and sentence level</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>so i need to look at
morphemes, clauses and sentences</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>and in order to look at
an essay, also paragraphs and essays</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>should it then encode
these into units of knowledge, which will be connected (perhaps
hierarchically?)</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>is there any reason to
include a morphological parser (other than completeness) if i can include
pretty much every word with its inflections etc. in a big dictionary -
including more than one possible category for each combination to =&gt; &gt;1
parse tree</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>&nbsp;</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>memory does not store
thing according to one characteristic - there's 2 dimensions:</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>_____ strength/vividness/accuracy/completeness
of memory (which seems to be usually assumed (wrongly) to be simply a result of
a limited-capacity analogue mechanism, but is actually another way of sifting
through, and probabilistically prioritising association</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>_____ semantic/content-based
connections - is 'association' a part of this, or more fundamental to the whole
process?</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>&nbsp;</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>like an interactive
activation model, the levels should feed information/weightings back and
forwards to influence each other</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>&nbsp;</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>how to include semantic
information in a morphological parser</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>&nbsp;</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>what's a gloss/feature?</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>&nbsp;</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>new words:</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>include etymology
somehow?</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>ask the user to
define/relate them - ask part of speech, has it been spelt wrong, is it similar
to this word, give contextual examples of its use etc.</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>&nbsp;</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>language may well just
be the tip of a cognitive iceberg, but you can still try and get as high a
tip-to-iceberg ratio as possible</span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'><span style='layout-grid-mode:line'>I&#8217;m
speculating that the subject-verb(-object) construct is one of the simplest and
most useful, and likely most ancient, genuinely linguistic (i.e. powerful,
syntactic relation between symbols) constructs, and trying to model how it
might emerge within a minimum cognitive + social framework</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>I&#8217;m going to start by
building an agent that can learn a pre-built simple language from a teacher</span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'><span style='layout-grid-mode:line'>I&#8217;ll
continually feed it sentences describing the environment around it</span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'><span style='layout-grid-mode:line'>it&#8217;ll
babble as it sees things (because it&#8217;s speech organs will be initially
haphazardly linked to its sense input (including a special (text???) linguistic
input channel from its teacher))</span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'><span style='layout-grid-mode:line'>I
want to build a cognitive processing bridge between sensory + linguistic input
and motor output that correlates common/regular features of the senses (i.e.
environment) with the linguistic channel, probably by rewarding it every time
its babble matches with the taught describing sentence</span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'><span style='layout-grid-mode:line'>these
sentences will either be simple labels (e.g. &#8216;rabbit&#8217; or &#8216;Fluffy&#8217;), or the
3-word sentences with some sort of prosody-like emphasis on the most relevant objects</span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'><span style='layout-grid-mode:line'>how
do I make sure that it doesn't simply ignore the sensory input and repeat
everything it hears linguistically???</span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'><span style='layout-grid-mode:line'>partly
because the pattern associator will seek the widest/richest pattern across its
inputs, right??? is that right???</span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'><span style='layout-grid-mode:line'>and
partly because the teaching sentences will become quieter/less often as it gets
them right more often, though the rewards for babbling correctly will continue</span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'><span style='layout-grid-mode:line'>this
pattern will definitely be linearly separable, right???</span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'><span style='layout-grid-mode:line'>I
will slowly increase the number of objects (nouns) it encounters. I will also
try and teach it the difference between proper names and types, so that it
realises that (e.g.) Fluffy is a type of rabbit</span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'><span style='layout-grid-mode:line'>then
I&#8217;ll start to feed it sentences like &#8216;rabbit zorking duck&#8217;</span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'><span style='layout-grid-mode:line'>how
exactly do I get from this simple correlation to syntactic categories, i.e. the
distinction between nouns + verbs???</span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'><span style='layout-grid-mode:line'>re-read
the nowak thing about combinatorial explosion</span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'><span style='layout-grid-mode:line'>if
it&#8217;s just a big backprop net linking input and output patterns, that&#8217;ll be a
mess</span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'><span style='layout-grid-mode:line'>I
guess the way I intend to represent nouns is to have a competitive net based on
my ling channel that grows a new output node every time it hears a new word,
and that output node will be wired back to the environment somehow so that it
will &#8230;???</span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'><span style='layout-grid-mode:line'>basically,
a verb has to be a correlation between the environment and a group of nouns???</span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'><span style='layout-grid-mode:line'>see
Altmann on zorking etc.</span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'><span style='layout-grid-mode:line'>maybe
it would be easier to think of verbs without an object as adjectives, and verbs
with an object like prepositions (especially in something like blocksworld) &#8211;
verbs are after all just relations between nouns, although after a while, it
makes more sense to think of it the other way round, i.e. nouns as just objects
related by verbs</span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'><span style='layout-grid-mode:line'>verbs
are one of the hard parts &#8211; once you&#8217;ve managed 1-, 2- and 3-place verbs,
you&#8217;ve more or less got the syntactic toolbox you need to think in terms of nouns,
verbs, prepositions and adjectives, with adverbs being I suppose just an
extension of verbs</span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'><span style='layout-grid-mode:line'>all
of this business of thinking of (e.g.) adjectives growing out of nouns as the
combinatorial explosion makes it necessary (same as with objects + events in
Nowak) makes morphology seem the more natural route</span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'><span style='layout-grid-mode:line'>as
said elsewhere, perhaps its easier to have a morphological neural
representation that gets transformed (Chomsky)/put in sequence after/by the
speech-motor system</span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'><span style='layout-grid-mode:line'>maybe
part of the secret to variable length sentences is chunking</span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'><span style='layout-grid-mode:line'>e.g.
sentence =</span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:71.4pt;margin-bottom:.0001pt'><span style='layout-grid-mode:line'>NP
+ Event/Description</span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:71.4pt;margin-bottom:.0001pt'><span style='layout-grid-mode:line'>NP
=</span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:89.25pt;margin-bottom:.0001pt'><span style='layout-grid-mode:line'>Noun</span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:89.25pt;margin-bottom:.0001pt'><span style='layout-grid-mode:line'>Adj
+ &#8230; + Noun</span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:71.4pt;margin-bottom:.0001pt'><span style='layout-grid-mode:line'>Event/Description
=</span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:89.25pt;margin-bottom:.0001pt'><span style='layout-grid-mode:line'>Verb</span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:89.25pt;margin-bottom:.0001pt'><span style='layout-grid-mode:line'>Verb
+ DirObj</span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:89.25pt;margin-bottom:.0001pt'><span style='layout-grid-mode:line'>Verb
+ IndirObj</span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:89.25pt;margin-bottom:.0001pt'><span style='layout-grid-mode:line'>Preposition
+ DirObj</span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:89.25pt;margin-bottom:.0001pt'><span style='layout-grid-mode:line'>isAdjective</span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:71.4pt;margin-bottom:.0001pt'><span style='font-size:9.0pt;
layout-grid-mode:line'>sentence + conjunction + sentence</span></p>

<p class=MsoNormal style='margin-left:53.55pt'><span style='layout-grid-mode:
line'>if you only allow right-branching sentences, then the unpacking from
chunked-meaning-representation to sequence-surface-speech can be in real time</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>&nbsp;</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'><a
href="http://cognet.mit.edu/MITECS/Entry/smolensky">http://cognet.mit.edu/MITECS/Entry/smolensky</a></span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'><a
href="http://citeseer.nj.nec.com/elman90finding.html">http://citeseer.nj.nec.com/elman90finding.html</a></span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'><a
href="http://www.coli.uni-sb.de/~crocker/Teaching/Connectionist/Connectionist.html">http://www.coli.uni-sb.de/~crocker/Teaching/Connectionist/Connectionist.html</a></span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>[2] L. Bloom. One Word
at a Time: The Use of Single Word Utterances Before Syntax. Mouton de Gruyter, </span><span
  style='layout-grid-mode:line'>The Hague</span><span style='layout-grid-mode:
line'>, 1973.</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>&nbsp;</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>&nbsp;</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>ergative???</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>&nbsp;</span></p>

<h3><a name="_Toc7457555">Environ/language</a></h3>

<p class=MsoNormal>critter</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>Alpha</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>Bravo</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>Charlie</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>Delta</p>

<p class=MsoNormal style='margin-top:0in'>food</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>mutton</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>steak</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>beef</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>pasta</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>corn</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>cereal</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>chips</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>spaghetti</p>

<p class=MsoNormal style='margin-top:0in'>drink</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>water</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>milk</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>orange-juice</p>

<p class=MsoNormal style='margin-top:0in'>sweets</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>chocolate</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>crisps</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>ice-cream</p>

<p class=MsoNormal style='margin-top:0in'>painful plants</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>nettle</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>mushroom</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>thorn</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>briar</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>holly</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>fly-trap</p>

<p class=MsoNormal style='margin-top:0in'>predator</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>lion</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>tiger</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>bear</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>spider</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>wasp</p>

<p class=MsoNormal style='margin-top:0in'>trap</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>tripwire</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>bearpit</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>banana-skin</p>

<p class=MsoNormal>___</p>

<p class=MsoNormal style='margin-top:0in'>&nbsp;</p>

<p class=MsoNormal style='margin-top:0in'>animals</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>rabbit</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>duck</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>sheep</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>cow</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>fox</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>cat</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>dog</p>

<p class=MsoNormal>___</p>

<p class=MsoNormal style='margin-top:0in'>&nbsp;</p>

<p class=MsoNormal style='margin-top:0in'>agent/friend</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>propernames</p>

<p class=MsoNormal style='margin-top:0in'>food</p>

<p class=MsoNormal style='margin-top:0in'>drink</p>

<p class=MsoNormal style='margin-top:0in'>hunger</p>

<p class=MsoNormal style='margin-top:0in'>thirst</p>

<p class=MsoNormal style='margin-top:0in'>replete</p>

<p class=MsoNormal style='margin-top:0in'>quenched</p>

<p class=MsoNormal style='margin-top:0in'>pain</p>

<p class=MsoNormal style='margin-top:0in'>healed</p>

<p class=MsoNormal style='margin-top:0in'>danger/fear/SOS</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>types of predator</p>

<p class=MsoNormal style='margin-top:0in'>exists/is-there</p>

<p class=MsoNormal style='margin-top:0in'>allgone</p>

<p class=MsoNormal style='margin-top:0in'>fleeing</p>

<p class=MsoNormal style='margin-top:0in'>eating</p>

<p class=MsoNormal style='margin-top:0in'>drinking</p>

<p class=MsoNormal style='margin-top:0in'>idling</p>

<p class=MsoNormal style='margin-top:0in'>gave</p>

<p class=MsoNormal style='margin-top:0in'>like</p>

<p class=MsoNormal style='margin-top:0in'>dislike</p>

<p class=MsoNormal style='margin-top:0in'>has-status-of</p>

<p class=MsoNormal style='margin-top:0in'>very/much</p>

<p class=MsoNormal style='margin-top:0in'>not-much</p>

<p class=MsoNormal style='margin-top:0in'>numbers</p>

<p class=MsoNormal style='margin-top:0in'>feed</p>

<p class=MsoNormal style='margin-top:0in'>cheat/deprive</p>

<p class=MsoNormal style='margin-top:0in'>social system</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>leader</p>

<p class=MsoNormal style='margin-top:0in'>cooperate</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>hunt</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>join</p>

<p class=MsoNormal style='margin-top:0in'>fight</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>chase</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>escape</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>defeat</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>kill</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>retreat</p>

<p class=MsoNormal style='margin-top:0in'>&nbsp;</p>

<p class=MsoNormal style='margin-top:0in'>how about just a series of scenes
that it has to describe???</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>e.g.</p>

<p class=MsoNormal style='margin-top:2.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>red square near blue circle</p>

<p class=MsoNormal style='margin-top:2.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>rabbit eats crisps</p>

<p class=MsoNormal style='margin-top:2.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>etc.</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>the question then entirely rests on
the form of the sensory input &#8211; if you effectively feed it the words for
rabbit, crisps etc. then what is it doing??? it&#8217;s doing what Elman&#8217;s FSIT NN
does, which is learning about syntactic categories</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>and it has to reformat the sequence
of words</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>the fitness function is how many of
the examples it correctly describes</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>having achieved that, you can then
try and get a community to convention-agree the vocabulary + syntax (is that
what I want to do???)</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'>or better still, get the community
to describe each other</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'>but what will they be doing??? if
they&#8217;re going to be eating, then they have to have motor systems + intentions
etc.</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:71.4pt;margin-bottom:.0001pt'>not necessarily, they could have
reptilian (i.e. algorithmic) hind-brains that involuntarily do all that stuff
for themselves</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:71.4pt;margin-bottom:.0001pt'>and that way they could describe
themselves as well</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:71.4pt;margin-bottom:.0001pt'>would it then be a huge leap to try
and correlate their internal state with external events???</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>&nbsp;</p>

<p class=MsoNormal style='margin-top:0in'>&nbsp;</p>

<p class=MsoNormal>see Smolensky on tensors + roles (re systematicity)</p>

<p class=MsoNormal>vampire bats social system/reciprocity???</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>most of our words depend on diachronic or synchronic
conditionals</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>e.g.</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>hunt = (agent1 cooperating/fighting
monster) AND (agent2 cooperating/fighting monster) etc.</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>escape = (monster chase agent -
past) AND (agent alive - now) AND (monster not chase agent  now)</p>

<p class=MsoNormal style='margin-left:17.85pt'>for this reason, tenses are very
important, and so is being able to take in more than one aspect of the
environment &#8211; it&#8217;s about <i>comparing states of affairs</i>, whether
past/present or here/there or him/me or whatever</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>that means having some sort of
short-term memory in which you can compare two (or more) aspects of the
external world &#8211; with almost_ all words, you can't rely on observables, either
because we&#8217;re talking about something that isn't happening right in front of
you right now, or because you want to convey <i>gossip</i>, or simply because
the word requires you to consider something other than a single obvious/simple
event/(2-place)relationship</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>the question is whether or not you
want to encode descriptions in this STM linguistically</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'>for instance, do you literally
define &#8216;kill&#8217; as &#8216;(creature2 alive &#8211; past) AND (creature1 fight creature2 -
past)&#8217;</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:71.4pt;margin-bottom:.0001pt'>although of course there has to be
something else about creature1 actually being the active cause of creature2
dying etc.</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'>or do you store the STM in something
more like the sensory-encoded-representation???</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>language is about discourse, interrogation, a constant,
continuous, flowing, conversant process</p>

<p class=MsoNormal>_____ how about adopting the LOTH, and using lang as the
means of communication tween modules???</p>

<p class=MsoNormal>_____ how about having two hemispheres which use it as a
protocol???</p>

<p class=MsoNormal>_____ how else can you understand questions???</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>more generic turing test</p>

<p class=MsoNormal>_____ see if it can learn/speak a given simple pidgin
faster/as well as a human</p>

<p class=MsoNormal>_____ see if it can learn a suite of unknown
games/rules/patterns as fast as a human</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>The proposal is that the acquisition of grammatical
relations occurs as a three-stage process. In the first stage a child learns
verb argument structures as separate, individual &#8220;mini-grammars&#8221;. This word is
used to emphasize that there are no overarching abstractions that link these
individual argument structures to other argument structures. Each argument
structure is a separate grammar unto itself. In the second stage the child
develops correspondences between the separate minigrammars; initially the
correspondences are based on both semantic and syntactic similarity, later the
correspondences are established on purely syntactic criteria. The transition is
gradual, with the role that semantics plays decreasing slowly.</p>

<p class=MsoNormal></p>

<p class=MsoNormal>In the third stage, the child begins to associate the
abstract arguments of the abstract transitive and intransitive constructions
with the coindexing constructions that instantiate the properties of, for
example, clause coordination, control structures, and reflexivization. So, for
example, an intransitive-to-transitive coindexing construction will associate the
S of an intransitive first clause with the deleted co-referent A of a
transitive second clause. This will enable the understanding of a sentence like
Max arrived and hugged everyone. Similarly, a transitive-to-intransitive
coindexing construction will associate the A of an initial transitive clause
with the S of a following intransitive clause; this will enable the
understanding of a sentence like Max hugged Annie and left. Since this
association takes place relatively late in the process, necessarily building on
layers of abstraction and guided by input, the grammatical relations (of which
S, A, and O are the raw material) &#8220;grow&#8221; naturally into the
language-appropriate molds. (Morris)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<h2><a name="_Toc7457556">Language arena</a></h2>

<p class=MsoNormal>I need an arena/environment in which my linguistic agents
can gambol - one where being able to effectively interpret, predict,
communicate and question about others' behaviour (beliefs, desires and
intentions) is particularly adaptive - they'll need at least one further
sensory modality, in fact, almost certaintly two - and a sense of space and
time, though it's possible that those emerge naturally out of the system</p>

<p class=MsoNormal>Why not give each agent semi-arbitrary/random digestive
systems/appetites and faculties/strengths, in a world full of different
obstacles/tasks, so that they have to work together to survive - the larger the
unit, comprising the more varied folk, the better. This will lead to speech
communities, which grow, where it would be optimal for them to aggregate
(babel-like) into one big one, but this will require them to learn to translate
between sub-specific speech communities since whenever a community dies out,
the skills lost will be automatically replaced but starting again from a random
point in the language-space</p>

<p class=MsoNormal>Do i need a second species??? I could have 2 species, which
cannot communicate at all whatsoever, which are designed to continually breed
to an asymptotic population maximum of the maximum the environment can sustain,
so the optimum is for one to die out completely</p>

<p class=MsoNormal>_____ - to each according to his needs and from each
according to their desires</p>

<p class=MsoNormal>To what extent will they be able to improve their physiology
of speech??? Specify in a (fairly) stable part of the genome sentence length,
word size etc. So that they get an advantage by using more complex sentences
and indeed need to use v complex sentences to be optimal in the environment,
but longer sentences are more tiring, and maybe require them to understand
place-holders - how can i ensure that the longer sentences correspond to more
generalising + powerful sentences???</p>

<h5>Possible tasks + problems requiring folk psychology + communication</h5>

<p class=MsoNormal>How about playing chess, but each agent can only see part of
the board??? No. That&#8217;s crap.</p>

<p class=MsoNormal>It has to be slightly strategic and require team-work</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:.25in;margin-bottom:.0001pt'>A maze, with parts accessible/passable/dangerous
to different agents</p>

<p class=MsoNormal>A team sport, or a battle/war (with territories to
occupy/protect)</p>

<p class=MsoNormal>It needs to be scalable, and to get more difficult to
coordinate with many people</p>

<p class=MsoNormal>Should they have limited range of earshot/visibility??? Will
it require trust, and have the potential for deception??? Yes, and altruism</p>

<p class=MsoNormal>The only things that can be affected by evolution are
language-related - speech production; syntactic construction + understanding;
listening capabilities; short-term linguistic memory</p>

<p class=MsoNormal>Must the language be discrete combinatorial??? Smaller
units, like in music, might be easier to evolve??? With harmonies, so that each
word is a much more complicated object, allowing simple sentence constructions
but comprised of many-overtoned-vocabulary</p>

<p class=MsoNormal>They will have to communicate about the external world as
well &#8211; position of good/bad things, routes + directions, order people to occupy
positions, landmarks, waypoints, common events, signal predators, warn of
danger</p>

<p class=MsoNormal>What if everyone has a slightly different hearing system, so
they can&#8217;t all communicate with each other, and require translators???</p>

<p class=MsoNormal>Better still, have a variety of populations, some of which
have complementary goals and can speak/hear at the same frequencies</p>

<h5>What senses will they have?</h5>

<p class=MsoNormal>Everyone&#8217;s senses will be different</p>

<p class=MsoNormal>Object position</p>

<p class=MsoNormal>Recognise objects + agents</p>

<h5>How can i make this applicable to the real world?</h5>

<p class=MsoNormal>Once i can always form a cohesive speech community, try
forcing populations to evolve towards human-like syntax (e.g.
Subject-object-verb)</p>

<p class=MsoNormal>Work towards being able to ask them questions and command
them about their world, using some sort of hybrid pidgin</p>

<h5>Forming representations and self-organising architectures</h5>

<p class=MsoNormal>Multi-modal competitive nets - lots of little competitive
nets, all working on one modality at once, and one big competitive net which is
fed them all at once, and which has bi-directional links with the little ones</p>

<p class=MsoNormal>What happens if you feed an autoassociator a lot of
variables at once for long enough - does it start to form its own categories
and archetypes, or do i need a competitive net to do that???</p>

<p class=MsoNormal>Can you have a pattern associator with hidden nodes???</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>yes, that's what backprop is</p>

<p class=MsoNormal>_____ feed a pattern associator all the info about a current
situation as training data as well as what happened after that - then when you
feed it current situational data, if the symbolic modules monitoring it thinks
it's sure enough about the resulting pattern associated, it can feed back its
prediction about what it thinks will happen</p>

<p class=MsoNormal>_____ if this works, then the hidden nodes of your
predictive pattern associator have formed an internal model!</p>

<p class=MsoNormal>_____ in order to do this, you need a suitably processed (by
this i mean 'relevant') input representation of the environment (geography,
food, shelter, weather, mating season etc., position of other
agents/prey/predators), the actions of other agents and the *internal states*
of the other agents (couched in the language of your own internal states???)
(possibly as well as of your own internal state) and you need a means of representing
the predictions - can you use the same combination of environment and
other-agent-internal-external representation ??? Yes, if the input
representation was good enough, you should certainly be able to use it as a
template for the output</p>

<p class=MsoNormal style='margin-left:17.85pt'>if you have a good internal
model of how your own body will respond to a given situation, you can just copy
that module and just feed in input about <i>other</i> agents to form a model of
<i>their</i> internal states</p>

<p class=MsoNormal>You may need a meta-representation of your own internal
states to use as part of your template for the internal states of other agents</p>

<p class=MsoNormal>_____ eventually, the hope is that all the agents will
evolve to voice their own internal states so that the other agents can more
easily form representations of each other's internal states, by correlating
'hungry' with eating food soon after</p>

<p class=MsoNormal>_____ how do you base one representation on another???
Simply copy its organisation and then feed it new data??? Teach it from
scratch???</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>There are lots of things we don't yet know how to do in
connectionist terms but which we have no a priori reason for thinking cannot be
done - why not just use symbolic modules as placeholders in the interim???</p>

<p class=MsoNormal>_____ this is the logic behind backprop nets - in fact, it
may make sense to use backprop modules instead of symbolic modules a lot of the
time</p>

<p class=MsoNormal>_____ now, let's say i've got a backprop net doing a vital
job in my network and i want to move towards biological plausibility - what can
i do??? Am i stuck with it??? It's learned a bunch of weights - i could encode
them in the genome i spose, but that's no fun...</p>

<p class=MsoNormal style='margin-left:17.85pt'>perhaps I could encode some of
the weights in the genome, and figure out different ways of encoding it more
efficiently &#8211; but I might have to do that externally and then artificially
graft it back into my experiment</p>

<p class=MsoNormal style='margin-left:17.85pt'>&nbsp;</p>

<p class=MsoNormal>It may be that having a symbolic module will be most useful
in memory-related functions</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>I shouldn't be too upset at having to make backprop nets
integral to my design, given that i was inspired in the first place by the idea
of chaining lots of them together, and it may be that i can somehow encode
their organisation in compressed form in the genome, perhaps by getting a
pattern associator to look at a report of their inputs/outputs/connectivity
after the event???</p>

<p class=MsoNormal style='margin-left:.25in'>Better still, i could sort out a
working agent, then keep everything else static, and figure out how to grow
that function using biologically plausible genetic/developmental tricks</p>

<p class=MsoNormal style='margin-left:.25in'>Is there any evidence against the
idea that early early animals specified connectivity at a pretty low level in
the genome???</p>

<p class=MsoNormal>Why not go for super-plasticity &#8211; when you want to try and
predict something, you generate a whole load of new spaces (mostly based on
groups you have for representing things) and try them all out and see which
one(s) is best for the new thing you want to represent, and just keep that one</p>

<p class=MsoNormal style='margin-left:.25in'>Why not go for a lamarckian system
&#8211; if you find a good representation, use a meta-nn to encode it in your genome
and all your descendants will have it</p>

<p class=MsoNormal style='margin-left:.25in'>This is the advantage of using
your genome to structure your agent. The hard part is figuring out how your
meta-nn can encode/compress it into the genome</p>

<p class=MsoNormal style='margin-left:.25in'>Having said that, you can have
quite a flexible genome &#8211; it can contain explicit, specific, weight-by-weight
(user-hand-coded or self-copies of a self-organised module) connectivity, a
broad connectivity formula, a spatial location from which to grow, parameters
for basic architectures (e.g. 5-output competitive net etc.), prewired timing
for flowering and pruning, a complete training set (fuck it, why not!),
backprop, symbolic modules, copies of working modules to that don&#8217;t start to
grow until adolescence, the types/properties of that group&#8217;s neurons</p>

<p class=MsoNormal style='margin-left:.5in'>How are the broad connectivity
formulae going to be encoded in the genome???</p>

<p class=MsoNormal>&nbsp;</p>

<h5>Misc</h5>

<p class=MsoNormal>I reckon that language piggybacks, like the tip of an
iceberg, on top of a whole host of perceptual + cognitive systems. Surely
though, all it really needs is the various outputs (and intermediate processing
levels in some cases too), which it can form together. After all, what&#8217;s so
different about language from any other abstract, multi-modal representation
(based on the same information)??? (this is why i&#8217;m happy to try and play
around with language without having solved every other lower level problem
first)</p>

<p class=MsoNormal style='margin-left:.25in'>Well, it&#8217;s defined in terms of the
type of output it needs to produce, which is defined by its function -
communication.</p>

<p class=MsoNormal>You can kind of imagine how a speech community will form.
They&#8217;ll be wired up to spontaneously produce sounds to begin with (kind of like
babies going &#8216;ga-ga&#8217;), especially in response to things. The early generations&#8217;
genome will be designed to produce probably one-word utterances. But they&#8217;ll
simultaneously be listening out for other people&#8217;s, especially if they
correlate with their own, and when that happens, they&#8217;ll look to see what was
going on in the world when they both said the same thing. This will lead to
speech communities formed around the same sensory system &#8211; ok, well then, we&#8217;ll
have to make sure that even if they have different
limbs/abilities/strengths/intelligences and different needs/desires/appetite
levels, they still share senses. Indeed, this makes sense. This is what quine
was talking about with observation sentences again.</p>

<p class=MsoNormal style='margin-left:17.85pt'>it makes especially sense if the
babbling is somehow (a little bit) systematically linked to their internal
state or sensory input or something, e.g. perhaps we&#8217;re wired up to squeal when
we&#8217;re in sudden pain which could be conventionalised into a word for pain like
&#8216;ow&#8217; </p>

<p class=MsoNormal>The problem it looks as though they&#8217;ll come up against at
every stage of language learning + building is how the community (or really
even just two &#8211; or even one??? - individuals) agree on a new
definition/structure, e.g. If they start uttering just one word, how will they
move to 2 words (with different parts of speech, say)???</p>

<p class=MsoNormal style='margin-left:.25in'>Perhaps the idea of words as
harmonies will help here, because then you can associate both (simultaneous)
sounds with the same event</p>

<p class=MsoNormal style='margin-left:.25in'>In this case, they won&#8217;t be so
much words as parallel (rather than serial/sequential) sentences</p>

<p class=MsoNormal style='margin-left:.25in'>Kind of like a huge multi-morpheme
word or a german compound noun</p>

<p class=MsoNormal style='margin-left:.25in'>In fact, is there any difference
between harmonies and adding morphemes to a stem??? Well, suffixes, prefixes
and infixes tend to contain less meaning than whole other words</p>

<p class=MsoNormal style='margin-left:.25in'>However, they do allow for more subtle
changes, rather than inventing a whole new word/harmony line, you can just move
a tiny bit in conceptual space (e.g. By changing the part of speech of a word
but retaining its semantic significance, e.g. Greg<span style='font-size:10.0pt'>/</span>greg&#8217;s,
high<span style='font-size:10.0pt'>/</span>height)</p>

<p class=MsoNormal>Part of what we&#8217;re investigating here is the idea of a
conceptual scheme, and how relativised to our sensory system this is.</p>

<p class=MsoNormal>Should i accept that i&#8217;m trying to do way too fucking much,
especially with the whole folk psychology thing, societies and trust, and
fucking language on top of it all</p>

<p class=MsoNormal>I could throw in a helpless not-very-bright
evolutionarily-static symbiotic population who can&#8217;t fend for themselves very
well but are necessary in the ecosystem in some way, so the agents have to
learn to protect and care for them &#8211; and this may ultimately require
communicating with them &#8211; and these agents will use human words like &#8216;food&#8217; and
&#8216;hungry&#8217;</p>

<p class=MsoNormal style='margin-left:.25in'>So by giving the helpless
symbiotic species more and more human-like vocab and grammar, we can build an
intertranslatory bridge to the agents&#8230; and the beauty is that they&#8217;ll be
translating into <i>our</i> language&#8230; but they won&#8217;t be innovating in our
language &#8211; how do i make them switch themselves permanently to english over
time???</p>

<p class=MsoNormal style='margin-left:.25in'>The problem is that even if they
learn words like &#8216;food&#8217; and &#8216;pain&#8217;, we can&#8217;t use the same techniques for really
teaching them english, because if we embody them in the real world we won&#8217;t be
able to use massive populations being selected for linguistic competence as the
drive to learn the language any more</p>

<p class=MsoNormal style='margin-left:.25in'>Unless you could use the a-life
simulation to put them in lots of different environments, growing more and more
similar to the real world, and forcing them to learn lots of languages and be
good at it and enjoy it and develop a reward system for learning new languages,
while making the helpless symbiotic population use more and more advanced
english (of course, this will have to be pre-programmed)</p>

<p class=MsoNormal style='margin-left:.5in'>Even with a limited training set,
they might conceivably be able to generalise basic human (&lt; 5 word) syntax,
on the basis of different constructions with the same meaning (e.g. &#8216;i am
hungry&#8217;, &#8216;greg is hungry&#8217; and &#8216;i want food&#8217;)</p>

<p class=MsoNormal style='margin-left:.5in'>This requires a really fucking high
level module that abstracts away from the actual sentence construction used to
its <i>meaning</i></p>

<p class=MsoNormal style='margin-left:.5in'>We&#8217;re back to minsky&#8217;s idea of
meaning as a multi-faceted representation (that feeds back on itself, e.g.
Using our output representation as input representation???)</p>

<p class=MsoNormal>How are they going to output sequences of words, i.e.
Sentences??? Will they have a fixed number of word output slots/sentence???</p>

<p class=MsoNormal>Perhaps they will need some sort of auditory stream that
they have to disambiguate, forcing them to parse the speech input data in some
way, form multiple possible trees, and choose the most likely one???</p>

<p class=MsoNormal>&nbsp;</p>

<h5>Birdseedland</h5>

<p class=MsoNormal>so-called because of the adverts with squirrels doing
mammoth obstacle courses to get the birdseed</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>imagine them being placed in front of arches, in groups -
pressing the red square opens the door, pressing the blue one lets them escape,
pressing the green one reveals the red one etc - perhaps they have to do them
in sequence, or at the same time, requiring them to cooperate with each other</p>

<p class=MsoNormal>_____ perhaps there are occasionally predators, and one has
to be on guard to let them all flee in time</p>

<p class=MsoNormal>_____ or they could be on a train with these test-arches
passing by - maybe this is a way of avoiding space, but keeping time - perhaps
some of them have restricted time-limits and so they have to be in place
beforehand</p>

<p class=MsoNormal>_____ how can i visualise what it would be like to have no
spatial sense - think back to strawson's auditory Hero</p>

<p class=MsoNormal>_____ if some of them can't see the whole arch, then they'll
need to question/communicate what they do see, and come up with a plan</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>alternatively, the agent could be replicated before being
allowed to practise with the arch for a while, then it has to communicate to
its ignorant self what to do</p>

<p class=MsoNormal>the problem is that all this shit requires it to learn words
associated with each object, and actions, questions, causation big-time, and
the need to communicate it to its mate as well as figuring out the necessary
sequence - TOO HARD, and it's not even considering space - how am i ever going
to get rid of causality??? perhaps it's just part of a minimum-iceberg, esp. if
all the other bits have been excluded too - after all, if you haven't got a cognitive
iceberg at all, then literally all you have is stimulus-response/associative
conditioning, which we all know can't do the job</p>

<p class=MsoNormal>if i replace NN bits with symbolic algorithms, what do i
lose??? after all, they can be plugged back in, and back-project their results
and stuff. but they don't learn. but i don't know how to get big cognitive NN
modules to learn goals and stuff anyway, so ...</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>i'm worried that maybe i'm going to have problems teaching
them nouns from day one - cos if i say 'redsquare' to them every time they see
a redsquare, and reward them for babbling 'redsquare' back, will they continue
to do that without the prompt??? let's say the anwswer is yes. if i still
reward them when they say 'redsquare' every time they see one, without the pre-emptive
voice prompt, that's cheating, but maybe necessary. anyway, they learn the
words for 5 different objects like that. maybe i also need to teach them to say
'redsquare' and press it at the same time somehow. ok. somehow. no no no, it's
all confused, about learning the name for it, learning to press it, learning
the name to press it, learning to produce that name for it etc. how about if
their motor system has a bunch of different pre-programmed options, including
:say 'redsquare', press the red square, say 'press' etc. then i teach them
'press redsquare' and 'say redsquare' as different actions for the same object.
wahey!</p>

<p class=MsoNormal>ok, so imagine the arch is a birdseed cage (reward), and it
has buttons and levers that have to be pressed</p>

<p class=MsoNormal style='margin-left:17.85pt'>they have hardcoded motor
options</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>should these hardcoded options be at
the level of full sentences, e.g. a command to &#8216;press the red button&#8217; or should
they be a program comprised of commands to &#8216;action-press&#8217; &#8216;object-redbutton&#8217;???</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>maybe try the latter &#8211; that would be
better, and it would probably be better because it would nudge it towards a
combinatorial cognitive representation, but it would probably be much harder</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>maybe getting semantic roles to emerge would all be much
easier with just a whole series of example sentences</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>e.g. &#8216;boy see girl&#8217;, &#8216;boy kiss
girl&#8217;, &#8216;girl slap boy&#8217; etc.</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>what more does my approach offer???
well, questions, much more interesting (and sort of naturalistic) environment,
emergence of language within a community (does it though???)</p>

<p class=MsoNormal><span style='layout-grid-mode:line'>&nbsp;</span></p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>use language in front of doors correctly &#8211; like a key &#8211; to
get the food inside</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>the community version requires 90%
to agree on their convention-agreed arbitrary word</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>e.g. be shown an object, an event
etc.</p>

<p class=MsoNormal style='margin-left:17.85pt'>something like the dolphins
instructing each other within earshot but no line of sight in separate tanks on
how to use the mechanism so that the instructor gets fed</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>requires a complicated motor system</p>

<p class=MsoNormal>eventually the agent might come to identify itself with
agents in the video-questions &#8211; perhaps it&#8217;s the other way round &#8211; it comes to
identify the agents with itself and that&#8217;s how it&#8217;s able to understand <i>their</i>
actions, relative to its own&#8230; </p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>give it a one-dimensional representation of space &#8211; i.e. it
can choose to progress forwards (harder) or backwards &#8211; perhaps automatically,
it&#8217;ll bobble about and then as it gets better it&#8217;ll go forwards</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>e.g. going uphill on a road, getting
things right gives it energy, getting them wrong makes it fall back down, with
these as birdseedcage puzzles by the wayside</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>kind of like a bunch of ribena berries
floating inside a thermometer &#8211; as they get more successful they rise higher</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>combine the best elements of all the ideas: how about I have
a community progressing together, with a designated leader who does the
babbling, and his babbling is a systematic version of his sensory
representation of the puzzle-environment</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>it will mean keeping the leader
constant throughout &#8211; so how does he improve??? perhaps not a leader, just a sort
of sound-to-light that they use like a metronome to keep in unison</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>no, because the leader won't have
syntax for them to learn from</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>how about if each agent is already a
network trained with basic syntax to be systematic about SVO and question
constructions??? using the vocab in their world??? so they&#8217;re used to forming grammatically
correct sentences, and now I&#8217;m placing them in a situation where they have to
learn to deploy them correctly in situations (i.e. semantically) to achieve a
(hard-wired) goal&#8230; </p>

<p class=MsoNormal style='margin-left:35.7pt'>e.g.</p>

<p class=MsoNormal style='margin-left:53.55pt'>Jim is-there</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'>lever is-there/out-there
(information statement)</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'>lever this-colour blue (information statement)</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'>button this-colour green (information
statement)</p>

<p class=MsoNormal style='margin-left:53.55pt'>I pull lever (action-done statement)</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'>Jim toggle yellow switch (action-done
statement)</p>

<p class=MsoNormal style='margin-left:53.55pt'>you push red button(! imperative)</p>

<p class=MsoNormal style='margin-left:53.55pt'>this-colour lever(?) OR lever
this-colour(? question)</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'>is-there button(?)</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'>you pull lever(?)</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'>&nbsp;</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>information = action-done &#8211; both are
statements about the world</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>might as well stick with SOV order,
and just add punctuation at the end</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>how will it be able to manage a green
button and a red button together???</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>to begin with, there&#8217;ll be no voice
in the head, but all the other critters will be algorithmic-teachers</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>if I&#8217;m forced to use a symbolic core
that figures out that it needs to know what colour the button is etc. then how
will the language centre know to ask that question??? basically, how is the
memory/central-system going to interface with the communication system??? this
feels like a central question</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>perhaps I could get it to learn
about questions by showing it a blank object, and rewarding it for saying the equivalent
of &#8216;what?&#8217; &#8211; but how do I get it to know to ask a question, or to try different
words??? I have to feed it the right one first &#8211; ok &#8211; how do I get it to store
information, since after all, it can't be expected to understand the concept of
question until it has states of ignorance and knowledge</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>how about giving place-names, so that
I can then ask it &#8216;what&#8217;s at place A?&#8217;??? we could start by touring up and down
a bit, associating place-names with position in 1-D space, then start to
elaborate on the place-names with descriptions, and somehow get it to supply
the descriptions when fed &#8216;place-name-X + question-mark' and vice versa</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'>this is kind of the same as showing
it &#8216;red button&#8217;, &#8216;green lever&#8217;, &#8216;red lever&#8217;, &#8216;green button&#8217; etc. to get
systematicity between adjective + noun, then showing it a green button and
saying &#8216;button?&#8217; &#8211; yes yes yes, what you&#8217;re then doing is rewarding it for
making the association between &#8216;button?&#8217; and it&#8217;s sensory/context
representation of the green button</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'>how do you get this bidirectionality
though??? you can get bi-directional auto-associators, e.g. between name and
phone number where you feed one and it responds with the other &#8211; that&#8217;s not
enough though &#8211; we want it on a much larger, systematic scale &#8211; and massively
multi-modal</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'>in effect, place/colour/object-type
represent different modalities &#8211; the plan was for the modalities to give
complete information together, but only incomplete information in isolation &#8211;
is this what is happening??? does the above plan develop the kind of
cross-modla correlations I had in mind???</p>

<p class=MsoNormal>I could have a GA and a fitness function even though I&#8217;m
running these agents through the gauntlet one-by-one/sequentially</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>the central decision-making module could be twin- (i.e.
multiple)-draft:</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>an experimental try-anything
symbolic module which only kicks in when the others don&#8217;t have a confident-hypothesis
(how do I measure how confident it is &#8211; how quickly it settles???)</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>reinforcement learning, which gets a
reward for right actions and a punishment for wrong ones</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>a pattern-associator/backprop which continually
associates all its sensory knowledge + chosen action with resulting outcomes</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>perhaps it could be wired up in a
feedback loop or something to the try-anything module as a kind of hypothesis
generator cum internal/predictive model???</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>this is interesting, because it breaks
down the distinction between memory/past-experience and prediction/decision</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>a competitive net which tries to
categorise types of situation (???)</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>no, better still, a Kohonen net to
show how similar two situations are</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>initially, a teacher module (which
could one day be taken over by another agent to actually allow them to teach
each other, wahoo) could control it by forcing it to do the right things in the
first few situations, so that the reward + pattern associator get the right
idea &#8211; there may be no need for this, if there&#8217;s a punishment for the wrong
actions &#8211; that&#8217;s the whole point of self-organisation</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>will there have to be some sort of
comparator overseer module which takes a look at the predictions and hypotheses
of all the models and rates then chooses one</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>will the ling channel hear its own voice??? probably not</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>might that be necessary for it to
identify itself as just another voice-agent??? I think not. and even if so,
it&#8217;s not important that it does identify itself as being like the others. real
sense of self is unimportantly blue-sky/high-level</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>if you have really passive other-agents, then it&#8217;s kind of
like a single collective-agent communicating by language between internal systems
(perceptual to central and questioning back to perceptual and central
commanding motor)</p>

<p class=MsoNormal>having said that, if they&#8217;re more active, then the
discourse/question/imperative thing makes more sense</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>if you add in &#8216;pressed&#8217; and &#8216;unpressed&#8217;, &#8216;lever-up&#8217; and &#8216;lever-down&#8217;
etc. then you get causality</p>

<p class=MsoNormal>interestingly, the parallel linguistic channel basis I&#8217;ve
been imagining makes a sensory apparatus redundant</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>it also makes the idea of questions
easier, because you just put a question mark in the slot where you&#8217;d normally
have information, e.g. &#8216;[colour]___? button&#8217; &#8211; and it fits in which Chomsky&#8217;s
transformational gaps too</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>but does it commit me to slots??? I
want the ling channel to be sequential and stored/encoded/compressed in a growing/parallel/non-sequential
context-memory somehow</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>there&#8217;ll be a need for some sort of reset/full-stop function</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>the way to think about the 2 stages of:</p>

<p class=MsoNormal style='margin-left:35.85pt;text-indent:-.25in'>1.<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp; </span>purely linguistic/syntactic
data, i.e. lots of grammatically correct sentence examples, of statement,
imperative + question types</p>

<p class=MsoNormal style='margin-left:35.85pt;text-indent:-.25in'>2.<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp; </span>situations
where those sentences are given meaning, where the 3 different types of sentence
are needed to solve the birdseed puzzles</p>

<p class=MsoNormal style='margin-left:17.85pt'>as being kind of
genetically-coded to restrict the incoming information so that it can be
processed in bite-size chunks initially, as appears to happen with infants &#8211; at
first they only hear the motherese-prosody-emphasised words, apparently</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>what about problems that require multi-step solutions???</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>more than one context memory??? or
represent different steps in parallel???</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>you do need the sensory information rather than just the
ling channel</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>why???</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>can you have meaning without any
environment to anchor the words onto???</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>even without sensory input, you&#8217;re
still building up an understanding of what the words mean, because their relation
to each other is not just determined by syntax, it&#8217;s determined by some outside
world &#8211; even if this meaning runs over sentences, rather than within them</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>the outside world is being
represented internally, conveyed and altered and re-conveyed by the ling conversation</p>

<p class=MsoNormal style='margin-top:4.0pt'>in a way, the ling channel is here
being allowed to play both a motor + a sensory role</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>the role of language is
communication, yes, but it&#8217;s not meant to be the sole means of accessing the
outside world</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>is it a problem if it is???</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>it&#8217;s supposed to be for things like
conveying gossip, that help, but aren't integral</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>y, but the point is that I&#8217;m trying
to strip things down to the linguistic minimum&#8230;</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<h5>Chatterboxes</h5>

<p class=MsoNormal>what would happen if we differentiate between explicit and
implicit knowledge?</p>

<p class=MsoNormal>is fractal thicketing viable/important?</p>

<p class=MsoNormal>do we really want to start categorising knowledge into
person/place/thing/motive/modality relationships?</p>

<p class=MsoNormal>can a syntax-only grammar-parsing chatterbox get anywhere?</p>

<p class=MsoNormal>what are the various ways for storing knowledge?</p>

<p class=MsoNormal>what do we mean by knowledge (here, in the AI sense)?</p>

<p class=MsoNormal>what does the erasmatron have to offer (me)?</p>

<p class=MsoNormal>how can I just feed it Britannica/Shakespeare and see what
it comes up with?</p>

<p class=MsoNormal>will first order predicate logic work?</p>

<p class=MsoNormal>what about Hofstadter&#8217;s research into analogies/creativity
etc.?</p>

<p class=MsoNormal>&nbsp;</p>

<h5>Multi- step/-component model of learning</h5>

<p class=MsoNormal>(kind of analogous to a more messy version of the scientific
method)</p>

<p class=MsoNormal>two modules, that interact to produce improving behaviour
based on a predictive world model in an unknown domain through trial and error:
</p>

<p class=MsoNormal style='margin-left:35.85pt;text-indent:-.25in'>1.<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp; </span>predictive/world
internal model</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'>this builds up a model of what
happens, associating circumstances (internal + external) + decisions with
outcomes</p>

<p class=MsoNormal style='margin-left:35.85pt;text-indent:-.25in'>2.<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp; </span>response/action
random/hypothesis generator</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'>this uses the world model as
teaching input/reward</p>

<p class=MsoNormal>thus as its world model improves, it chooses more optimal
behaviour</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>this leads to exploring the world in
a more optimal fashion, and so </p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>teaching the next generation (in a
GA simulation) would presumably be vital to ensure that behavioural optimality
doesn't hit the ceiling imposed by life-span</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>how do you program in the ability to
learn from parents???</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'>predisposition to imitation???</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:71.4pt;margin-bottom:.0001pt'>besides being inelegant and
non-self-organised, it would be pretty difficult to hand-code
connectionistically</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:71.4pt;margin-bottom:.0001pt'>if you can somehow get it to recognise
its parents very early (e.g. imprinting), can you somehow prioritise their actions,
or incorporate their decisions + outcomes as part of your own world model&#8217;s
training set</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:89.25pt;margin-bottom:.0001pt'>see the bit about filtering
different types of inputs to the internal model</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:89.25pt;margin-bottom:.0001pt'>&nbsp;</p>

<p class=MsoNormal>thus, it improves its world model on the basis of its
improving behaviour</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>random problems/thoughts about the choice generator:</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'>see Thaler and the two-part creatitivity
machine</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:71.4pt;margin-bottom:.0001pt'>since his machine isn't intended to
interact with or react to the environment, it doesn't have to have an internal
model of that environment, except as part of the evaluator&#8230; hmmm, is this
right???</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:71.4pt;margin-bottom:.0001pt'>oh yeah, he feeds his hypothesis
generator noise to make it &#8216;dream&#8217;/produce creative new ideas &#8211; no, he actually
fiddles with its synapses (as well???0</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:89.25pt;margin-bottom:.0001pt'>what was Rolls&#8217; response to whether
or not there is a suitable means of producing noise in the brain??? what did
Rolls want the noise for??? something to do with his 7-part computational model
of vision???</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:71.4pt;margin-bottom:.0001pt'>how does he train the evaluator
net??? is it just an uncorrupted version of the first??? </p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>random problems/thoughts about the internal world model:</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>needs to abstract extraneous details
(which will presumably happen automatically since they will vary contingently
between circumstances/decision/outcome) so that you can feed in a possible
choice to see what will happen</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>will this help with
counterfactuals??? presumably, if you can convince the thing to start thinking
in those terms &#8211; no, it will do that automatically, so if you can start to
figure in a linguistic element (i.e. an utterance) in, along with an internal
model of others&#8217; internal states, then it will automatically predict the
outcome of it saying something to another agent that has certain beliefs, and
so lies will simply be a useful way of behaving (after all, there&#8217;s no
important distinction made between truth and lies if all you&#8217;re doing is
seeking expedient communication)</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>this might also be a means of
generating reasons for behaviour, since it will be able to explain why it did
something in terms of alternative actions that it avoided because of their
outcomes</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>this is <i>one</i> type of reason &#8211;
what other types are there??? (see &#8216;reasons and causes&#8217; in Oxford Companion in
thesis)</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'>what about reasons <i>for</i> doing
something???</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>it can either be fed sensory input,
or a hypothesis behaviour to test for evaluation</p>

<p class=MsoNormal style='margin-left:17.85pt'>when learning to begin with, it
may need a very high &#8216;k&#8217; (learning rate) to rapidly structure its knowledge
space broadly, and then &#8216;k&#8217; can be slowly decreased so that new knowledge
doesn't completely outweigh old experience (i.e. momentum, as in backprop)</p>

<p class=MsoNormal style='margin-left:17.85pt'>the predictive model may require
a backprop algorithm &#8211; is it&#8217;s learning space likely to be linearly
separable???</p>

<p class=MsoNormal style='margin-left:17.85pt'>if you wanted to know why
another agent did something (its reasons), how would feed the internal model
the decision and the circumstances and ask it to spit back out the other
agent&#8217;s internal state???</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>this is going to require some sort
of filter that can feed the internal model 3 different types of information:</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>one&#8217;s own sensory information</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>hypothesised/random generated choices
(+ memories &#8211; why???) to be evaluated when choosing the most optimal behaviour
(as decided by the agent&#8217;s internal model)</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>processed sensory information that
represents the world from the parent/other agent&#8217;s perspective (this may be
very hard, comign after everything else)</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>moreover, the internal model needs
to know not to learn from its own hypothesised actions</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>aha &#8211; oops &#8211; I&#8217;ve missed out the
evaluator module that presumably just wouldn't feed it any reward/punishment
for hypothesised actions (although it would have to evaluate them in order to
choose between them)</p>

<p class=MsoNormal style='margin-left:17.85pt'>how do you get the internal
world model to organise its own means of representing the world (internal +
external)???</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>eventually allow the GA to determine which
of the total sensory + internal states it uses as its input</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>will there be a problem in
associating initial + resulting world states as the input + output???</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>revised model</p>

<p class=MsoNormal><span style='color:blue'>this is still very confused &#8211;
haven't figured out how the triumvirate really relate to each other properly&#8230;</span></p>

<p class=MsoNormal><span style='color:blue'>need to synthesise the thoughts
about language somehow eventually as well</span></p>

<p class=MsoNormal style='margin-left:35.85pt;text-indent:-.25in'>1.<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp; </span>predictive/world
internal model</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'>associates:</p>

<p class=MsoNormal style='margin-top:2.0pt;margin-right:0in;margin-bottom:0in;
margin-left:71.4pt;margin-bottom:.0001pt'>initial external/environmental circumstances</p>

<p class=MsoNormal style='margin-top:2.0pt;margin-right:0in;margin-bottom:0in;
margin-left:71.4pt;margin-bottom:.0001pt'>internal state</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:89.25pt;margin-bottom:.0001pt'>health/hunger etc.</p>

<p class=MsoNormal style='margin-top:2.0pt;margin-right:0in;margin-bottom:0in;
margin-left:89.25pt;margin-bottom:.0001pt'>its own decision (that&#8217;s been
made/being proposed)</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:107.1pt;margin-bottom:.0001pt'><span style='font-size:9.0pt'>eventually,
includes its own internal model???</span></p>

<p class=MsoNormal style='margin-top:2.0pt;margin-right:0in;margin-bottom:0in;
margin-left:71.4pt;margin-bottom:.0001pt'>other agents&#8217;</p>

<p class=MsoNormal style='margin-top:2.0pt;margin-right:0in;margin-bottom:0in;
margin-left:89.25pt;margin-bottom:.0001pt'>behaviour</p>

<p class=MsoNormal style='margin-top:2.0pt;margin-right:0in;margin-bottom:0in;
margin-left:89.25pt;margin-bottom:.0001pt'>internal states (hypothesised or as communicated)</p>

<p class=MsoNormal style='margin-top:2.0pt;margin-right:0in;margin-bottom:0in;
margin-left:89.25pt;margin-bottom:.0001pt'>etc.</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:71.4pt;margin-bottom:.0001pt'>evaluation of the current world state</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'>with:</p>

<p class=MsoNormal style='margin-top:2.0pt;margin-right:0in;margin-bottom:0in;
margin-left:71.4pt;margin-bottom:.0001pt'>the results represented in the same way</p>

<p class=MsoNormal style='margin-top:2.0pt;margin-right:0in;margin-bottom:0in;
margin-left:71.4pt;margin-bottom:.0001pt'>long-term outcomes???</p>

<p class=MsoNormal style='margin-left:35.85pt;text-indent:-.25in'>2.<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp; </span>response/action
random/hypothesis generator</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'>starts off randomly generating ideas</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'>just a little NN that somehow learns
which ideas the world model likes best as a means of mainly proposing vaguely likely
ideas</p>

<p class=MsoNormal style='margin-left:35.85pt;text-indent:-.25in'>3.<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp; </span>evaluator</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'>evaluates the current world state
(either in terms fixed by a definite goal, or according to internal state, or intermediate
goals&#8230;???)</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:53.55pt;margin-bottom:.0001pt'>is used as a reward/teaching input
to the action-generator</p>

<p class=MsoNormal style='margin-left:35.85pt;text-indent:-.25in'>4.<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp; </span>language
centre</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>are the evaluator and generator (or any two of the main triumvirate
of components) the same thing??? no, I don't think so</p>

<p class=MsoNormal>presumably, you could break up your world model into
components by having lots of little associators</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>each gets fed a compressed/encoded
version of the entire world state as well as the particular aspect of the world
it&#8217;s trying to model, and seeks associations between them</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>the big world model syntheses all
these component models to produce a prediction that can emphasise a particular
aspect of the world</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>moreover, presumably, it will be more
tolerant of missing aspects of the model</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:35.7pt;margin-bottom:.0001pt'>would it then also be easier to fill
in specifically those missing bits, e.g. other agents&#8217; internal states</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>building the model of other agents&#8217; internal
states can start off being based on your own, surely (cf the simulation theory
of folk psychology &#8211; do I discuss this elsewhere???)???</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>the evaluator is actually quite problematic</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>how do you train it??? does it need
hard-coded (by the programmer or GA) basic/primary goals (e.g. find food, avoid
harm etc.)??? how does it form its own intermediate goals??? especially when
those intermediate goals will be based on very long-term outcomes??? how will
it be able to tell that a given long-term outcome was the result in particular
of one among many factors??? how is it implicated in multi-step actions/behaviour???</p>

<p class=MsoNormal>&nbsp;</p>

<h2><a name="_Toc7457557">Unsorted</a></h2>

<p class=MsoNormal><span style='layout-grid-mode:line'>what effect does
evolutionary epistemology have on the idea of a computer having knowledge?</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>&nbsp;</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>need for stages -
understanding, learning/processing/comprehending/assessing/etc., replying</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>&nbsp;</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>the order i feed it information
should/will matter - so if i teach it regular verbs first, then irregular, and
expect initial over-regularisation and then to settle down into acceptance of
effectively 2 routes (rules/lexical) - can a NN model implictly have 2 routes?</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>&nbsp;</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>feature satisfaction</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>&nbsp;</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>how can i pass a
primitive data type reference to a method - that's the point - i can't - it
returns something, which can be the resultant change of a primitive type
variable, but it only permanently alters that one returned value - none of the
(instance) variables it might use in its processing are permanently affected</span></p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal><span style='layout-grid-mode:line'>could i write a v cool
database (applet) in java, so that it could be seen on any computer (with a
java compiler), perhaps ported to PDAs and other platforms (eg Mac), altered by
many users simultaneously, minimal system resources overhead (?)</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>or would it be easier to
write in access?</span></p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>gfind &quot;linear algebra&quot; in academic not in reading
of author</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>in a sense, there&#8217;s no need to prove that artifical minds
are conscious &#8211; gradually perceptions will change, people become more
open-minded, the idea become less ludicrous, indeed the idea that they don&#8217;t
will be considered ludicrous, as their clearly minded-seeming behaviour becomes
prevalent and evident</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>in Rethinking Innateness, why don&#8217;t we try coupling a
network which has learned the phonotactic rules of english with the past tense
network???</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>why are some thoughts harder than others???</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>I need to seriously consider my idealised domain of choice &#8211;
perhaps even design it myself</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>what is a functionalist??? is it someone who thinks that the
computation gives rise to consciousness??? how is that different to a monist
materialist??? and if so, how can functionalists be so certain that it is just
the computation going on in our brain and not our body that matters &#8211; indeed,
how can they be sure that it is not the computation going throughout the
universe that gives rise to their consciousness and sense of self???
functionalism <span style='font-size:10.0pt;font-family:Symbol'></span>
panpsychism&#8230;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>to what extent is the brain a formal system??? what&#8217;s a
formal system &#8211; anything that can be captured by a Turing machine</p>

<p class=MsoNormal>if I wanted to design a program that sought mathematical
proofs and interesting quirks, like Lenat&#8217;s, couldn&#8217;t I evolve a creature that
looks for them in its environment, whose fitness function depended on its
success at mathematically modelling and predicting formalisms in the world
around it???</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:.5in;margin-bottom:.0001pt'>maybe, but isn&#8217;t that what a NN is
implicitly doing anyway??? and the difficult bit would be getting it to express
it in a meaningful, and <i>symbolic</i>, way.</p>

<p class=MsoNormal>is Marvin Minsky still pursuing true symbolic AI??? is
anyone??? what is it??? why do they bother???</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>how useful is this high-level/symbolic/black-box AI stuff to
connectionists??? I spose eventually it might inform what sort of systems and
constructions to look for and model in the brain</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Sunpaq vampiric computers which you can&#8217;t unplug from
yourself leeching away your lifeforce after bio-plugs were invented &#8211; &#8216;teaming
yourself with your laptop&#8217; &#8211; all about human/machine relations</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>wet/dry interfacing</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>conceiving matter as energy then makes it much easier to
think of experiential content as being material&#8230;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal align=left style='text-align:left'>what would happen if we
differentiate between explicit and implicit knowledge?</p>

<p class=MsoNormal align=left style='text-align:left'>is fractal thicketing
viable/important?</p>

<p class=MsoNormal align=left style='text-align:left'>do we really want to
start categorising knowledge into person/place/thing/motive/modality
relationships?</p>

<p class=MsoNormal align=left style='text-align:left'>can a syntax-only
grammar-parsing chatterbox get anywhere?</p>

<p class=MsoNormal align=left style='text-align:left'>what are the various ways
for storing knowledge?</p>

<p class=MsoNormal align=left style='text-align:left'>what do we mean by
knowledge (here, in the AI sense)?</p>

<p class=MsoNormal align=left style='text-align:left'>&nbsp;</p>

<p class=MsoNormal>can i imagine how matter might be different and so help with
the mind-body problem (a la Penrose and Nagel)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>that's why evolution is where the progress in AI is to be
made - in future times, we will pity the beavering AI researchers and
philosophers of mind because we will realise that they did not have the
resources:</p>

<p class=MsoNormal>(funny unexpected radically different laws of physics that
give the materialists whole new territories and means of understanding the
mind-body (e.g. quantum mechanics and panpsychism, hugely powerful new
computers possibly with massively parallel processing (which means having more,
simpler processors connected up to each other more), new ideas in philosophy
(of mind), new maths for understanding dynamical processes and equations of 10
to the 10 dimensions, ways of multi-cell recording so that we can look at the
brain with the accuracy of single-cell recordings but like an fMRI so that we
can look at its functional organisation en masse, ability to affect neurons in
more precise as well as global ways, a means of instantiating our newly-mapped
brain in our new massively parallel computers, ethical freedom to experiment on
humans in any way we like, similar freedom to try and experimentally improve
monkeys' intelligence, today's computational models rerun on tomorrow's
computers, outlining what is unique about the mental (e.g. phenomenology,
language, unitary ideas, subjectivity, non-spatial/localised, spontaneous yet
apt, non-deterministic yet casually affects the physical, many dimensions (e.g.
hunger, pain, funny, hard/soft, colourful, harmony, rhythm, chicken korma,
love, disgust, dizzy, words), interacting computers with brains to increase
mental capacity, drugs to enhance memory and change thought processes, general
population having more leisure time to experiment with ideas )</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>if life is a sort of active processing element, perhaps of
information, ...</p>

<p class=MsoNormal>_____ xxx???</p>

<p class=MsoNormal>_____ then mind is the next stage of information
organising???</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>We don't necessarily need consciousness to anchor our words
outside other words. We do need something though. You can't have language
without cognitive processes (it may be that you can't have certain (levels of)
cognitive processes without language, either). But you do need maybe embodiment
within a rich and difficult environment, sensory modalities, idiothetic
signals, a motor interface with your environment, goals/rewards and
punishment???, other agents, the means to evolve and sufficient complexity to
represent all this.</p>

<p class=MsoNormal>i can imagine the local actions and interactions of
individual bees, when viewed as an aggregate from a distant, high level, could
be conscious - if you could figure out how to communicate with/interpret the
hive mind, then the overall pattern of activity could meet criterion for
consciousness - but this maybe just me imagining some huge AI controlling all
the bees with a little joystick to spell out words in 10 foot
yellow-and-black-striped letters on the tarmac.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>can i write a spell-checker which corrects words for me,
based on exceeding a probability of my having intended a diff word?</p>

<p class=MsoNormal>that probability can be based on the number of letters in
the word, the number of letters it differs from the word it thinks i mean, the
number of candidates for a different word there are, the number of times the
prospective word has been used (and in the context it thinks i'm writing in),
whether it seems like a proper english word (in terms of statistically matching
letter pairings/triplets etc.), whether the keys i've mixed up are close
together (and whether the letters are inverted, key missed out/double pressed
etc.)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>what is a brain wave?</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>recurrent connections</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>while not at the goal pick a direction to move toward the
goal if that direction is clear for movement move there else pick another
direction according to an avoidance strategy </p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>is there a way we can combine the comprehensible rules-based
(often human encoded) symbolic AI approach with the non-ruled adaptive
incomprehensible NNs??? that wouldn't be biologically plausible though. could i
write a program to decode NNs, perhaps by running through hundreds of
simulations and somehow cataloguing the results (i.e. reverse engineering the
results, so that i could have an NN whose workings i could understand, or at
least the results of the working anyway) - but the whole point is that NNs
don't have rules per se, eg the NNs that are more successulf for learning both
regular and irregular words because they don't rely on either one or the other
rule, but constraint satisfaction in some way</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>second order neural network - you use a neural network to
determine the growth, development and organisation of the first order net - you
want a NN to solve a complex path-finding problem, so you train your second
order NN on other NNs that have proven successful at their tasks, by showing it
the input data, the required output data and the NNs themselves. then you use
that second order NN to organise others. it's not how the brain develops, but
with each stage/order of evolution/neural net, you jack up the order or power
of abstraction and self-organisation of the environet</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>human mind is able to use the environment as a means of
storing information - e.g. writing and talking</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>understanding = knowing about the application of a rule.
being able to apply the rule yourself, as well as being able to recognise
legitimate and complicated applications of the rule.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>intelligence = learned, goal-directed (alive), measurable by
the complexity of the chain of reasoning (the number of steps/obstacles between
the current state and the state you want to be in)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>quake family or perhaps a single modular agent comprised of
different body parts/functions, which need to communicate to each other. its NN
learns to make sense of the visual input, and to form an internal model of the
environment, and learns what 'forward' or 'shoot' mean in terms of what it can
understand. from this, abstract to 'movement', 'pain', 'hide' etc.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>how can dennett explain blindsight? surely there must be
something specific about the various neural paths/tracks which makes some of
them conscious, and some not</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>coarse coding = distributed? sparse? linear? random
selection? interference?</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>could we not get a drug which simply speeded up long-term
potentiation in certain areas of the brain - the ones to do with formation of
concepts ...?</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>i'm going to have a glossary with various ways of explaining
the same thing, canvassed f diff sources</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>what is the problem with epiphenomenonalism, ie what is
wrong with the idea that the mental is inert?</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>what makes up me, ie my peculiar brain processes and neural
make-up is preserved - it is simply that the decision-making is going on at the
physical, neural level and perceived in mental terms, rather than the mental
directing the physical</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>i can be a functionalist, and just say that (though i have
no idea how) my program will have phenomenological experience</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>could you copy a conscious AI indefinitely?</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>how would dennett explain simultanagnosia</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>does Dijkstra's algorithm necessarily find the best path?
does it analyse every single node in terrain? do you need to look at every node
in the terrain to be sure of finding the best path? or only if there are patchy
terrain costs?</p>

<p class=MsoNormal>what difference does it make to our choice/power of
algorithm if we do/don't know where the goal is and/or what obstacles are in
the way, or shroud as in C&amp;C?</p>

<p class=MsoNormal>_____ prioritise the choice of algorithm, so that it fits
the best knowledge it has</p>

<p class=MsoNormal>trade-off also as to how fast we want to find a solution vs
how good a path it is</p>

<p class=MsoNormal>what if we're also trying to avoid something, or there's
gravity?</p>

<p class=MsoNormal>what happens if the terrain affects acceleration, as well as
top speed? :)</p>

<p class=MsoNormal>can we get a good sliding scale of efficiency by slapping
different scales of tiles on our terrain?</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>5 variables defines a pixel (x, y, 3 colours)</p>

<p class=MsoNormal>a visual module which feeds into the intelligence module
which commands the joystick module - all via a natural language interface - all
of them evolve </p>

<p class=MsoNormal>together - hierarchical goals</p>

<p class=MsoNormal>a quake family (computer game + internet multi-player).
mother + father (brains and ears/guns), plus child - gets genetic inheritance
plus experience</p>

<p class=MsoNormal>GUI that humans can tweak features, watch teh families
interact, change the level, add obstacles, play as a family. see if societies
build up</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>irony of AI arising in a game simulating intelligence</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>would we be smarter if we lived in a much harsher
environment? - what if aliens do?</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>how can we be sure of identifying an alien intelligence if
we find one?</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>intelligence: demonstrable/exhibited, learned, adapted to
body-in-its-environment, goal-oriented</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>visual representations of the glowing growing evolving
symbol structures </p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>knowledge rep (static) vs learning (dynamic process)</p>

<p class=MsoNormal>sq root (analogy)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>what makes one thought more conceptually difficult than
another?</p>

<p class=MsoNormal>and might those thoughts be considered easy in a different
representational system?</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>is the difference tween man/animal emotion (according to
Damasio) that we have the conscious evaluative mech, and similarly, that we
have the landscape/foreground body state/thought content 'feeling' which can go
alongside</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>for it to answer intelligently, there has to be some sort of
intelligence behind it - for that, it has to understand, and have purpose (and
obstacles)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>for it to understand, it must first comprehend
syntactically, then compare semantically with knowledgebase</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>it has access to infinite reading material</p>

<p class=MsoNormal>but i do not have infinite time/resources(/expertise) - so
the solution must be elegant, not by dint of brute power</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>by first limiting the requirements/demands/topics it has to
face, i will then build it up into something wider/broader/more completely
human</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>if it's going to be able to understand its input, it has to
realise what the input is about first</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>can i use the same sequential, age-related development
assumptions as IQ tests - so that my program learns to speak like a child</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>the difference is that it has no visual/vocal stimuli to
accompany and associate with the words</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>does it change anything if we talk about size of gaps
between APs instead of rate?</p>

<p class=MsoNormal>_____ = analogue info in time-steps?</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>would it make more sense to speak of something's arrangement
being too complex, rather than cognitively closed to us</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>is rolls' model compatible with dennett's?</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>build a visual environment of my own &#8211; complete with
spyhole, but also able to run purely virtually &#8211; feeds in to provide the
program with an internal representation</p>

<p class=MsoNormal>OR harness the quake one, complete with level builder</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>could it be that the general intelligence, g, is not a
specific but a general factor, i.e. speed of connections or something that
can&#8217;t be directly measured in any specific area?</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>visual-motor system (use a genetic algorithm mechanism for
simulating the developmental connection-forming/pruning) </p>

<p class=MsoNormal>multiple modalities = can&#8217;t describe in terms of anything
else (e.g. emotion, hunger)</p>

<p class=MsoNormal style='margin-top:4.0pt'>&nbsp;</p>

<p class=MsoNormal>it all comes down to knowledge representation</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>could I set up a neural net that does the learning and
translates/re-represents that knowledge differently for employment</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>slideshow program</p>

<p class=MsoNormal>chatterbox</p>

<p class=MsoNormal>agent in a virtual world</p>

<p class=MsoNormal>something to swallow and represent knowledge, e.g. in
dictionaries</p>

<p class=MsoNormal>an ideas box</p>

<p class=MsoNormal>a contacts database</p>

<p class=MsoNormal>model the retina</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>kantian categories &#8211; space (sense of self-position,
localised body), time (continuous, perhaps independent of internal dure),
imperfect transparency of mind</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>is it that Nick thinks he can create consciousness and
semantics without specifically coding towards them &#8211; or that they don&#8217;t matter,
since they are supervenient?</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>relationships + entities &#8211; formulated through Markov chains</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>how important could virtual machines, bi-cameral parallel
processing, virtual machines and internal representations prove?</p>

<p class=MsoNormal><span style='layout-grid-mode:line'>&nbsp;</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>re-read Elman, Finding
structure in time</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>&nbsp;</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>formal, closed system
with defined aims &amp; rules, subjective representation, often social
interaction, without real survival value (fun &amp; emotion)</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>representation, interaction,
conflict, and safety</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>clarity = sine qua non
of computer games?</span></p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>what you really want is a learning paradigm powerful enough
so that (after having accumulated a body of knowledge), it is able to observe
itself doing low-order work, and be able to apply its own paradigm to itself to
develop higher-order &#8216;thinking skills&#8217; and abstraction etc.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal><span style='layout-grid-mode:line'>expressiveness vs
efficiency - 2 separate languages</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>&nbsp;</span></p>

<p class=MsoNormal><span style='layout-grid-mode:line'>consistency?: knowledge
only needs to be consisistent within a context</span></p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>if I represent each word as three 1-byte numbers (255), then
I can represent sentences as a string of colours (like RGB) &#8211; easy for me as
programmer to interpret</p>

<p class=MsoNormal>the debate we&#8217;re seeing at the moment is analogous to the
18th-century empiricist vs rationalist debate &#8211; and the rationalists are going
to lose, but the empiricists are going to have to concede a little as well</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>linking rules??? reference to Dowty in Morris &amp; Elman</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>is functionalism (necessarily) physicalistic?</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>ned block describes physicalism as a kind of subset of
materialism, which holds that there is only one single materialistic
explanation of mind, i.e. ours. this seems like a rather misleading use of the
term, 'physicalism', as well as pointless since i think very few philosophers
even vaguely subscribe to such a restrictive form of materialism.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>what is a reason??? it's a response to a question. for what
is a question, but a demand for reasons...</p>

<p class=MsoNormal>_____ does it have to be a why-question??? other q-types
include: who, what, where, how, when</p>

<p class=MsoNormal>___________ does it make sense to speculate that the other
q-types also want reasons??? no, they fill syntactic (or base semantic) gaps.
only 'why' demands 'because'</p>

<p class=MsoNormal>_____ does 'why' have to come after all the other types
then??? well, it certainly seems to help to have the concepts of agent, means,
time + place - maybe you don't necessarily need all of them for every
why-question</p>

<p class=MsoNormal>_____ does 'why' require intention???</p>

<p class=MsoNormal>is there a way to link talk of reasons, reason, naturalism
and causality, and Hume, together</p>

<p class=MsoNormal style='margin-left:17.85pt'>of course, you could see it
equally the other way round &#8211; a reason is anything that starts &#8216;because &#8230;&#8217;</p>

<p class=MsoNormal style='margin-left:17.85pt'>neither way of seeing it
(definition in terms of a frame sentence) really tells you what role (or how)
it plays in our belief economy/interactions</p>

<p class=MsoNormal style='margin-left:17.85pt'>[also in thesis questions]</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>so much of our language is space/travel-based (see
jackendoff in pinker on the verbs that have been co-opted) that a non-spatial
(or 1-D) world will lose)</p>

<p class=MsoNormal>cyborgs will have to be human-based because so much of what
we prize is contingent and species-specific, e.g. creative writing, dancing,
humour &#8230;</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>cf French on the sub-cognitive
demands of the Turing test</p>

  <p class=MsoNormal>&nbsp;</p>
  <p class=MsoNormal style='margin-top:0in;mso-layout-grid-align:none;text-autospace:
none'> </p>
  <hr>
  <p align="center"><font color="#FFFFFF" face="Times New Roman, Times, serif"><b><i><font color="#000000">- 
    <a href="../../about/about.htm">About me</a> - <a href="../../outlets/outlets.htm">Outbursts 
    &amp; outlets</a> - <a href="../../collections/collections.htm">Collected 
    mishmash </a></font></i></b></font></p>
  <p align="right"><font color="#000000" face="Times New Roman, Times, serif"><b><i><font size="1">Greg 
    Detre, <a href="mailto:grog@dial.pipex.com">grog@dial.pipex.com</a>, November 
    2001, <a href="http://users.ox.ac.uk/%7Ecorp0517/" target="_top">http://users.ox.ac.uk/~corp0517/</a></font></i></b></font></p>

</div>

<!-- InstanceEndEditable --> 
<hr>
<p align="center"><font size="2"><a href="/greg/index.htm">Home</a> - <a href="/greg/blog/index.htm">Blog</a> 
  - <a href="/greg/about/about.htm">About me</a> - <a href="/greg/outbursts/outbursts.htm">Outbursts 
  &amp; outlets</a> - <a href="/greg/collected/collected.htm">Collected mishmash</a></font></p>
<p align="center"><font size="2">Greg Detre, greg@remove-this.gregdetre.co.uk, 
  <a href="http://www.gregdetre.co.uk">http://www.gregdetre.co.uk</a> - updated 
  <!-- #BeginDate format:Am1 -->June 29, 2003<!-- #EndDate -->
  </font> 
<p>&nbsp; </p>
</body>
<!-- InstanceEnd --></html>
