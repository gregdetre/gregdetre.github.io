<html xmlns:o="urn:schemas-microsoft-com:office:office"
xmlns:w="urn:schemas-microsoft-com:office:word"
xmlns="http://www.w3.org/TR/REC-html40">

<head>
<meta http-equiv=Content-Type content="text/html; charset=windows-1252">
<meta name=ProgId content=Word.Document>
<meta name=Generator content="Microsoft Word 9">
<meta name=Originator content="Microsoft Word 9">
<link rel=File-List
href="revision%20-%20neuro2%20finals%20citations%2002_filelist.xml">
<title>Title</title>
<!--[if gte mso 9]><xml>
 <o:DocumentProperties>
  <o:Author>Greg Detre</o:Author>
  <o:LastAuthor>Greg Detre</o:LastAuthor>
  <o:Revision>2</o:Revision>
  <o:TotalTime>37</o:TotalTime>
  <o:LastPrinted>2002-06-10T17:12:00Z</o:LastPrinted>
  <o:Created>2003-07-02T01:20:00Z</o:Created>
  <o:LastSaved>2003-07-02T01:20:00Z</o:LastSaved>
  <o:Pages>3</o:Pages>
  <o:Words>3448</o:Words>
  <o:Characters>19657</o:Characters>
  <o:Company>-</o:Company>
  <o:Lines>163</o:Lines>
  <o:Paragraphs>39</o:Paragraphs>
  <o:CharactersWithSpaces>24140</o:CharactersWithSpaces>
  <o:Version>9.2720</o:Version>
 </o:DocumentProperties>
 <o:OfficeDocumentSettings>
  <o:DoNotOrganizeInFolder/>
 </o:OfficeDocumentSettings>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:DrawingGridHorizontalSpacing>4.5 pt</w:DrawingGridHorizontalSpacing>
  <w:DrawingGridVerticalSpacing>12.25 pt</w:DrawingGridVerticalSpacing>
  <w:DisplayHorizontalDrawingGridEvery>0</w:DisplayHorizontalDrawingGridEvery>
  <w:Compatibility>
   <w:WW6BorderRules/>
   <w:FootnoteLayoutLikeWW8/>
   <w:ShapeLayoutLikeWW8/>
   <w:AlignTablesRowByRow/>
   <w:ForgetLastTabAlignment/>
   <w:LayoutRawTableWidth/>
   <w:LayoutTableRowsApart/>
  </w:Compatibility>
 </w:WordDocument>
</xml><![endif]-->
<style>
<!--
 /* Font Definitions */
@font-face
	{font-family:Wingdings;
	panose-1:5 0 0 0 0 0 0 0 0 0;
	mso-font-charset:2;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:0 268435456 0 0 -2147483648 0;}
@font-face
	{font-family:"Book Antiqua";
	panose-1:2 4 6 2 5 3 5 3 3 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:647 0 0 0 159 0;}
@font-face
	{font-family:Tahoma;
	panose-1:2 11 6 4 3 5 4 4 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:553679495 -2147483648 8 0 66047 0;}
 /* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{mso-style-parent:"";
	margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";}
h1
	{mso-style-next:Normal;
	margin-top:0in;
	margin-right:0in;
	margin-bottom:6.0pt;
	margin-left:0in;
	text-align:center;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	mso-outline-level:1;
	font-size:12.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	color:purple;
	mso-font-kerning:14.0pt;
	mso-bidi-font-weight:normal;
	font-style:italic;
	mso-bidi-font-style:normal;}
h2
	{mso-style-next:Normal;
	margin-top:16.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	mso-outline-level:2;
	font-size:12.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	color:navy;
	mso-bidi-font-weight:normal;
	font-style:italic;
	mso-bidi-font-style:normal;}
h3
	{mso-style-next:Normal;
	margin-top:16.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	mso-outline-level:3;
	tab-stops:right 451.45pt;
	font-size:12.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	color:green;
	font-weight:normal;
	font-style:italic;
	mso-bidi-font-style:normal;}
h4
	{mso-style-next:Normal;
	margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	mso-outline-level:4;
	font-size:12.0pt;
	font-family:"Times New Roman";
	color:maroon;
	font-weight:normal;
	text-decoration:underline;
	text-underline:single;}
h5
	{mso-style-next:Normal;
	margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	mso-outline-level:5;
	font-size:12.0pt;
	font-family:"Times New Roman";
	color:olive;
	font-weight:normal;
	text-decoration:underline;
	text-underline:dotted;}
h6
	{mso-style-next:Normal;
	margin-top:9.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	mso-outline-level:6;
	font-size:12.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	color:#999999;
	font-weight:normal;
	mso-bidi-font-weight:bold;
	text-decoration:underline;
	text-underline:wave;}
p.MsoHeading7, li.MsoHeading7, div.MsoHeading7
	{mso-style-next:Normal;
	margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	mso-outline-level:7;
	font-size:12.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	color:#333399;}
p.MsoHeading9, li.MsoHeading9, div.MsoHeading9
	{mso-style-next:Normal;
	margin-top:12.0pt;
	margin-right:0in;
	margin-bottom:3.0pt;
	margin-left:0in;
	text-align:justify;
	mso-pagination:widow-orphan;
	mso-outline-level:9;
	font-size:11.0pt;
	font-family:Arial;
	mso-fareast-font-family:"Times New Roman";}
p.MsoToc1, li.MsoToc1, div.MsoToc1
	{mso-style-parent:"Heading 1";
	mso-style-next:Normal;
	margin-top:3.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	tab-stops:.75in right 451.45pt;
	font-size:11.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	font-variant:small-caps;
	color:purple;
	mso-font-kerning:14.0pt;
	font-weight:bold;
	mso-bidi-font-weight:normal;
	font-style:italic;
	mso-bidi-font-style:normal;}
p.MsoToc2, li.MsoToc2, div.MsoToc2
	{mso-style-parent:"Heading 2";
	mso-style-next:Normal;
	margin-top:3.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:10.1pt;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	tab-stops:right 451.3pt;
	font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	color:navy;
	font-style:italic;
	mso-bidi-font-style:normal;}
p.MsoToc3, li.MsoToc3, div.MsoToc3
	{mso-style-parent:"TOC 2";
	mso-style-next:Normal;
	margin-top:3.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:20.0pt;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	tab-stops:right 451.45pt;
	font-size:9.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	color:teal;
	font-style:italic;
	mso-bidi-font-style:normal;}
p.MsoToc4, li.MsoToc4, div.MsoToc4
	{mso-style-update:auto;
	mso-style-parent:"TOC 3";
	mso-style-next:Normal;
	margin-top:3.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:35.7pt;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	tab-stops:right 451.45pt;
	font-size:7.5pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	color:maroon;
	mso-bidi-font-weight:bold;
	font-style:italic;
	mso-bidi-font-style:normal;}
p.MsoFootnoteText, li.MsoFootnoteText, div.MsoFootnoteText
	{margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";}
p.MsoHeader, li.MsoHeader, div.MsoHeader
	{margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	tab-stops:center 239.75pt right 6.65in;
	font-size:11.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	font-style:italic;
	mso-bidi-font-style:normal;}
span.MsoFootnoteReference
	{vertical-align:super;}
p.MsoListNumber, li.MsoListNumber, div.MsoListNumber
	{margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:.25in;
	margin-bottom:.0001pt;
	text-align:justify;
	text-indent:-.25in;
	mso-pagination:widow-orphan;
	mso-list:l0 level1 lfo8;
	tab-stops:list .25in;
	font-size:12.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";}
p.MsoDate, li.MsoDate, div.MsoDate
	{margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:right;
	mso-pagination:widow-orphan;
	font-size:11.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	font-style:italic;
	mso-bidi-font-style:normal;}
p.MsoDocumentMap, li.MsoDocumentMap, div.MsoDocumentMap
	{margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	background:navy;
	font-size:12.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:Tahoma;
	mso-fareast-font-family:"Times New Roman";}
p.Section, li.Section, div.Section
	{mso-style-name:Section;
	margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:center;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	font-weight:bold;
	mso-bidi-font-weight:normal;}
p.Heading0, li.Heading0, div.Heading0
	{mso-style-name:"Heading 0";
	mso-style-parent:"Heading 1";
	margin-top:6.0pt;
	margin-right:0in;
	margin-bottom:6.0pt;
	margin-left:0in;
	text-align:center;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	mso-outline-level:1;
	border:none;
	mso-border-alt:solid windowtext .5pt;
	padding:0in;
	mso-padding-alt:1.0pt 4.0pt 1.0pt 4.0pt;
	font-size:16.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Book Antiqua";
	mso-fareast-font-family:"Times New Roman";
	mso-bidi-font-family:"Times New Roman";
	font-variant:small-caps;
	color:purple;
	font-weight:bold;
	mso-bidi-font-weight:normal;}
p.Anchor, li.Anchor, div.Anchor
	{mso-style-name:Anchor;
	mso-style-update:auto;
	mso-style-parent:"Heading 9";
	margin-top:4.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	mso-outline-level:9;
	font-size:12.0pt;
	mso-bidi-font-size:11.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	mso-bidi-font-family:Arial;
	font-style:italic;
	mso-bidi-font-style:normal;}
@page Section1
	{size:841.9pt 595.3pt;
	mso-page-orientation:landscape;
	margin:.3in .5in .3in .3in;
	mso-header-margin:.5in;
	mso-footer-margin:.5in;
	mso-columns:3 even .3in;
	mso-paper-source:0;}
div.Section1
	{page:Section1;}
 /* List Definitions */
@list l0
	{mso-list-id:-120;
	mso-list-type:simple;
	mso-list-template-ids:-1247397174;}
@list l0:level1
	{mso-level-style-link:"List Number";
	mso-level-tab-stop:.25in;
	mso-level-number-position:left;
	margin-left:.25in;
	text-indent:-.25in;}
@list l1
	{mso-list-id:1470240892;
	mso-list-type:hybrid;
	mso-list-template-ids:-318178384 1685484530 67698713 67698715 67698703 67698713 67698715 67698703 67698713 67698715;}
@list l1:level1
	{mso-level-tab-stop:.25in;
	mso-level-number-position:left;
	margin-left:17.85pt;
	text-indent:-17.85pt;}
@list l2
	{mso-list-id:1476406644;
	mso-list-type:hybrid;
	mso-list-template-ids:168605670 266271734 67698691 67698693 67698689 67698691 67698693 67698689 67698691 67698693;}
@list l2:level1
	{mso-level-number-format:bullet;
	mso-level-text:o;
	mso-level-tab-stop:.5in;
	mso-level-number-position:left;
	text-indent:-.25in;
	font-family:"Courier New";
	mso-bidi-font-family:"Times New Roman";}
@list l2:level2
	{mso-level-tab-stop:1.0in;
	mso-level-number-position:left;
	text-indent:-.25in;}
@list l3
	{mso-list-id:1724403298;
	mso-list-type:hybrid;
	mso-list-template-ids:-1626289188 67698703 67698713 67698715 67698703 67698713 67698715 67698703 67698713 67698715;}
@list l3:level1
	{mso-level-tab-stop:.5in;
	mso-level-number-position:left;
	text-indent:-.25in;}
@list l4
	{mso-list-id:1746143482;
	mso-list-type:simple;
	mso-list-template-ids:-719658964;}
@list l4:level1
	{mso-level-tab-stop:.25in;
	mso-level-number-position:left;
	margin-left:.25in;
	text-indent:-.25in;}
ol
	{margin-bottom:0in;}
ul
	{margin-bottom:0in;}
-->
</style>
</head>

<body lang=EN-GB style='tab-interval:17.85pt'>

<div class=Section1>

<h1 style='margin-top:4.0pt'><span style='font-size:10.0pt;color:black'>Revision
� neuro2 finals citations 02<o:p></o:p></span></h1>

<p class=MsoNormal align=right style='margin-top:4.0pt;text-align:right'><span
style='font-size:10.0pt;color:black'>Greg Detre<o:p></o:p></span></p>

<p class=MsoNormal align=right style='margin-top:4.0pt;text-align:right'><span
style='font-size:10.0pt;color:black'>Sunday, 09 June, 2002<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></span></p>

<h2 style='margin-top:4.0pt'><span style='font-size:10.0pt;color:black'>Misc<o:p></o:p></span></h2>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Carpenter, �Neurophysiology�, 1996<o:p></o:p></span></p>

<h2 style='margin-top:4.0pt'><span style='font-size:10.0pt;color:black'>Auditory<o:p></o:p></span></h2>

<h3 style='margin-top:4.0pt'><span style='font-size:10.0pt;color:black'>Sound
localisation<o:p></o:p></span></h3>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Pickles (1988), �An introduction to the physiology of hearing�<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Kaas, Hackett and Tramo (1999), �Auditory processing in primate
cerebral cortex� in Current opinion in Neurobiology<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Helmholtz <i style='mso-bidi-font-style:normal'>resonance theory</i>
� the cross striations resonate with different frequencies of sounds (like
piano strings which of different length/stiffness)<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>von Bekesy tested this and found that each sound does not lead to
the resonance of only one narrow segment of the basilar membrane, but initates
a <i style='mso-bidi-font-style:normal'>traveling wave</i> along the length of
the cochlea that starts at the oval window (like snapping a rope tied at one
end to a post)<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>the <i style='mso-bidi-font-style:normal'>volley principle</i> (Weaver)
� several fibres <i style='mso-bidi-font-style:normal'>phase-locking</i>
(preferential firing at a particular point of the sound wave) at different
cycles of a high-frequency stimulus might work in concert to signal high
frequencies<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>2 main cells of the ventral cochlear nucleus (Oertel). when
depolarised by steady current pulse:<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'><span style='font-size:10.0pt;
color:black'>stellate cell � generates a spaced series of action potentials at
regular intervals, called a <i style='mso-bidi-font-style:normal'>chopper
resopnse</i><o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'><span style='font-size:10.0pt;
color:black'>bushy cell � generates only one or two spikes at the beginning of
the pulse, signaling the onset and timing (important for localisation)<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>organisation of the primate auditory cortex (Brugge)<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Kaas &amp; Hackett, 1999, �What� and �where� processing in
auditory cortex<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Romanski et al examined the connectivity of higher auditory
cortical areas in macaque monkeys, using a combination of anatomical tracer
dyes with electrophysiological recordings. their results support the
ventral/dorsal temporal/parietal what/where processing dichotomy, contributing
to functionally distinct regions of the frontal lobe<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Moore &amp; King, 1999, Auditory perception: the near and far of
sound localisation<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'><span style='font-size:10.0pt;
color:black'>Most experiments on auditory localisation have been concerned with
horizontal and vertical positions of sound sources, ignoring the third
dimension - distance. There has been little work on this since von Bekesy,
until Bronkhorst and Houtgast's demonstration using virtual sound technology
that �the perception of sound distance in an enclosed room by human listeners
can be quite simply modelled by fitting a temporal window around the ratio of
direct-to-reverberant sound energy; and Graziano et al have shown that neurons
in the frontal cortex of monkeys respond preferentially to sounds presented at
particular near distances, within a hand grasp of the monkey's head.�<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>There is less evidence for distance tuning in the auditory system
of non-echolocating animals. Graziano recorded from the monkey's ventral
premotor cortex which, like the superior colliculus, is a multisensory area
involved in the sensory guidance of movement. They have shown that the auditory
receptive fields of ventral premotor cortex neurons, like their visual
counterparts, rarely extend beyond 30cm from the head (and are therefore
restricted to a region of space within the monkey's reach).<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>&quot;There is, however, a fundamental difference in the way that
auditory distance was examined in the two studies. The virtual space stimuli
used by Bronkhurst and Houtgast simulated source distances of a metre or more -
the far field, and refers to the region of space within which both monaural and
binaural cue values are essentially independent of distance. In contrast, the
distances in the Graziano et al. study were within the near field, a more
complex region within which energy circulates without propagating. Monaural
spectral cues and interaural level differences associated with near-field sound
sources therefore vary with distance, providing a possible basis for distance
discrimination by both individual neurons and human listeners. This is
obviously useful for localising nearby sounds, but doesn't establish whether
auditory neurons in non-echolocating mammals are sensitive to the other cues
available for more distant sound sources.&quot;<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Payne had shown that the owls make use of their superb scotopic
vision to pounce on mice in very dim light. However, they are still able to
catch the mouse even if the lights are turned off as the owl is leaving its
perch, as long as the mouse makes some sort of noise. This ability is impaired
if the owl's ears are plugged.<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>&quot;Eric Knudsen and Mark Konishi took this behavior into the
lab and developed a technique to assess the animal's ability to localize sound.
They trained an owl to sit on a perch in a dark, sound proof, anechoic room and
attend to a sound produced by a speaker that could be positioned anywhere about
the owl. When an owl localizes a sound, it turns its head, toward the direction
of the sound. The owl's localization of sound was monitored by recording its
head position with a special device -- a simple detector mounted on the head
recorded induced electric currents produced by a pair of electric coils mounted
around the animal's head. The speaker was mounted on a track and its position
was controlled by a computer.&quot;<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>&quot;Takahashi, Moiseff and Konishi [in 1984] used a local
anesthetic to show that binaural intensity differences giving rise to
space-specific cells in the MLD require the normal activity of the nucleus
Magnocellularis. The processing of OTD requires the nucleus Angularis. Manley,
Koppl, Carr and Konishi [in 1988]) showed that IID from L/R Nucleus Angularis
is processed in the VLVp region of the Nucleus of the Lateralis Lemniscus while
OTD from L/R Nucleus Magnocellularis is processed in the Nucleus
Laminaris&quot;<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Konishi &amp; Knudsen�s (1977) study with owls� sound localisation
abilities<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Most experiments on auditory localisation have been concerned with
horizontal and vertical positions of sound sources, ignoring the third
dimension - distance. There has been little work on this since von Bekesy,
until Bronkhorst and Houtgast's study using virtual sound technology (the cues
provided by the head, the ears and the room are measured, digitally synthesised
and mixed with the acoustic characteristics of the presenting headphones,
making them indistinguishable from real sounds presented within rooms by
distant loudspeakers), and Graziano et al.�s work with frontal cortex neurons
in monkeys. Bronkhurst and Houtgast simulated source distances of a metre or
more, while the Graziano et al. study focused on the near field. They showed
that small distance processing can rely on monaural spectral cues and
interaural level differences, but it is not yet clear whether auditory neurons
in non-echolocating mammals are sensitive to the other cues available for more
distant sound sources.<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Moore and King consider the idea that perception (in all three
major sensory systems) divides neatly into what and where processing pathways.
This thesis is probably clearest and most defensible for the visual system,
where support comes from lesion studies in monkeys, in which impairment of spatial
abilities or object identification can be separated, and anatomical studies
which show that connections in the visual pathways are fairly strongly
segregated. Of course, the auditory system too must analyse both identity and
location of stimuli, but it is not clear to what extent these are functionally
and anatomically isolated.<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></span></p>

<h3 style='margin-top:4.0pt'><span style='font-size:10.0pt;color:black'>Central
auditory pathways<o:p></o:p></span></h3>

<h3 style='margin-top:4.0pt'><span style='font-size:10.0pt;color:black'>Ears<o:p></o:p></span></h3>

<h2 style='margin-top:4.0pt'><span style='font-size:10.0pt;color:black'>Somatosensory<o:p></o:p></span></h2>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Johnson (2001), The roles and functions of cutaneous
mechanoreceptors<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Killackey (1995), The formation of a cortical somatotopic map (in
rodents)<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Further evidence that the formation of of a vibrissae-related
pattern is extrinsic to the neocortex is the demonstration that the visual
cortex of the neonatal rat, when transplanted to the region of the
somatosensory cortex, is capable of supporting ingrowth of thalamocortical
afferents, and teh expression of a vibrissae-related pattern (Schlagger &amp;
O'Leary, 1994).<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Zhang et al. (2001), Functional characteristics of the parallel
SI- and SII-projecting neurons of the thalamic ventral posterior nucleus in the
marmoset � abstract only<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Huffman &amp; Krubitzer (2001), Thalamo-cortical connections of
areas 3a and M1 in marmoset monkeys<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Kaas &amp; Collins (2001), The organisation of sensory cortex<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Bierman et al. (1998), Interaction of finger representation in the
human first somatosensory cortex<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black;mso-fareast-language:EN-GB'>Proske et al. (2000), The role of
muscle receptors in the detection of movements<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Melzack and Wall: 1962 explanation for this antagonism between
larger cutaneous afferents and smaller pain fibres<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></span></p>

<h3 style='margin-top:4.0pt'><span style='font-size:10.0pt;color:black'>Touch
receptors<o:p></o:p></span></h3>

<h3 style='margin-top:4.0pt'><span style='font-size:10.0pt;color:black'>Somatosensory
plasticity<o:p></o:p></span></h3>

<h3 style='margin-top:4.0pt'><span style='font-size:10.0pt;color:black'>Spinal
pathways<o:p></o:p></span></h3>

<h3 style='margin-top:4.0pt'><span style='font-size:10.0pt;color:black'>Somatosensory
system<o:p></o:p></span></h3>

<h3 style='margin-top:4.0pt'><span style='font-size:10.0pt;color:black'>Pain<o:p></o:p></span></h3>

<h2 style='margin-top:4.0pt'><span style='font-size:10.0pt;color:black'>Vision<o:p></o:p></span></h2>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Snellen chart in opticians<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>how distinct are they anatomically - Young (Nature, 1992, pg 155)<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Livingstone + Hubel were wrong - inputs are not purely p- and m- -
it's all mixed up<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Hendry &amp; Calkins, 1998, Neuronal chemistry and functional
organization in the primate visual system<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>The gain of the vestibular-ocular and opto-kinetic reflexes adapt,
so we can adapt over a few days to reversing prisms and glasses, which change
how head movement effects retinal movement. This requires the cerebellar
flocculus � Miles et al. found that flocculuar Purkinje cells int eh monkey
respond to the visual signal that arises from the mismatch of head velocity and
eye velocity.<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>transform these �tiny, distorted, upside-down images� (<span
style='mso-bidi-font-style:italic'>Gregory 1966</span>) into the
three-dimensional mental constructs we <i>see</i>, we have to construct this
visual representation from �unconscious inferences� (Rock, 1984) and ambiguous
data.<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Zeki first showed that the visual system seems to operate using
perhaps three parallel pathways, which can be roughly characterised as being
for analysing:<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'><span style='font-size:10.0pt;
color:black'>what (parvo-cellular inter-blob) � object recognition<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'><span style='font-size:10.0pt;
color:black'>where (magno-cellular) � position and motion in a
three-dimensional world<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'><span style='font-size:10.0pt;
color:black'>colour (parvo-cellular blob)� allowing us to distinguish
equiluminances<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>the visual system should be able to compare the previous location
of an object with its current location by extracting the necessary information
from the retina. This is complicated by the fact that information about the
direction of motion from a small receptive field can be ambiguous. For example,
the aperture problem <i>(Movshon, 1990)</i> demonstrates that if a grating of
diagonal lines is moved either downwards, sideways or perpendicular to the
gratings, then it will always appear to move in the same right-downwards
direction � in order to be sure, information from two separate local areas
needs to be taken<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>The difficulties involved increase with more complex objects and
surfaces moving in three dimensions. Problems like the aperture problem
highlight the need for a more complex solution, prompting researchers like Marr
and Movshon to propose that information about motion in the visual field is
extracted in two stages. The first stage is concerned with one-dimensional
moving objects and measuring the motion of the components of complex objects.
The second stage involves higher-order neurons combining and integrating the
components of motion analysed by several of the initial stage neurons.<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Lashley � cast doubt on simple-minded views of localisation<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'><span style='font-size:10.0pt;
color:black'>the effect on rats in a maze depended on the quantity of cortex
removed, not where from<o:p></o:p></span></p>

<h3 style='margin-top:4.0pt'><span style='font-size:10.0pt;color:black'>Retina
etc.<o:p></o:p></span></h3>

<h3 style='margin-top:4.0pt'><span style='font-size:10.0pt;color:black'>LGN +
V1<o:p></o:p></span></h3>

<h3 style='margin-top:4.0pt'><span style='font-size:10.0pt;color:black'>Superior
colliculus, pretectum<o:p></o:p></span></h3>

<h3 style='margin-top:4.0pt'><span style='font-size:10.0pt;color:black'>Motion<o:p></o:p></span></h3>

<h3 style='margin-top:4.0pt'><span style='font-size:10.0pt;color:black'>Depth +
stereopsis<o:p></o:p></span></h3>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Kandel &amp; Schwarz 2000<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>De Angelis &amp; Cumming (2001), �The physiology of vision�<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Garnham, �Artificial intelligence�<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Mayhew and Frisby (1981), �Psychophysical and computational
studies towards a theory of human stereopsis�, <i style='mso-bidi-font-style:
normal'>Artificial Intelligence</i>, 17: 349-85<span
class=MsoFootnoteReference><o:p></o:p></span></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></span></p>

<h3 style='margin-top:4.0pt'><span style='font-size:10.0pt;color:black'>Form<o:p></o:p></span></h3>

<h3 style='margin-top:4.0pt'><span style='font-size:10.0pt;color:black'>Colour<o:p></o:p></span></h3>

<h3 style='margin-top:4.0pt'><span style='font-size:10.0pt;color:black'>Parietal<o:p></o:p></span></h3>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>human and monkey studies:the posterior parietal cortex has a role
in programming actions and in transforming sensory signals into plans for motor
behaviours (Mountcastle et al. 1975, Andersen et al. 1992)<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>different areas of the posterior parietal = functionally different
(Sakata et al, 1997)<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:.25in;margin-bottom:.0001pt'><span style='font-size:10.0pt;
color:black'>lateral intraparietal area (LIP) � sacades<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:.25in;margin-bottom:.0001pt'><span style='font-size:10.0pt;
color:black'>posterior parietal region (PRR) � planning reaching movements<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:.25in;margin-bottom:.0001pt'><span style='font-size:10.0pt;
color:black'>anterior intraparietal area (AIP) � grasping<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Sakata (1997), The parietal association cortex in depth perception
and visual control of hand action<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Iwaniak &amp; Whishaw (2000), On the origin of skilled forelimb
movements<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Goodale (1998), Frames of Reference for Perception and Action in
the Human Visual System<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>a vital role in the visuomotor stream (following Goodale &amp;
Haffenden�s (1998) terminology) used for directing action, often at a
subconscious level. This seems to involve the representation and transformation
between various coordinate frames of reference, in what Andersen et al (1997)
terms a �multimodal representation of space�. More controversially, the
parietal cortex also seems to contain neuronal activity relating to attention,
intention and decision.<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Metelli et al (1994): AIP and the premotor areas are connected
reciprocally<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Sakata et al (1997): many AIP neurons are selective for object
shape and size<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>mirror neurons � active both when the monkey performs and observes
an action � Rizzolatti, Fogassi and Gallese � basic system of action
recognition, and creating an internal model<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Andersen (1997), Multimodal representation of space in the
posterior parietal cortex and its use in planning movements<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black;mso-fareast-language:EN-GB'>Andersen et al (1992) speculate that
LIP is the 'parietal eye field', 'specialised for visual-motor transformation
functions related to saccades', on the basis of the strong direct projections
from extrastriate visual areas and projections to various cortical and
subcortical areas concerned with saccadic eye movements, and results from
electrical stimulation.<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black;mso-fareast-language:EN-GB'>Andersen claims that areas 7a and LIP
use their eye position and retinal input signals to represent the location of a
visual target with respect to the head, a 'head-centred reference frame'. He
concedes that 'intuitively one would imagine that an area representing space in
a head-centred reference frame would have receptive fields that are anchored in
space with respect to the head', but proposes instead that instead a highly
distributed pattern is used to uniquely specify each head-centred location in
the activity across a population of cells with different eye position and
retinal position sensitivities. Indeed, he argues that 'when neural networks
are trained to transform retinal signals into head-centred coordinates by using
eye position signals, the middle-layer units that make the transformation gain
fields similar to the cells in the parietal cortex (Zipser &amp; Andersen,
1988)'.<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Snyder et al (1993) showed that supplying solely vestibular
signals (in the dark to isolate from visual input), or solely proprioceptive
cues (rotating the trunk while keeping the head fixed), both elicit responses
from these cells in 7a and LIP, indicating that both of these sources are used
in constructing the body-centred frame. Furthermore, input from the vestibular
and visual systems (e.g. landmarks and optic flow) can contribute to a
world-centred representation.<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black;mso-fareast-language:EN-GB'>Mazzoni et al (1996) recently
demonstrated that when a monkey is required to memorize the location of an
auditory target in the dark and then to make a saccade to it after a delay,
there is activity in LIP during the presentation of the auditory target and
during the delay period. This auditory response generally had the same
directional preference as the visual response, suggesting that the auditory and
visual receptive fields and memory fields may overlap one another. The above
experiments were done when the animal was fixating straight ahead, with its
head also oriented in the same direction. Under these conditions, the eye and
head coordinate frames overlap. However, if the animal changes the orbital
position of its eyes, then the two coordinate frames move apart. Do the
auditory and visual receptive fields in LIP move apart when the eyes move, or
do they share a common spatial coordinate frame?<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black;mso-fareast-language:EN-GB'>Stricanne et al (1996) showed that
almost half of the auditory-responding cells in LIP coded the auditory location
in eye-centred coordinates, like in the superior colliculus, where auditory
fields are also in eye-centred coordinates (Jay &amp; Sparks, 1984).<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black;mso-fareast-language:EN-GB'>Handily, MSTd contains cells selective
for one or more of the following: expansion-contraction, rotation and linear
motion (Saito, 1986). However, it appears that MSTd is not decomposing the
optic flow into channels of expansion, rotation and linear motion - Andersen
produced a spiral space with expansion on one axis and rotation on another, and
found that disappointingly few of the MSTd neurons had tuning curves aligned
directly along these axes<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black;mso-fareast-language:EN-GB'>Perrone &amp; Stone's (1994) and
Warren's (1995) similar models require more neurons for separate heading maps
for different combinations of eye direction and speed (rather than just eye
movement)(???).<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black;mso-fareast-language:EN-GB'>In Xing et al's (1995) model, which
takes in head-centred auditory signals and eye position and retinal position
signals as input, and whose output codes the metrics of a planned movement in
motor coordinates, the middle layers develop overlapping receptive fields for
auditory and visual stimuli and eye position gain fields. It is interesting
that the visual signals also develop gain fields, since both the retinally
based stimuli and the motor error signals are always aligned when training the
network and, in principle, do not need to use eye position information.
However, the auditory and visual signals share the same circuitry and
distributed representation, which results in gain fields for the visual
signals.<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black;mso-fareast-language:EN-GB'>No coordinate transformation is
necessary for a simple visual saccade. However, there are occasionally times
when the oculomotor ocordinates are in a different frame from sensory-retinal
coordinates (e.g. displacement of the eye from electrical stimulation or an
intervening saccade), yet the cells in the PPC, frontal eye fields and superior
colliculus are still able to code the impending movement vector, even though no
visual stimulus has appeared in their receptive fields. Krommenhoek et al's
(1993) and Xing et al's (1995) networks were able to replicate this result,
both developing eye gain fields in the hidden layer. The Xing et al neural
network was trained on a double-saccade task; it inputted two retinal locations
and then outputted the motor vectors of two eye movements, first to one target
and then to the other. In order to program the second saccade accurately, the
network was required to use the remembered retinal location of the first target
and update it with the new eye position. This implies that an implicit
distributed representation of head-centred location was formed in the hidden
layer.<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Gnadt &amp; Andersen (1988) have shown that activity in cells
primarily in LIP (coding in oculomotor coordinates) precedes saccades. This
activity is also memory-related, e.g. lighting up when a monkey is remembering
the location of a briefly-flashed stimulus and, after a delay, made a saccade
to the remembered location. Glimcher &amp; Platt required an animal to attend
to a distractor target, which was extinguished as a cue to saccade to the selected
target, thus separating the focus of attention from the selected movement. For
many of the cells, the activity reflected the movement plan and not the
attended location, although the activity of some cells was influenced by the
attended location. Andersen thinks that these and other studies suggest that a
component of LIP activity is related to movements that the animal intends to
make.<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Mazzoni et al (1996) used a delayed double-saccade experiment to
try and distinguish whether the memory activity was primarily related to
intentions to make eye movements or to a sensory memory of the location of the
target. They found both types of cells, with the majority of overall activity
being related to the next intended saccade and not to the remembered stimulus location.
This did not necessarily lead to execution of the movement, since the animals
could be asked to change their planned eye movements during the delay period in
a memory saccade task, and the intended movement activity in LIP would change
correspondingly (Bracewell et al, 1996).<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Bushnell et al (1981) recorded from PPC neurons while the animal
programmed an eye or reaching movement to a retinotopically identical stimulus.
They claimed that the activity of the cells did not differentiate between these
two types of movements, indicating that the PPC is concerned with sensory
location and attention and not with planning movements. However, when Andersen
et al repeated the experiment, they found that 2/3 of cells in the PPC were
selective during the memory period for whether the target requires an arm or
eye movement.<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Andersen considers Duhamel et al, 1992 (similar to Gnadt &amp;
Andersen, 1988) and Kalaska &amp; Crammond, 1995 as studies in which their
theory that the memory-related activity in the PPC signals the animal's plan to
make a movement could explain the results.<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black;mso-fareast-language:EN-GB'>Husain &amp; Jackson (2001), Visual
space is not what it appears to be<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Probe stimuli that appear very briefly at a wide range of stimulus
locations immediately prior to the execution of a saccadic eye movement are not
perceived to be in their veridical positions, but are instead reported to be at
locations compressed towards the target of the saccadic eye movement - the
intended new point of fixation or direction of gaze. If no saccadic eye
movement is planned, then the location is misreported closer to the point of
fixation (Ross &amp; Morrone, 1997).<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>When the intraparietal sulcus is lesioned in humans, a profound
spatial deficit which Husain &amp; Jackson explain as an impairment in spatial
re-mapping across saccades when tested on a double-saccade task [16,17], in
that they are unable to '[make] saccades commensurate with the original retinal
position of the second target', i.e. failing to take into account the new eye
position after the first saccade. They suggest that this may account for one
component of the hemispatial neglect syndrome which follows parietal damage.<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Stein (1992) � 2 characteristics of all posterior parietal
neurons:<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:.5in;margin-bottom:.0001pt;text-indent:-.25in;mso-list:l3 level1 lfo11;
tab-stops:list .25in'><![if !supportLists]><span style='font-size:10.0pt;
color:black'>1.<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span><![endif]><span style='font-size:10.0pt;color:black'>combinations
of sensory, motivational and motor information are received<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:.5in;margin-bottom:.0001pt;text-indent:-.25in;mso-list:l3 level1 lfo11;
tab-stops:list .25in'><![if !supportLists]><span style='font-size:10.0pt;
color:black'>2.<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span><![endif]><span style='font-size:10.0pt;color:black'>response is
greatest when the animal attends to, or moves towards, a target<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:.25in;margin-bottom:.0001pt'><span style='font-size:10.0pt;
color:black'>we might then expect posterior parietal neurons to be transforming
sensory information into commands for directing attention and guiding motor
outputs<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>spatial deficits � perhaps due to damage to temporal-parietal
polysensory regions(Goodale &amp; Milner, 1993), rather than to the dorsal
stream�s role in visuomotor guidance<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'><span style='font-size:10.0pt;
color:black'>right hemisphere lesions (greater polysensory growth in the right
hemisphere) </span><span style='font-size:10.0pt;font-family:Symbol;mso-ascii-font-family:
"Times New Roman";mso-hansi-font-family:"Times New Roman";color:black;
mso-char-type:symbol;mso-symbol-font-family:Symbol'><span style='mso-char-type:
symbol;mso-symbol-font-family:Symbol'>�/span></span><span style='font-size:
10.0pt;color:black'> greater deficits on complex spatial tasks<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Goodale &amp; Haffenden (1998) It appears as though DF's visual
system is no longer able to deliver perceptual information abotu the size,
shape and orientation of objects, yet the visuomotor systems that control the
programming and execution of visually-guided actions remain sensitive to these
same object features.<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>Goodale and Milner (1992) have propposed that these two streams
correlate with the 'dorsal' and 'visual' streams identified in the cerebral
cortex of the monkey<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'>�When the eyes move, the focus tuning curve of these cells shifts
in order to compensate for the retinal focus shift due to the eye movement. In
this way MSTd could map out the relationship between the expansion focus and
heading with relatively few neurons, each adjusting its focus preference
according to the velocity of the eye.� This pursuit compensation is achieved by
a non-uniform gain and distortion applied to different locations in the
receptive field. Andersen acknowledges that Perrone &amp; Stone's (1994) and
Warren's (1995) models are similar, but require more neurons for separate
heading maps for different combinations of eye direction and speed (rather than
just eye movement). Andersen goes so far as to say that MSTd may compensate
spatially for the consequences of eye movements for all patterns of motion.<o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></span></p>

<p class=MsoNormal style='margin-top:4.0pt'><span style='font-size:10.0pt;
color:black'><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></span></p>

</div>

</body>

</html>
