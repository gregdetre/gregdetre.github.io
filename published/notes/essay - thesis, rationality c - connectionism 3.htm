<html xmlns:o="urn:schemas-microsoft-com:office:office"
xmlns:w="urn:schemas-microsoft-com:office:word"
xmlns="http://www.w3.org/TR/REC-html40">

<head>
<meta http-equiv=Content-Type content="text/html; charset=windows-1252">
<meta name=ProgId content=Word.Document>
<meta name=Generator content="Microsoft Word 9">
<meta name=Originator content="Microsoft Word 9">
<link rel=File-List
href="essay%20-%20thesis,%20rationality%20c%20-%20connectionism%203_filelist.xml">
<title>Title</title>
<!--[if gte mso 9]><xml>
 <o:DocumentProperties>
  <o:Author>Greg Detre</o:Author>
  <o:LastAuthor>Greg Detre</o:LastAuthor>
  <o:Revision>2</o:Revision>
  <o:TotalTime>804</o:TotalTime>
  <o:Created>2003-07-02T01:00:00Z</o:Created>
  <o:LastSaved>2003-07-02T01:00:00Z</o:LastSaved>
  <o:Pages>1</o:Pages>
  <o:Words>3737</o:Words>
  <o:Characters>21302</o:Characters>
  <o:Company>-</o:Company>
  <o:Lines>177</o:Lines>
  <o:Paragraphs>42</o:Paragraphs>
  <o:CharactersWithSpaces>26160</o:CharactersWithSpaces>
  <o:Version>9.2720</o:Version>
 </o:DocumentProperties>
 <o:OfficeDocumentSettings>
  <o:DoNotOrganizeInFolder/>
 </o:OfficeDocumentSettings>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:DrawingGridHorizontalSpacing>4.5 pt</w:DrawingGridHorizontalSpacing>
  <w:DrawingGridVerticalSpacing>12.25 pt</w:DrawingGridVerticalSpacing>
  <w:DisplayHorizontalDrawingGridEvery>0</w:DisplayHorizontalDrawingGridEvery>
  <w:Compatibility>
   <w:WW6BorderRules/>
   <w:FootnoteLayoutLikeWW8/>
   <w:ShapeLayoutLikeWW8/>
   <w:AlignTablesRowByRow/>
   <w:ForgetLastTabAlignment/>
   <w:LayoutRawTableWidth/>
   <w:LayoutTableRowsApart/>
  </w:Compatibility>
 </w:WordDocument>
</xml><![endif]-->
<style>
<!--
 /* Font Definitions */
@font-face
	{font-family:Wingdings;
	panose-1:5 0 0 0 0 0 0 0 0 0;
	mso-font-charset:2;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:0 268435456 0 0 -2147483648 0;}
@font-face
	{font-family:"Book Antiqua";
	panose-1:2 4 6 2 5 3 5 3 3 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:647 0 0 0 159 0;}
@font-face
	{font-family:Tahoma;
	panose-1:2 11 6 4 3 5 4 4 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:553679495 -2147483648 8 0 66047 0;}
 /* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{mso-style-parent:"";
	margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:12.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-language:EN-GB;}
h1
	{mso-style-next:Normal;
	margin-top:0in;
	margin-right:0in;
	margin-bottom:6.0pt;
	margin-left:0in;
	text-align:center;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	mso-outline-level:1;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:12.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	color:purple;
	mso-font-kerning:14.0pt;
	mso-fareast-language:EN-GB;
	mso-bidi-font-weight:normal;
	font-style:italic;
	mso-bidi-font-style:normal;}
h2
	{mso-style-next:Normal;
	margin-top:16.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	mso-outline-level:2;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:12.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	color:navy;
	mso-fareast-language:EN-GB;
	mso-bidi-font-weight:normal;
	font-style:italic;
	mso-bidi-font-style:normal;}
h3
	{mso-style-next:Normal;
	margin-top:16.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	mso-outline-level:3;
	tab-stops:right 451.45pt;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:12.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	color:green;
	mso-fareast-language:EN-GB;
	font-weight:normal;
	font-style:italic;
	mso-bidi-font-style:normal;}
h4
	{mso-style-next:Normal;
	margin-top:12.0pt;
	margin-right:0in;
	margin-bottom:3.0pt;
	margin-left:0in;
	text-align:justify;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	mso-outline-level:4;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:12.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:Arial;
	mso-bidi-font-family:"Times New Roman";
	mso-fareast-language:EN-GB;
	mso-bidi-font-weight:normal;}
h5
	{mso-style-next:Normal;
	margin-top:10.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	mso-outline-level:5;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:12.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	color:maroon;
	mso-fareast-language:EN-GB;
	font-weight:normal;
	text-decoration:underline;
	text-underline:single;}
h6
	{mso-style-parent:"Heading 5";
	mso-style-next:Normal;
	margin-top:9.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:.5in;
	margin-bottom:.0001pt;
	text-align:justify;
	text-indent:-.25in;
	mso-pagination:widow-orphan;
	mso-outline-level:6;
	mso-list:l3 level1 lfo10;
	tab-stops:list .5in;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:12.0pt;
	mso-bidi-font-size:11.0pt;
	font-family:"Times New Roman";
	color:olive;
	mso-fareast-language:EN-GB;
	font-weight:normal;
	mso-bidi-font-weight:bold;
	text-underline:#33CCCC;}
p.MsoToc1, li.MsoToc1, div.MsoToc1
	{mso-style-parent:"Heading 1";
	mso-style-next:Normal;
	margin-top:3.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	tab-stops:.75in right 451.45pt;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:11.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	font-variant:small-caps;
	color:purple;
	mso-font-kerning:14.0pt;
	mso-fareast-language:EN-GB;
	font-weight:bold;
	mso-bidi-font-weight:normal;
	font-style:italic;
	mso-bidi-font-style:normal;}
p.MsoToc2, li.MsoToc2, div.MsoToc2
	{mso-style-parent:"Heading 2";
	mso-style-next:Normal;
	margin-top:3.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:10.1pt;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	tab-stops:right 451.3pt;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	color:navy;
	mso-fareast-language:EN-GB;
	font-style:italic;
	mso-bidi-font-style:normal;}
p.MsoToc3, li.MsoToc3, div.MsoToc3
	{mso-style-parent:"TOC 2";
	mso-style-next:Normal;
	margin-top:3.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:20.0pt;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	tab-stops:right 451.45pt;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:9.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	color:teal;
	mso-fareast-language:EN-GB;
	font-style:italic;
	mso-bidi-font-style:normal;}
p.MsoToc4, li.MsoToc4, div.MsoToc4
	{mso-style-update:auto;
	mso-style-parent:"TOC 3";
	mso-style-next:Normal;
	margin-top:3.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:35.7pt;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	tab-stops:right 451.45pt;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:7.5pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	color:maroon;
	mso-fareast-language:EN-GB;
	mso-bidi-font-weight:bold;
	font-style:italic;
	mso-bidi-font-style:normal;}
p.MsoFootnoteText, li.MsoFootnoteText, div.MsoFootnoteText
	{margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-language:EN-GB;}
p.MsoCommentText, li.MsoCommentText, div.MsoCommentText
	{margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-language:EN-GB;}
p.MsoHeader, li.MsoHeader, div.MsoHeader
	{margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	tab-stops:center 239.75pt right 6.65in;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:11.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-language:EN-GB;
	font-style:italic;
	mso-bidi-font-style:normal;}
span.MsoFootnoteReference
	{vertical-align:super;}
span.MsoCommentReference
	{mso-ansi-font-size:8.0pt;
	mso-bidi-font-size:8.0pt;}
p.MsoListNumber, li.MsoListNumber, div.MsoListNumber
	{margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:.25in;
	margin-bottom:.0001pt;
	text-align:justify;
	text-indent:-.25in;
	mso-pagination:widow-orphan;
	mso-list:l0 level1 lfo8;
	tab-stops:list .25in;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:12.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-language:EN-GB;}
p.MsoDate, li.MsoDate, div.MsoDate
	{margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:right;
	mso-pagination:widow-orphan;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:11.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-language:EN-GB;
	font-style:italic;
	mso-bidi-font-style:normal;}
p.MsoDocumentMap, li.MsoDocumentMap, div.MsoDocumentMap
	{margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	background:navy;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:12.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:Tahoma;
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-language:EN-GB;}
p.Section, li.Section, div.Section
	{mso-style-name:Section;
	margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:center;
	mso-pagination:widow-orphan;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:12.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-language:EN-GB;
	font-weight:bold;
	mso-bidi-font-weight:normal;}
p.Heading0, li.Heading0, div.Heading0
	{mso-style-name:"Heading 0";
	mso-style-parent:"Heading 1";
	margin-top:6.0pt;
	margin-right:0in;
	margin-bottom:6.0pt;
	margin-left:0in;
	text-align:center;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	mso-outline-level:1;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	border:none;
	mso-border-alt:solid windowtext .5pt;
	padding:0in;
	mso-padding-alt:1.0pt 4.0pt 1.0pt 4.0pt;
	font-size:16.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Book Antiqua";
	mso-fareast-font-family:"Times New Roman";
	mso-bidi-font-family:"Times New Roman";
	font-variant:small-caps;
	color:purple;
	mso-fareast-language:EN-GB;
	font-weight:bold;
	mso-bidi-font-weight:normal;}
p.CommentSubject, li.CommentSubject, div.CommentSubject
	{mso-style-name:"Comment Subject";
	mso-style-parent:"Comment Text";
	mso-style-next:"Comment Text";
	margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-language:EN-GB;
	font-weight:bold;}
p.BalloonText, li.BalloonText, div.BalloonText
	{mso-style-name:"Balloon Text";
	margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:8.0pt;
	font-family:Tahoma;
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-language:EN-GB;}
@page Section1
	{size:595.3pt 841.9pt;
	margin:68.05pt 68.05pt 68.05pt 68.05pt;
	mso-header-margin:.5in;
	mso-footer-margin:.5in;
	mso-paper-source:0;}
div.Section1
	{page:Section1;}
 /* List Definitions */
@list l0
	{mso-list-id:-120;
	mso-list-type:simple;
	mso-list-template-ids:-1247397174;}
@list l0:level1
	{mso-level-style-link:"List Number";
	mso-level-tab-stop:.25in;
	mso-level-number-position:left;
	margin-left:.25in;
	text-indent:-.25in;}
@list l1
	{mso-list-id:1103186221;
	mso-list-type:hybrid;
	mso-list-template-ids:89585846 134807567 134807577 134807579 134807567 134807577 134807579 134807567 134807577 134807579;}
@list l1:level1
	{mso-level-tab-stop:.5in;
	mso-level-number-position:left;
	text-indent:-.25in;}
@list l2
	{mso-list-id:1470240892;
	mso-list-type:hybrid;
	mso-list-template-ids:-318178384 1685484530 67698713 67698715 67698703 67698713 67698715 67698703 67698713 67698715;}
@list l2:level1
	{mso-level-tab-stop:.25in;
	mso-level-number-position:left;
	margin-left:17.85pt;
	text-indent:-17.85pt;}
@list l3
	{mso-list-id:1476406644;
	mso-list-type:hybrid;
	mso-list-template-ids:168605670 266271734 67698691 67698693 67698689 67698691 67698693 67698689 67698691 67698693;}
@list l3:level1
	{mso-level-number-format:bullet;
	mso-level-style-link:"Heading 6";
	mso-level-text:o;
	mso-level-tab-stop:.5in;
	mso-level-number-position:left;
	text-indent:-.25in;
	font-family:"Courier New";
	mso-bidi-font-family:"Times New Roman";}
@list l3:level2
	{mso-level-tab-stop:1.0in;
	mso-level-number-position:left;
	text-indent:-.25in;}
@list l4
	{mso-list-id:1746143482;
	mso-list-type:simple;
	mso-list-template-ids:-719658964;}
@list l4:level1
	{mso-level-tab-stop:.25in;
	mso-level-number-position:left;
	margin-left:.25in;
	text-indent:-.25in;}
ol
	{margin-bottom:0in;}
ul
	{margin-bottom:0in;}
-->
</style>
</head>

<body lang=EN-GB style='tab-interval:17.85pt'>

<div class=Section1>

<h1><span style='color:windowtext;font-weight:normal'>Is a naturalistic account
of reason compatible with its objectivity?<o:p></o:p></span></h1>

<h1><span style='color:windowtext'>Can rational objectivism be implemented in a
connectionist system (like the brain)?<o:p></o:p></span></h1>

<p class=MsoNormal align=right style='text-align:right'>Greg Detre</p>

<p class=MsoNormal align=right style='margin-top:2.0pt;text-align:right'>Tuesday,
January 29, 2002</p>

<p class=MsoNormal align=right style='margin-top:2.0pt;text-align:right'>Dr
Tasioulas</p>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<h2>Introduction</h2>

<p class=MsoNormal>At root, connectionism amounts to the thesis that the brain
is a dynamical system, like a mathematically modellable complex of levers and
pulleys, or in this case, neurons and synapses. The high-level behaviour of the
system seems to emerge like magic out of a morass of low-level interactions, just
as the seemingly-centralised wheeling and coordination of a flock of birds
results from each bird paying attention to purely local rules, e.g. the
position and speed of its neighbours.</p>

<h3>Define connectionism</h3>

<p class=MsoNormal>More specifically, connectionism refers to the family of
theories that aim to understand mental abilities in terms of formalised models
of the brain. These usually employ large numbers of nodes (neurons), with
weighted inter-connections (synapses). The firing rate of a neuron is usually some
non-linear function (e.g. sigmoid) of its activity, which is calculated as the
weighted sum of the firing rates of neurons that synapse onto it. In this way,
activity is propagated over time (milliseconds, in practice) in parallel from
the input neurons eventually to the output neurons.</p>

<p class=MsoNormal>Input neurons are defined as those whose activation is (at
least partially) determined by the external environment (in the case of the
brain, various sensory receptors), and output neurons are those which affect
some change in the system�s behaviour in that environment (e.g. motor neurons
connected to muscle) � hidden neurons are those whose activity is invisible to
the environment.</p>

<p class=MsoNormal>What makes neural networks interesting is their ability to
self-organise, or �learn�, by modifying their weights according to a learning
algorithm. The simplest are the Hebbian-type learning rules<a style='mso-footnote-id:
ftn1' href="#_ftn1" name="_ftnref1" title=""><span class=MsoFootnoteReference><span
style='mso-special-character:footnote'><![if !supportFootnotes]>[1]<![endif]></span></span></a>,
which are based on the principle:</p>

<p class=MsoNormal style='margin-left:17.85pt'>the synapse between two neurons should
be strengthened if the neurons fire simultaneously</p>

<p class=MsoNormal>This can be implemented in a pattern-associator, an
architecture for associating a set of input patterns with a set of
pre-specified output patterns. Innumerable improvements and revisions have been
employed, and the Hebbian rule really only works well for orthogonal (i.e.
uncorrelated) input patterns, but its human-like robustness and ability to
generalise are notable. When presented with a novel pattern which is similar
but not identical to a learned input pattern, its output will be similar or
identical to the learned output pattern. It can be seen to generalise to new
data, and form prototypes based on families of resemblance between input
patterns, both of which features had to be explicitly, inelegantly and
inefficiently built into previous symbolic models.</p>

<h3>Smolensky�s stronger claim of �connectionism�</h3>

<p class=MsoNormal>Before continuing, I want to mention a second, stronger
sense in which the term �connectionism� is used as a thesis about the workings
of the mind. The stronger claim, as espoused by Smolensky, can be stated
negatively: a symbolic, cognitive-level description cannot fully capture (i.e.
specify in law-like terms) our mental activity. That is, if we want to fully
understand (i.e. account for or predict) the workings of the mind, we cannot
talk at the level of psychology, but must (at least partially) descend towards
the neural level. Smolensky maintains that a sub-symbolic level consisting of
non-semantically evaluable constituents or micro-features of symbols exists,
above the neural level, at which we will be able to fully specify (i.e. capture
nomologically) mental activity.</p>

<p class=MsoNormal>If we reject this stronger thesis of connectionism, we are
left with the (more or less incontrovertible) physiological evidence that the
brain comprises approximately 10<sup>11</sup> neurons, linked by about 10<sup>14</sup>
synapses which are the <span style='color:blue'>main unit of computation</span>.
Since a connectionist system can be seen as a Universal Turing Machine, we can (if
we choose) simply see the neuronal level as implementing the symbols posited by
psychologists and GOFAI researchers.</p>

<p class=MsoNormal>However, I find Smolensky�s view highly congenial � it seems
implausible to me that the labyrinthine workings of the brain can be cleanly
distilled down to a manageable number of discrete boxes (or �modules�, in
Fodor�s sense), each with an informationally-encapsulated, specific domain/function
etc.<a style='mso-footnote-id:ftn2' href="#_ftn2" name="_ftnref2" title=""><span
class=MsoFootnoteReference><span style='mso-special-character:footnote'><![if !supportFootnotes]>[2]<![endif]></span></span></a>
I will this stronger sense of �connectionism� from now on, since I consider it
interesting, powerful and plausible, and only really open to a single extra
objection, the systematicity objection.</p>

<h2>Main</h2>

<h3>Why am I discussing connectionism?</h3>

<p class=MsoNormal>I have raised the issue of connectionism because its success
at explaining and understanding low-level neural phenomena is firmly
established, and there is cause for optimism that it will prove a valid
paradigm for investigation of much, if not all, of the higher levels of the
brain and our behaviour. However, there are a number of <i>a priori</i>
concerns that need to be addressed and laid to rest before this optimism can be
justified.</p>

<h3>Discrete vs analog (probabilistic/statistical???)</h3>

<p class=MsoNormal>The brain is a more or less analog system. It is a dynamical
system operating in real time (as opposed to discrete time-steps), based on
continuous variables like membrane voltage potential, synaptic weight strength
etc. (although admittedly at the atomic level, the quantity of neurotransmitter
at a given synapse is discrete, but this is a moot point). It seems intuitive
that since the computations being performed by the system are analog, and the
outputs also analog, that a neural system could not give discrete responses �
at best, the system might respond with a very high tendency in one direction or
another, but the neurons are not binary, and do not give �true� or �false�
answers, only high or low firing rates. As a result, the sort of binary formal
logic that mathematicians, logicians and rationalists employ seems
inappropriate for such a system. More fundamentally, it seems as though such a
system could never be <i style='mso-bidi-font-style:normal'>certain</i>, in the
way Nagel requires. If it were to turn out that our minds are inherently
probabilistic, and could only consider a proposition to be 99.9% true, or infer
the correct consequences of a belief most of the time, then reason�s primary
position as an ultimately trustworthy source of authority would be
fundamentally, irrecoverably undermined.</p>

<p class=MsoNormal>Fortunately though, our irrationality can not, I believe, be
so easily demonstrated. The objection rests on a confusion between the neural
and behavioural levels, that is, between the way that individual neurons
operate and the way the overall, dynamical system that they comprise operates. A
crucial aspect of a connectionist system�s dynamics relates to its
non-linearity. The most obvious source of this non-linearity is in the
activation function relating neuronal activity (membrane voltage) with firing
rate (rate of action potentials produced). As mentioned above, the activation
of a neuron can be expressed more or less as the weighted (according to the
strength of the synapse) sum of all its inputs. The firing rate is not,
however, proportional to this activity. A low activation may produce the
occasional lonely action potential. However, as the activity increases, the
firing rate will increase non-linearly, up to an asymptote (determined by the
bare minimum �absolutely refractory period� between action potentials that a
neuron requires to �recharge�, so to speak). This non-linear function could be
binary, a threshold linear model, sigmoid or logarithmic<a style='mso-footnote-id:
ftn3' href="#_ftn3" name="_ftnref3" title=""><span class=MsoFootnoteReference><span
style='mso-special-character:footnote'><![if !supportFootnotes]>[3]<![endif]></span></span></a>.
All that matters is that it is not simply linear. This non-linearity gives rise
to peculiar dynamics at a high-level, i.e. ensembles of neurons collectively
forming a distributed representation, which can begin to seem more and more
discrete. We can understand this intuitively if we consider that each neuron
will be only slightly activated if its input neurons are not firing vigorously,
and so will in its turn hardly fire at all. However, if its input neurons are firing
rapidly, its output will be especially high. <span style="mso-spacerun:
yes">�</span>Consequently, at a high level, after numerous successive
computations have been performed, a more-or-less binary output could easily
result.</p>

<p class=MsoNormal>It should of course be noted that the real situation in the
brain is considerably more complicated than has been outlined here. The brain
makes use of graded and patterned firing rates, rather than simply treating the
signal as a mean or �rate� code over a short period of time, and so
incorporating the possible informational content of temporal synchronisation,
e.g. as employed in sound localisation. All consideration of inhibitory
neurons, neurons with spontaneously high firing rates, the effects of random
noise, and competing or inhibitory modules etc. has been stripped from the
account to make the essential point that the brain can be considered to work in
a discrete way at a high level.</p>

<h3>Generality (rationality seems to be able to work in more or less any
domain)</h3>

<p class=MsoNormal>I want now to discuss a deeper concern: to what extent could
a connectionist system be as general in its domain of applicability as Nagel�s
rationality requires?</p>

<p class=MsoNormal>Computational models have demonstrated that simple logic gates
(like AND or OR) can be easily simulated by neural networks. Indeed, much more
complicated functions can be replicated too. However, these might be considered
to be misleadingly simple cases, since the number of possible permutations is
small enough to be contained inside the training set. The system can learn,
like a finite state machine, a set of prescribed absolute responses for the
given input patterns. This is clearly not an option for most problems. One of
the major strengths of a connectionist system is that it can generalise. It
forms prototypes from the data, and is able to gauge the similarity between
given patterns. As a result, it is able to respond appropriately to novel
patterns, and so degrade �gracefully�. Connectionist systems, unlike the
programs running on most desktop computers today, are robust. By this, I mean
that unexpected, erroneous or corrupt data does not bring the system to its
knees. If you feed a neural network damaged or incomplete data, it will settle
into the closest attractor available, based on the weight organisation that has
arisen from its training.</p>

<p class=MsoNormal>Rationality, in order to �arrive at principles that are
universal and exceptionless � to be able to come up with reasons that apply in
all relevantly similar situations, and to have reasons of similar generality
that tell us when situations are relevantly similar�, seems perhaps to require
too much of a network. In a way, this is an empirically question: �Is the data
set to which our brains have been exposed sufficiently broad and representative
for us to be able to reason reliably about the areas to which we apply it?� It
requires an implausible stretch of the imagination to explain how our senses
could provide the data by means of which we could learn to reason mathematically
or logically.</p>

<p class=MsoNormal>This can be seen as another way of asking the same question
that led Alfred Wallace (lesser known co-discover of evolution) astray: �why
would early man require a brain capable of playing chess, writing poetry .
Despite conceiving evolution in more or less the same way as Darwin, and at the
same time, Wallace remained a creationist about intelligence because he
considered modern man�s intelligence to be superior to that of early <i
style='mso-bidi-font-style:normal'>homo sapiens</i> (the savage languages
�contain no words for abstract conceptions; the utter want of foresight of the
savage man beyond his simplest necessities; his inability to combine, or to
compare, or to reason on any general subject that does not immediately appeal
to his senses�<a style='mso-footnote-id:ftn4' href="#_ftn4" name="_ftnref4"
title=""><span class=MsoFootnoteReference><span style='mso-special-character:
footnote'><![if !supportFootnotes]>[4]<![endif]></span></span></a>), and indeed
to be far beyond what is necessary to sustain such a forager lifestyle. The
fact that early and modern man are, at least phylogenetically (that is, as a
species), more or less cognitively equals, can be explained in a number of
ways. I have tried to cover the most important reasons <i style='mso-bidi-font-style:
normal'>why</i> we might have evolved to be rational in the section on
evolution, so in this connectionist section I am interested primarily in <i
style='mso-bidi-font-style:normal'>how</i> it is that our physiology could be
understood as implementing this rationality.</p>

<p class=MsoNormal>The main answer to both similar questions, of the extent to
which a connectionist system could be as general in its domain of applicability
as Nagel�s rationality requires, and of how a connectionist system originally
designed for a forager lifestyle could be capable of playing chess and reasoning
formally is <i style='mso-bidi-font-style:normal'>plasticity</i>.</p>

<p class=MsoNormal>At this point, we have to remember a very obvious point:
people�s reasoning improves with time. This is partly through the basic genetic
and developmental processes that govern our improved hand-eye coordination
through youth, or puberty, for example. However, as evidenced by the effects of
education, human cognitive capacities can be trained in certain directions,
allowing us to build enormous pyramid-like conceptual toolkits. Maths is
probably the most obvious example. To take a very basic example, we learn what
the �addition� operator means through continual, repetitive usage, practicing
sums as small children. Over time, somehow, this process �chunks� into a
simple, atomic �concept� or automaticised �habit of thought� that we can use
unthinkingly when trying to master more complicated concepts which build upon
it, e.g. multiplication, or addition of complex numbers.</p>

<p class=MsoNormal>What we are actually doing is building new, abstract spaces
within which we become increasingly adept at operating<a style='mso-footnote-id:
ftn5' href="#_ftn5" name="_ftnref5" title=""><span class=MsoFootnoteReference><span
style='mso-special-character:footnote'><![if !supportFootnotes]>[5]<![endif]></span></span></a>.
We see this process going on every day � when we learn a new word, there is an
acclimatisation period where it becomes necessary to reiterate the definition
every time we encounter the word, but through usage and repeated encounters, it
nestles into our vocabulary web. Variants of this process are going on when we
learn new languages, mathematics, formal logic, analytic philosophical
reasoning etc. Much more is going on than simply learning new words � we are creating
new domains within which certain mental operations are easy or appropriate,
just as it can be easier to express one idea in one language than another, or
through an image rather than words. These domains piggyback upon and
inter-weave with each other. Certainly, we shouldn't expect to see obvious
delineations at the neural level.</p>

<p class=MsoNormal>If we want to better understand the development of abstract
spaces, there are various simple basic cases to consider. For example, each
sensory modality gives us a different way of perceiving the world, in a trivial
and a non-trivial sense. If there is any doubt that the brain is sufficiently
plastic to self-organise entirely new domains of thought on the fly, there is
plenty of experimental evidence that we are able to, especially for <span
style='color:blue'>language and the somatosensory system, especially as
children</span>.</p>

<p class=MsoNormal>In neurophysiological terms, it is clear that our brains
undergo various genetically-timed stages of progression, especially during our
earliest years, initially forming an enormous profusion of synaptic connections
that are subsequently pruned. This is not what I am really referring to � as we
progress through education, even long beyond the point at which our brains are
undergoing developmental (i.e. internally-prescribed) changes, our ability to
reason improves. We are continually forming new conceptual spaces, and this
improvement is incremental. This is related to the reason that maths, for
instance, requires an element of trudging practice that cannot be avoided. An
essential part of learning a new theory or technique is practicing it,
repeatedly, with different problems. In this way, we are expanding our set of
training data to be more representative of a given problem domain, and in the
process expanding the generalisation ability of our reasoning. This is exactly what
philosophers do when they read each other�s work, expanding their training
data.</p>

<p class=MsoNormal><span style='color:blue'>Of course, this makes one rather
big assumption � it assumes that philosophy, or even the separate areas of
philosophy, can in some way be divided up into domains within which exposure to
�training data� (i.e. the literature), is helpful.</span></p>

<h3>Penrose � non-computable human mental functioning</h3>

<p class=MsoNormal>Perhaps the broadest criticism of all such approaches stems
from Godel's theorem, most famously advocated with relation to the mind-body problem
by Lucas, and more recently, Penrose<a style='mso-footnote-id:ftn6'
href="#_ftn6" name="_ftnref6" title=""><span class=MsoFootnoteReference><span
style='mso-special-character:footnote'><![if !supportFootnotes]>[6]<![endif]></span></span></a>.
Godel's theory states that in a formal system of above a certain complexity,
there will always be formally-undecidable, true propositions, i.e. statements
that are true, but which cannot be proved within the system. This thwarted
attempts like Russell and Whitehead's Principia Mathematica to found the whole
of mathematics on a minimal set of principles (axioms). It also poses problems
for connectionist systems. Part of the appeal of a connectionist system is that
it can be seen as a Universal Turing Machine. Consequently though, formally
non-computable functions cannot be implemented finitely by such a system.
Penrose argues that the brain (i.e. people) *can* do this, and so our minds
must be more than Turing machines.</p>

<p class=MsoNormal>Of course, Penrose is himself a physicist and mathematician
foremost, and so very much a believer about reason�s objectivism. He proposes
that there must be more going on in the brain than we're currently aware of at
the sub-neural level - he speculates that there may be quantum effects in
microtubules in the brain that allow us to perform non-computable functions,
that allow us to see outside the system, where even a very fast machine (such
as Deep Blue) would flounder and fail to make the meta-inference.</p>

<p class=MsoNormal>This is a tricky area to discuss, since Penrose�s extensive
proof would be the initial point of attack, but the mathematics are beyond the
scope of this paper. As a result I intend to skirt the issue. However, it is
worth noting that there is very little evidence to support Penrose�s
substantive claims (about the quantum micro-tubules) and that the issue of
human fallibility may complicate the picture of the brain as a normal formal
system.</p>

<p class=MsoNormal>If Penrose were to prove right, then almost all of the debate
currently centring around the capabilities of purely connectionist systems
becomes almost irrelevant, because the nature of such a quantum system would
probably be unimaginably different and more powerful. If anything, I would be
more tempted to ask what limitations such a hypothetical system would have, and
whether our brains are actually much more limited-seeming than one would expect
of such a system.</p>

<h3>Hard-wired neural representations</h3>

<p class=MsoNormal>Pursuing a greater understanding of our genome, and the way
in which it gives rise to a fully-functioning human body and mind is one of the
main focuses of current scientific efforts. We have every reason to consider it
an area that will eventually yield to standard empirical techniques, laced with
the usual input of conceptual imagination and brute computational power that
all frontier science requires.</p>

<p class=MsoNormal>Firstly, we can build up our understanding by considering
far simpler genetic mechanisms in simpler organisms first. Moreover, especially
with such organisms, we are not bound by ethical constraints, and can
experimentally manipulate and so observe the relationship between genotype and
phenotype. The situation is more complicated when considering the human genome,
since we cannot simply alter a gene here or there and dispassionately note the
result. Secondly, the situation is incomparably more complex. Indeed, this is
the major difficulty facing us when we try and decode our DNA � unlike
planetary bodies and neural networks, DNA may not be formalisable or reducible
to a set of underlying dynamic equations. Our scientific toolkit has trouble
dealing with irreducibly complex systems, where one component affects another,
which in turn has affects a multitude of other genes, each of which has a
direct or indirect effect back. This is the case with our genome. Each gene
expresses itself in terms of proteins, which have various effects on each
other. This is still the low level. At a higher level, the mass of protein
interactions results in the cellular system that makes up the human body,
including the brain. Perhaps the only way to understand such a system will be
to simulate it.</p>

<p class=MsoNormal>The best understanding available involves an interaction
between our genotype and our environment, which results in our eventual
phenotype. That is, the way we are and the way our body becomes is an
interaction of our genes and the experiences we have. In terms of neural
development, this can be expressed in terms of internal (developmental) and
external (learning) processes. The �nature-nurture� debate has thus decomposed
into a discussion of the relative proportions with which either factor
contributes, and under which circumstances. This duality is usually termed
�interactionism�.</p>

<p class=MsoNormal>Tooby and Cosmides� notions of ecological rationality,
speculating that we are genetically hard-wired to be cognitively well-suited to
certain domains of action and Nozick�s stronger notion of chains of reasoning
that have become automaticised to seem �self-evident� are requiring our genes
to be able to quite precisely specify neural representations for such ideas and
behaviour. There is some debate about the degree of control our genes could
have over low-level synaptic organisation, or whether in fact the neural
constraints are very broad, determining only architectural or timing parameters
perhaps<a style='mso-footnote-id:ftn7' href="#_ftn7" name="_ftnref7" title=""><span
class=MsoFootnoteReference><span style='mso-special-character:footnote'><![if !supportFootnotes]>[7]<![endif]></span></span></a>.
This is ultimately an empirical issue, but one that is unlikely to be
categorically settled for a considerable time. It seems implausible to me
though that our DNA would code for such regularities as the assumption of other
minds, or of an external world), but the possibility cannot be dismissed. This
certainly makes things easier for Tooby &amp; Cosmides, and for Nozick.</p>

<h3>Systematicity (cf Chomsky�s argument about combinatorial explosion etc.???)</h3>

<p class=MsoNormal>The problem of systematicity relates specifically to the
thesis that the sub-symbolic level is the highest level at which the workings
of the mind can be fully specified.</p>

<p class=MsoNormal>When we reason, or indeed form a sentence, we relate a
series of symbols (whether words, propositions, names etc.???) inter-changeably
together by syntax � although connectionist models can be trained to be
systematic, they can also be trained, for example, to recognize �John loves
Mary� without being able to recognize �Mary loves John� (the problem of
�systematicity�).</p>

<p class=MsoNormal>Although in principle, this seems like quite a telling
objection, it need not be. Smolensky proposes one solution. Effectively, it
involves a distributed representation composed of pairs of neurons (or more
likely, pairs of mini-ensembles). One of the pair specifies the content (e.g.
the word), and the other specifies the role being played (i.e. the position in
the sentence). A string of such pairs could thus specify both:</p>

<p class=MsoNormal style='margin-left:17.85pt'>(loves, 2) (John, 1) (Mary, 3) =
John loves Mary</p>

<p class=MsoNormal style='margin-left:17.85pt'>or</p>

<p class=MsoNormal style='margin-left:17.85pt'>(loves, 2) (John, 3) (Mary, 1) =
Mary loves John</p>

<p class=MsoNormal>Admittedly, this solution is inelegant, probably impractical
and inflexible, and biologically implausible, but it does neatly settle the
central issue raised by Fodor, of how a formal syntax <i style='mso-bidi-font-style:
normal'>could</i> be implemented in a distributed connectionist system. Fodor�s
attack would be more problematic for early straw man ideas of lexical
processing which hypothesised separate, synchronised lists of words categorised
by part of speech, for instance.</p>

<h2>How can connectionism inform our understanding of rationality?</h2>

<p class=MsoNormal>I am going to contend that some variant on these claims will
remain the dominant way of thinking about the mind and brain for the
foreseeable future, and that this should inform our understanding of
rationality in a number of ways. To some degree, adherence to this picture
narrows down what we can be capable of as connectionist-implemented
rationalists - most notably, it serves as a constant reminder of our finitude
(see my discussion of Cherniak�s �minimal rationality� below). At the same time
though, it may helpfully flesh out our conception of ourselves as rational
beings, partly by restricting or constraining the number and type of possible
explanations, and partly by providing a good idea of the sort of properties we
should expect to find.</p>

<p class=MsoNormal>Hopefully, considering ourselves as
connectionist-rationalists might give us a new approach to the problem of
alternate rationalities (i.e. 'conceptual schemes'). I am thinking of the
low-level differences between the brain of every human on the planet, despite
being very similar macroscopically. In terms of the actual computation being
performed, nobody thinks in exactly the same way. It is an empirical question
how similar our brains are - but it is certainly clear that mapping an area
from one brain to the corresponding location in another brain is far from easy
(as neuroimaging researchers constantly find). It may be that these differences
amount to more or less identical computational processes at a higher level. One
might imagine such functionally irrelevant differences as being analogous to
the difference between, say, <i style='mso-bidi-font-style:normal'>2(a + b)</i>
and <i style='mso-bidi-font-style:normal'>2a + 2b</i>.</p>

<p class=MsoNormal><span style='color:blue'>Perhaps, if we were able to say how
people�s brains differ in terms of the computations being performed, we might
eventually begin to trace a broad schema of computational approaches which
qualify as rational, to a greater or lesser degree. In fact, a growing number
of approaches seek an understanding of the mind in terms of numerous
interacting components, moving away from the �monolithic internal models,
monolithic control, and general purpose processing� of �classical AI� (Brooks
et. al (MIT), Dennett�s multiple drafts, Fodor�s modules). I will discuss some
ideas for how these interacting cognitive components comprising �rationality�
might be taxonomised.<o:p></o:p></span></p>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

</div>

<div style='mso-element:footnote-list'><![if !supportFootnotes]><br clear=all>

<hr align=left size=1 width="33%">

<![endif]>

<div style='mso-element:footnote' id=ftn1>

<p class=MsoFootnoteText><a style='mso-footnote-id:ftn1' href="#_ftnref1"
name="_ftn1" title=""><span class=MsoFootnoteReference><span style='mso-special-character:
footnote'><![if !supportFootnotes]>[1]<![endif]></span></span></a> Hebb, D.O.
(1949). <i>The organization of behavior</i>. New York: Wiley</p>

</div>

<div style='mso-element:footnote' id=ftn2>

<p class=MsoFootnoteText><a style='mso-footnote-id:ftn2' href="#_ftnref2"
name="_ftn2" title=""><span class=MsoFootnoteReference><span style='mso-special-character:
footnote'><![if !supportFootnotes]>[2]<![endif]></span></span></a> Fodor, <i
style='mso-bidi-font-style:normal'>Modularity of mind</i>. Fodor defines a
�module� in terms of nine features, of which I have mentioned two of the most
important. The others are: mandatory; central systems have limited access to
the representations computed by input systems; fast; informationally
encapsulated; input systems have &quot;shallow&quot; outputs; associated with
fixed neural architecture; exhibit characteristic and specific breakdown
patterns; their ontological development exhibits a characteristic pace and
sequencing.</p>

</div>

<div style='mso-element:footnote' id=ftn3>

<p class=MsoFootnoteText><a style='mso-footnote-id:ftn3' href="#_ftnref3"
name="_ftn3" title=""><span class=MsoFootnoteReference><span style='mso-special-character:
footnote'><![if !supportFootnotes]>[3]<![endif]></span></span></a> Rolls, <i
style='mso-bidi-font-style:normal'>Brain and Emotion</i></p>

</div>

<div style='mso-element:footnote' id=ftn4>

<p class=MsoFootnoteText><a style='mso-footnote-id:ftn4' href="#_ftnref4"
name="_ftn4" title=""><span class=MsoFootnoteReference><span style='mso-special-character:
footnote'><![if !supportFootnotes]>[4]<![endif]></span></span></a> Wallace,
cited in Pinker, <i style='mso-bidi-font-style:normal'>How the mind works<o:p></o:p></i></p>

</div>

<div style='mso-element:footnote' id=ftn5>

<p class=MsoFootnoteText><a style='mso-footnote-id:ftn5' href="#_ftnref5"
name="_ftn5" title=""><span class=MsoFootnoteReference><span style='mso-special-character:
footnote'><![if !supportFootnotes]>[5]<![endif]></span></span></a> Plunkett,
personal communication</p>

</div>

<div style='mso-element:footnote' id=ftn6>

<p class=MsoFootnoteText><a style='mso-footnote-id:ftn6' href="#_ftnref6"
name="_ftn6" title=""><span class=MsoFootnoteReference><span style='mso-special-character:
footnote'><![if !supportFootnotes]>[6]<![endif]></span></span></a> Penrose, <i
style='mso-bidi-font-style:normal'>Shadows of the mind</i></p>

</div>

<div style='mso-element:footnote' id=ftn7>

<p class=MsoFootnoteText><a style='mso-footnote-id:ftn7' href="#_ftnref7"
name="_ftn7" title=""><span class=MsoFootnoteReference><span style='mso-special-character:
footnote'><![if !supportFootnotes]>[7]<![endif]></span></span></a> Elman et
al., <i style='mso-bidi-font-style:normal'>Rethinking innateness<o:p></o:p></i></p>

</div>

</div>

</body>

</html>
