<html xmlns:o="urn:schemas-microsoft-com:office:office"
xmlns:w="urn:schemas-microsoft-com:office:word"
xmlns="http://www.w3.org/TR/REC-html40">

<head>
<meta http-equiv=Content-Type content="text/html; charset=windows-1252">
<meta name=ProgId content=Word.Document>
<meta name=Generator content="Microsoft Word 9">
<meta name=Originator content="Microsoft Word 9">
<link rel=File-List
href="essay%20-%20thesis,%20rationality%20c%20-%20connectionism%202_filelist.xml">
<title>Title</title>
<!--[if gte mso 9]><xml>
 <o:DocumentProperties>
  <o:Author>Greg Detre</o:Author>
  <o:LastAuthor>Greg Detre</o:LastAuthor>
  <o:Revision>2</o:Revision>
  <o:TotalTime>1114</o:TotalTime>
  <o:Created>2003-07-02T01:00:00Z</o:Created>
  <o:LastSaved>2003-07-02T01:00:00Z</o:LastSaved>
  <o:Pages>1</o:Pages>
  <o:Words>2995</o:Words>
  <o:Characters>17076</o:Characters>
  <o:Company>-</o:Company>
  <o:Lines>142</o:Lines>
  <o:Paragraphs>34</o:Paragraphs>
  <o:CharactersWithSpaces>20970</o:CharactersWithSpaces>
  <o:Version>9.2720</o:Version>
 </o:DocumentProperties>
 <o:OfficeDocumentSettings>
  <o:DoNotOrganizeInFolder/>
 </o:OfficeDocumentSettings>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:DrawingGridHorizontalSpacing>4.5 pt</w:DrawingGridHorizontalSpacing>
  <w:DrawingGridVerticalSpacing>12.25 pt</w:DrawingGridVerticalSpacing>
  <w:DisplayHorizontalDrawingGridEvery>0</w:DisplayHorizontalDrawingGridEvery>
  <w:Compatibility>
   <w:WW6BorderRules/>
   <w:FootnoteLayoutLikeWW8/>
   <w:ShapeLayoutLikeWW8/>
   <w:AlignTablesRowByRow/>
   <w:ForgetLastTabAlignment/>
   <w:LayoutRawTableWidth/>
   <w:LayoutTableRowsApart/>
  </w:Compatibility>
 </w:WordDocument>
</xml><![endif]-->
<style>
<!--
 /* Font Definitions */
@font-face
	{font-family:Wingdings;
	panose-1:5 0 0 0 0 0 0 0 0 0;
	mso-font-charset:2;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:0 268435456 0 0 -2147483648 0;}
@font-face
	{font-family:"Book Antiqua";
	panose-1:2 4 6 2 5 3 5 3 3 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:647 0 0 0 159 0;}
@font-face
	{font-family:Tahoma;
	panose-1:2 11 6 4 3 5 4 4 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:553679495 -2147483648 8 0 66047 0;}
 /* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{mso-style-parent:"";
	margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:12.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-language:EN-GB;}
h1
	{mso-style-next:Normal;
	margin-top:0in;
	margin-right:0in;
	margin-bottom:6.0pt;
	margin-left:0in;
	text-align:center;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	mso-outline-level:1;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:12.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	color:purple;
	mso-font-kerning:14.0pt;
	mso-fareast-language:EN-GB;
	mso-bidi-font-weight:normal;
	font-style:italic;
	mso-bidi-font-style:normal;}
h2
	{mso-style-next:Normal;
	margin-top:16.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	mso-outline-level:2;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:12.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	color:navy;
	mso-fareast-language:EN-GB;
	mso-bidi-font-weight:normal;
	font-style:italic;
	mso-bidi-font-style:normal;}
h3
	{mso-style-next:Normal;
	margin-top:16.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	mso-outline-level:3;
	tab-stops:right 451.45pt;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:12.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	color:green;
	mso-fareast-language:EN-GB;
	font-weight:normal;
	font-style:italic;
	mso-bidi-font-style:normal;}
h4
	{mso-style-next:Normal;
	margin-top:12.0pt;
	margin-right:0in;
	margin-bottom:3.0pt;
	margin-left:0in;
	text-align:justify;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	mso-outline-level:4;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:12.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:Arial;
	mso-bidi-font-family:"Times New Roman";
	mso-fareast-language:EN-GB;
	mso-bidi-font-weight:normal;}
h5
	{mso-style-next:Normal;
	margin-top:10.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	mso-outline-level:5;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:12.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	color:maroon;
	mso-fareast-language:EN-GB;
	font-weight:normal;
	text-decoration:underline;
	text-underline:single;}
h6
	{mso-style-parent:"Heading 5";
	mso-style-next:Normal;
	margin-top:9.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:.5in;
	margin-bottom:.0001pt;
	text-align:justify;
	text-indent:-.25in;
	mso-pagination:widow-orphan;
	mso-outline-level:6;
	mso-list:l3 level1 lfo10;
	tab-stops:list .5in;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:12.0pt;
	mso-bidi-font-size:11.0pt;
	font-family:"Times New Roman";
	color:olive;
	mso-fareast-language:EN-GB;
	font-weight:normal;
	mso-bidi-font-weight:bold;
	text-underline:#33CCCC;}
p.MsoToc1, li.MsoToc1, div.MsoToc1
	{mso-style-parent:"Heading 1";
	mso-style-next:Normal;
	margin-top:3.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	tab-stops:.75in right 451.45pt;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:11.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	font-variant:small-caps;
	color:purple;
	mso-font-kerning:14.0pt;
	mso-fareast-language:EN-GB;
	font-weight:bold;
	mso-bidi-font-weight:normal;
	font-style:italic;
	mso-bidi-font-style:normal;}
p.MsoToc2, li.MsoToc2, div.MsoToc2
	{mso-style-parent:"Heading 2";
	mso-style-next:Normal;
	margin-top:3.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:10.1pt;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	tab-stops:right 451.3pt;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	color:navy;
	mso-fareast-language:EN-GB;
	font-style:italic;
	mso-bidi-font-style:normal;}
p.MsoToc3, li.MsoToc3, div.MsoToc3
	{mso-style-parent:"TOC 2";
	mso-style-next:Normal;
	margin-top:3.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:20.0pt;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	tab-stops:right 451.45pt;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:9.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	color:teal;
	mso-fareast-language:EN-GB;
	font-style:italic;
	mso-bidi-font-style:normal;}
p.MsoToc4, li.MsoToc4, div.MsoToc4
	{mso-style-update:auto;
	mso-style-parent:"TOC 3";
	mso-style-next:Normal;
	margin-top:3.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:35.7pt;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	tab-stops:right 451.45pt;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:7.5pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	color:maroon;
	mso-fareast-language:EN-GB;
	mso-bidi-font-weight:bold;
	font-style:italic;
	mso-bidi-font-style:normal;}
p.MsoFootnoteText, li.MsoFootnoteText, div.MsoFootnoteText
	{margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-language:EN-GB;}
p.MsoCommentText, li.MsoCommentText, div.MsoCommentText
	{margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-language:EN-GB;}
p.MsoHeader, li.MsoHeader, div.MsoHeader
	{margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	tab-stops:center 239.75pt right 6.65in;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:11.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-language:EN-GB;
	font-style:italic;
	mso-bidi-font-style:normal;}
span.MsoFootnoteReference
	{vertical-align:super;}
span.MsoCommentReference
	{mso-ansi-font-size:8.0pt;
	mso-bidi-font-size:8.0pt;}
p.MsoListNumber, li.MsoListNumber, div.MsoListNumber
	{margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:.25in;
	margin-bottom:.0001pt;
	text-align:justify;
	text-indent:-.25in;
	mso-pagination:widow-orphan;
	mso-list:l0 level1 lfo8;
	tab-stops:list .25in;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:12.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-language:EN-GB;}
p.MsoDate, li.MsoDate, div.MsoDate
	{margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:right;
	mso-pagination:widow-orphan;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:11.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-language:EN-GB;
	font-style:italic;
	mso-bidi-font-style:normal;}
p.MsoDocumentMap, li.MsoDocumentMap, div.MsoDocumentMap
	{margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	background:navy;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:12.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:Tahoma;
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-language:EN-GB;}
p.Section, li.Section, div.Section
	{mso-style-name:Section;
	margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:center;
	mso-pagination:widow-orphan;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:12.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-language:EN-GB;
	font-weight:bold;
	mso-bidi-font-weight:normal;}
p.Heading0, li.Heading0, div.Heading0
	{mso-style-name:"Heading 0";
	mso-style-parent:"Heading 1";
	margin-top:6.0pt;
	margin-right:0in;
	margin-bottom:6.0pt;
	margin-left:0in;
	text-align:center;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	mso-outline-level:1;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	border:none;
	mso-border-alt:solid windowtext .5pt;
	padding:0in;
	mso-padding-alt:1.0pt 4.0pt 1.0pt 4.0pt;
	font-size:16.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Book Antiqua";
	mso-fareast-font-family:"Times New Roman";
	mso-bidi-font-family:"Times New Roman";
	font-variant:small-caps;
	color:purple;
	mso-fareast-language:EN-GB;
	font-weight:bold;
	mso-bidi-font-weight:normal;}
p.CommentSubject, li.CommentSubject, div.CommentSubject
	{mso-style-name:"Comment Subject";
	mso-style-parent:"Comment Text";
	mso-style-next:"Comment Text";
	margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-language:EN-GB;
	font-weight:bold;}
p.BalloonText, li.BalloonText, div.BalloonText
	{mso-style-name:"Balloon Text";
	margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:8.0pt;
	font-family:Tahoma;
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-language:EN-GB;}
@page Section1
	{size:595.3pt 841.9pt;
	margin:68.05pt 68.05pt 68.05pt 68.05pt;
	mso-header-margin:.5in;
	mso-footer-margin:.5in;
	mso-paper-source:0;}
div.Section1
	{page:Section1;}
 /* List Definitions */
@list l0
	{mso-list-id:-120;
	mso-list-type:simple;
	mso-list-template-ids:-1247397174;}
@list l0:level1
	{mso-level-style-link:"List Number";
	mso-level-tab-stop:.25in;
	mso-level-number-position:left;
	margin-left:.25in;
	text-indent:-.25in;}
@list l1
	{mso-list-id:1103186221;
	mso-list-type:hybrid;
	mso-list-template-ids:89585846 134807567 134807577 134807579 134807567 134807577 134807579 134807567 134807577 134807579;}
@list l1:level1
	{mso-level-tab-stop:.5in;
	mso-level-number-position:left;
	text-indent:-.25in;}
@list l2
	{mso-list-id:1470240892;
	mso-list-type:hybrid;
	mso-list-template-ids:-318178384 1685484530 67698713 67698715 67698703 67698713 67698715 67698703 67698713 67698715;}
@list l2:level1
	{mso-level-tab-stop:.25in;
	mso-level-number-position:left;
	margin-left:17.85pt;
	text-indent:-17.85pt;}
@list l3
	{mso-list-id:1476406644;
	mso-list-type:hybrid;
	mso-list-template-ids:168605670 266271734 67698691 67698693 67698689 67698691 67698693 67698689 67698691 67698693;}
@list l3:level1
	{mso-level-number-format:bullet;
	mso-level-style-link:"Heading 6";
	mso-level-text:o;
	mso-level-tab-stop:.5in;
	mso-level-number-position:left;
	text-indent:-.25in;
	font-family:"Courier New";
	mso-bidi-font-family:"Times New Roman";}
@list l3:level2
	{mso-level-tab-stop:1.0in;
	mso-level-number-position:left;
	text-indent:-.25in;}
@list l4
	{mso-list-id:1746143482;
	mso-list-type:simple;
	mso-list-template-ids:-719658964;}
@list l4:level1
	{mso-level-tab-stop:.25in;
	mso-level-number-position:left;
	margin-left:.25in;
	text-indent:-.25in;}
ol
	{margin-bottom:0in;}
ul
	{margin-bottom:0in;}
-->
</style>
</head>

<body lang=EN-GB style='tab-interval:17.85pt'>

<div class=Section1>

<h1><span style='color:windowtext;font-weight:normal'>Is a naturalistic account
of reason compatible with its objectivity?<o:p></o:p></span></h1>

<h1><span style='color:windowtext'>Can rational objectivism be implemented in a
connectionist system (like the brain)?<o:p></o:p></span></h1>

<p class=MsoNormal align=right style='text-align:right'>Greg Detre</p>

<p class=MsoNormal align=right style='margin-top:2.0pt;text-align:right'>Tuesday,
January 29, 2002</p>

<p class=MsoNormal align=right style='margin-top:2.0pt;text-align:right'>Dr
Tasioulas</p>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<h2>Introduction</h2>

<p class=MsoNormal>At root, connectionism amounts to the thesis that the brain
is a dynamical system, a mathematically modellable complex of levers and
pulleys, or in this case, neurons and synapses. The high-level behaviour of the
system seems to emerge like magic out of a morass of low-level interactions,
just as the seemingly-centralised wheeling and coordination of a flock of birds
results from each bird paying attention to the position and speed of its
neighbours (local rules).</p>

<h3>Define connectionism</h3>

<p class=MsoNormal>More specifically, connectionism refers to the family of
theories that aim to understand mental abilities in terms of formalised models
of the brain. These usually employ large numbers of nodes (neurons), with
weighted inter-connections (synapses). The firing rate of a neuron is usually some
non-linear function (e.g. sigmoid) of its activity, which is calculated as the
weighted sum of the firing rates of neurons that synapse onto it. In this way,
activity is propagated over time (milliseconds, in practice) in parallel from
the input neurons eventually to the output neurons.</p>

<p class=MsoNormal>Input neurons are defined as those whose activation is (at
least partially) determined by the external environment (in the case of the
brain, various sensory receptors), and output neurons are those which affect
some change in the system�s behaviour in that environment (e.g. motor neurons
connected to muscle) � hidden neurons are those whose activity is invisible to
the environment.</p>

<p class=MsoNormal>What makes neural networks interesting is their ability to
self-organise, or �learn�, by modifying their weights according to a learning
algorithm. The simplest are the Hebbian-type learning rules<a style='mso-footnote-id:
ftn1' href="#_ftn1" name="_ftnref1" title=""><span class=MsoFootnoteReference><span
style='mso-special-character:footnote'><![if !supportFootnotes]>[1]<![endif]></span></span></a>,
which are based on the principle:</p>

<p class=MsoNormal style='margin-left:17.85pt'>the synapse between two neurons should
be strengthened if the neurons fire simultaneously</p>

<p class=MsoNormal>This can be implemented in a pattern-associator, an
architecture for associating a set of input patterns with a set of
pre-specified output patterns. Innumerable improvements and revisions have been
employed, and the Hebbian rule really only works well for orthogonal (i.e.
uncorrelated) input patterns, but its human-like robustness and ability to
generalise are notable. When presented with a novel pattern which is similar
but not identical to a learned input pattern, its output will be similar or
identical to the learned output pattern. It can be seen to generalise to new
data, and form prototypes based on families of resemblance between input
patterns, both of which features had to be explicitly, inelegantly and
inefficiently built into previous symbolic models.</p>

<h3>Smolensky�s stronger claim of �connectionism�</h3>

<p class=MsoNormal>Before continuing, I want to mention a second, stronger
sense in which the term �connectionism� is used as a thesis about the workings
of the mind. The stronger claim, as espoused by Smolensky, can be stated
negatively: a symbolic, cognitive-level description cannot fully capture (i.e.
specify in law-like terms) our mental activity. That is, if we want to fully
understand (i.e. account for or predict) the workings of the mind, we cannot
talk at the level of psychology, but must (at least partially) descend towards
the neural level. Smolensky maintains that a sub-symbolic level consisting of
non-semantically evaluable constituents or micro-features of symbols exists,
above the neural level, at which we will be able to fully specify (i.e. capture
nomologically) mental activity.</p>

<p class=MsoNormal>If we reject this stronger thesis of connectionism, we are
left with the (more or less incontrovertible) physiological evidence that the
brain comprises approximately 10<sup>11</sup> neurons, linked by about 10<sup>14</sup>
synapses which are the <span style='color:blue'>main unit of computation</span>.
Since a connectionist system can be seen as a Universal Turing Machine, we can
simply see the neuronal level as implementing the symbols posited by
psychologists and GOFAI researchers.</p>

<p class=MsoNormal>I find Smolensky�s view highly congenial � it seems implausible
to me that the labyrinthine workings of the brain can be cleanly distilled down
to a manageable number of discrete boxes (or �modules�, in Fodor�s sense), each
with an informationally-encapsulated, specific domain/function etc.<a
style='mso-footnote-id:ftn2' href="#_ftn2" name="_ftnref2" title=""><span
class=MsoFootnoteReference><span style='mso-special-character:footnote'><![if !supportFootnotes]>[2]<![endif]></span></span></a>
I will adopt this stronger sense of �connectionism� from now on, since it is
only really the systematicity objection that relates to it specifically (and
not to the weaker claim), and I think this can be met in various ways.</p>

<h2>Main</h2>

<p class=MsoNormal>What problems might be raised when considering how a
connectionist system could implement rationality? Is there hope that a
connectionist system could implement rationality?</p>

<h3>Discrete vs analogue (probabilistic/statistical???)</h3>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<p class=MsoNormal>ah, but that�s where the low-level non-linearity resolves
into more or less discrete results at a high level</p>

<h3>We don't evolve representations</h3>

<p class=MsoNormal>the DNA may constrain things into representations, allowing
the interactionist to more or less posit innate ideas</p>

<h3>Systematicity (cf Chomsky�s argument about combinatorial explosion etc.???)</h3>

<p class=MsoNormal>systematicity possible in connectionist systems � see
Smolensky</p>

<h3>Generality (rationality seems to be able to work in more or less any
domain)</h3>

<h3>Penrose � non-computable human mental functioning</h3>

<p class=MsoNormal>fallibility???</p>

<p class=MsoNormal>2 formal systems, watching each other???</p>

<p class=MsoNormal>how doe the quantum help???</p>

<p class=MsoNormal>The mathematics of </p>

<h2>Discussion</h2>

<p class=MsoNormal>Nozick�s account is attractive in a number of ways. It can
be accommodated with minimal metaphysical commitments, </p>

<p class=MsoNormal>Its price is that it does not really face Nagel head on �
Nozick is content to admit that he is not explaining rationality �from first
principles�(???) � he is presupposing a degree of rationality in order to
consider oneself rationally. And, as I will discuss later, this is the only
position that I think we <i style='mso-bidi-font-style:normal'>can</i> take as
philosophers. On the one hand, we face an empty, skeptical suspension of belief
since we recognise that in order to hold <i style='mso-bidi-font-style:normal'>any</i>
justified beliefs whatsoever, we first require a justified belief about our
ability to form such beliefs. And yet, in suspending our belief, we have already
recognised that this is the only <i style='mso-bidi-font-style:normal'>rational</i>
option. In this way, Nagel�s characterisation of �thoughts that we cannot get
outside of� is particularly appropriate.</p>

<p class=MsoNormal>In a way, it�s obvious that we could never monitor our
entire brain � with what would we be doing the monitoring? Where can we stand
that we can view our position from any position but our own? Can we turn our
eyes back upon our own skull (in a more meaningful sense than just the
eyeball-rolling party trick)?</p>

<p class=MsoNormal><span style='color:blue'>So we have little choice but to
accept that simply being able to frame the question of one�s own rationality is
a sort of base condition for rationality. Doubting is, of necessity, a kind of <i
style='mso-bidi-font-style:normal'>rational</i> thinking. Descartes� <i
style='mso-bidi-font-style:normal'>cogito</i> may thus serve instead to
bootstrap us into knowledge of our own rationality.<o:p></o:p></span></p>

<p class=MsoNormal>Perhaps it�s not so much the doubting about questioning
one�s own rationality, as simply being able to conceive of rationality at all.
Perhaps the complex notion of rationality is its own key. Being able to
conceive abstractly of context-independent, formal, generalisable methods and
propositions, or perhaps the notions of context-independence, formality,
generalisability, method or proposition collectively form the tip of a
cognitive framework iceberg comprising a syntax-manipulating, representation-of-representation
mind, even a fallible, specialised, evolved one.</p>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<p class=MsoNormal><span style='color:blue'>Define functionalism<o:p></o:p></span></p>

<p class=MsoNormal>I am going to contend that some variant on these claims will
remain the dominant way of thinking about the mind and brain for the
foreseeable future, and that this should inform our understanding of
rationality in a number of ways. To some degree, adherence to this picture
narrows down what we can be capable of as
connectionist/functionalist-implemented rationalists - most notably, it serves
as a constant reminder of our finitude (see Cherniak???).</p>

<p class=MsoNormal>At the same time though, it may helpfully flesh out our
conception of ourselves as rational beings, partly by restricting or
constraining the number and type of possible explanations, and partly by
providing a good idea of the sort of properties we should expect to find.</p>

<p class=MsoNormal>Hopefully, considering ourselves as
connectionist-rationalists might give us a new approach to the problem of
alternate rationalities (i.e. 'conceptual schemes'). I am not thinking of
'multiple realisablity' here - this is the term that functionalists use to mean
that the same abstract organisation, the same underlying function, and so the
same mental abilities, could be implemented in physically very different
systems (e.g. a silicon chip could be functionally identical to a biological
brain). Rather, I am thinking of the low-level differences between the brain of
every human on the planet, despite being very similar macroscopically. In terms
of the actual computation being performed, nobody thinks in exactly the same
way. It is an empirical question how similar our brains are - but it is
certainly clear that mapping an area from one brain to the corresponding
location in another brain is far from easy (as neuroimaging researchers
constantly find). It may be that these differences amount to more or less
identical computational processes at a higher level. One might imagine such
functionally irrelevant differences as being analogous to the difference
between, say, a + (b + c) and (a + b) + c. Perhaps, if we were able to say how
people�s brains differ in terms of the computations being performed, we might
eventually begin to trace a broad schema of computational approaches which
qualify as rational, to a greater or lesser degree. In fact, a growing number
of approaches seek an understanding of the mind in terms of numerous
interacting components, moving away from the �monolithic internal models,
monolithic control, and general purpose processing� of �classical AI� (Brooks
et. al (MIT), Dennett�s multiple drafts, Fodor�s modules).</p>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<p class=MsoNormal>There are certain problems with trying to square
connectionism with rationality. Some are relatively general difficulties with
connectionism, in its various forms. Others stem from a seeming incompatibility
between the two.</p>

<p class=MsoNormal>Perhaps the broadest criticism of all such approaches stems
from Godel's theorem, most famously advocated with relation to the mind-body
problem by Lucas, and more recently, Penrose. Godel's theory states that in a
formal system of above a certain complexity, there will always be
formally-undecidable, true propositions, i.e. statements that are true, but
which cannot be proved within the system. This thwarted attempts like Russell
and Whitehead's Principia Mathematica to found the whole of mathematics on a
minimal set of principles (axioms). It also poses problems for connectionist
systems. Part of the appeal of a connectionist system is that it can be seen as
a Universal Turing Machine. Consequently though, formally non-computable
functions cannot be implemented finitely by such a system. Penrose argues that
the brain (i.e. people) *can* do this, and so our minds must be more than
Turing machines. As he argues, there must be more going on in the brain than
we're currently aware of at the neural or even sub-neural level - he speculates
that there may be quantum effects in microtubules in the brain that allow us to
... If Penrose is right, then almost all of the debate currently centring
around the capabilities of purely connectionist systems becomes almost
irrelevant, because the power of such a quantum system could potentially be of
an unimaginably greater magnitude. The first questions would relate to what
limitations such a system would have, and why our brains are so much more
limited-seeming than one would expect of such a system.</p>

<p class=MsoNormal>There are a number of related issues specific to
connectionism to consider. To what extent could a connectionist system be as
general in its applicability as Nagel�s rationality requires? When we reason,
or indeed form a sentence, we relate a series of symbols (whether words,
propositions, names etc.???) inter-changeably together by syntax � although
connectionist models can be trained to be systematic, they can also be trained,
for example, to recognize �John loves Mary� without being able to recognize
�Mary loves John� (the problem of �systematicity�). When a connectionist system
represents a proposition as a vector of synaptic weights, is it really <i
style='mso-bidi-font-style:normal'>understanding</i> the proposition? </p>

<p class=MsoNormal>To an extent, these parallel the debate in evolutionary
epistemology about the extent to which true beliefs are adaptive, and that
truth-tracking could have been selected for. </p>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<p class=MsoNormal>The idea of the brain as a rational machine brings up the
two related issues of discreteness and generalisation.</p>

<p class=MsoNormal>The brain is a more or less analogue system. It is a
dynamical system operating in real time (as opposed to discrete time-steps),
based on continuous variables like membrane voltage potential, synaptic weight
strength etc. (although admittedly at the atomic level, the quantity of neurotransmitter
at a given synapse is discrete, but this is a moot point). It seems intuitive
that since the computations being performed by the system are analogue, and the
outputs also analogue, that a neural system could not give discrete responses �
at best, the system might respond with a very high tendency in one direction or
another, but the neurons are not binary, and do not give �true� or �false�
answers, only high or low firing rates. As a result, the sort of binary formal
logic that mathematicians, logicians and rationalists employ seems
inappropriate for such a system.</p>

<p class=MsoNormal>Computational models have demonstrated that simple logic
gates (like AND or OR) can be easily simulated by neural networks. Indeed, much
more complicated functions can be replicated too. However, these might be
considered to be misleadingly simple cases, since the number of possible
permutations is small enough to be contained inside the training set. The
system can learn, like a finite state machine, a set of prescribed absolute responses
for the given input patterns. This is clearly not an option for most problems.
One of the major strengths of a connectionist system is that it can generalise.
It forms prototypes from the data, and is able to gauge the similarity between
given patterns. As a result, it is able to respond appropriately to novel
patterns. This is the property that gives rise to �graceful degradation�.
Connectionist systems, unlike the programs running on most desktop computers
today, are robust. By this, I mean that unexpected, erroneous or corrupt data
does not bring the system to its knees. If you feed a neural network damaged or
incomplete data, it will settle into the closest attractor available, based on
the weight organisation that has arisen from its training.</p>

<p class=MsoNormal>A crucial aspect of a connectionist system�s dynamics
relates to its non-linearity. By this I mean that the activation function
relating its current activity is non-linear. This could be a simple binary
function, a threshold linear model, sigmoid or logarithmic. All that matters is
that it is not simply linear. This non-linearity gives rise to peculiar
dynamics at a high-level, i.e. ensembles of neurons collectively forming a
distributed representation, which can begin to seem more and more discrete.</p>

<p class=MsoNormal>Rationality, in order to �arrive at principles that are
universal and exceptionless � to be able to come up with reasons that apply in
all relevantly similar situations, and to have reasons of similar generality
that tell us when situations are relevantly similar�, seems to require too much
of a network. In a way, this is an empirically question: �Is the data set to
which our brains have been exposed sufficiently broad and representative for us
to be able to reason reliably about the areas to which we apply it?� It
requires an implausible stretch of the imagination to explain how our senses
could provide the data by means of which we could learn to reason
mathematically or logically.</p>

<p class=MsoNormal>At this point, we have to remember a very obvious point:
people�s reasoning improves. This is not simply a point about developmental
psychology. Clearly, our brains are undergoing various genetically-timed stages
of progression, especially during our earliest years, initially forming an
enormous profusion of synaptic connections that are subsequently pruned. This
is not what I am really referring to � as we progress through education, even
long beyond the point at which our brains are undergoing developmental (i.e.
internally-prescribed) changes, our ability to reason improves. We are continually
forming new conceptual spaces, and this improvement is incremental. This is
related to the reason that maths, for instance, requires an element of trudging
practice that cannot be avoided. An essential part of learning a new theory or
technique is practicing it, repeatedly, with different problems. In this way,
we are expanding our set of training data to be more representative of a given
problem domain, and in the process expanding the generalisation ability of our
reasoning.</p>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<h2>Points</h2>

<p class=MsoNormal>parallels between symbolic approaches and rationality</p>

<p class=MsoNormal style='margin-left:17.85pt'>a connectionist system is a
Universal Turing machine, and so could just be the hardware implementation of a
symbolic rational mode</p>

<p class=MsoNormal style='margin-left:17.85pt'>symbolic-only approaches have
made little progress in modelling any aspect of the mind, including the sort of
broad rationality we�re talking about</p>

<p class=MsoNormal>rationality seems so intimately tied to things like
creativity and analogy that maybe it requires some sort of sub-symbolic system</p>

<p class=MsoNormal>like evolution, connectionism is about self-organisation, and
so gives an alternative demonstration of how our minds could be so adapted to
our environment</p>

<h3>Kim Plunkett stuff</h3>

<p class=MsoNormal>Could a connectionist system (even one as complex as the
brain) ever be truly rational???</p>

<p class=MsoNormal style='margin-left:17.85pt'>In two ways, this is a stupid
question. On the one hand, how can anyone know? � our current NN efforts are so
feeble in comparison to human rationality. On the other, humans appear rational
(questionably), and we have connectionist brains, so we must be. Well, Nagel
for one is prepared to argue that our current conception of mind almost
certainly needs to undergo at least one paradigm shift before we can make sense
of problems like the mind-body problem and how we can have access to such �universally
valid methods of objective thought�.</p>

<p class=MsoNormal style='margin-left:17.85pt'>Won�t there always be a
probabilistic aspect to its computation that would make it fallible or
non-rational to some extent, i.e. rational 99.9% of the time???</p>

<p class=MsoNormal style='margin-left:17.85pt'>An inherent part of true
rationality for Nagel is its generality:</p>

<p class=MsoNormal style='margin-left:35.7pt'><span style='font-size:9.0pt;
mso-bidi-font-size:10.0pt'>Our aim as thinkers and rational agents is to arrive
at principles that are �universal and exceptionless� � to be able to come up
with reasons that apply in all relevantly similar situations, and to have
reasons of similar generality that tell us when situations are relevantly
similar.<o:p></o:p></span></p>

<p class=MsoNormal style='margin-left:35.7pt'>Can a connectionist system ever
be <i style='mso-bidi-font-style:normal'>generally</i> rational, since its
training data will always be limited, and so its synaptic organisation will be
geared towards that<span style='font-size:9.0pt;mso-bidi-font-size:10.0pt'><o:p></o:p></span></p>

<p class=MsoNormal><span style='mso-bidi-font-size:12.0pt'>&nbsp;<o:p></o:p></span></p>

<p class=MsoNormal>Is rationality adaptive??? it seems clear that having true
beliefs may well be more expensive and less fitness-enhancing than having
useful beliefs, and so much less likely to evolve.</p>

<p class=MsoNormal>Following on from this, Robert Nozick (developing from
Cosmides &amp; Tooby and others) has an interesting idea that we have evolved
to find certain chains of inference automatic and self-evident, i.e. that there
may be hard-wired, specialised inferential mechanisms for common past
situations that have been selected for. Thus, for example, the list of
philosophical problems we've been least successful with all mark assumptions
that evolution has built into us: the problem of induction, of other minds, of
the external world, of justifying rationality etc. These seem to me to be just
the sort of genetically pre-wired neural representations that are argued
against in Rethinking Innateness.</p>

<p class=MsoNormal style='margin-left:17.85pt'><span style='mso-bidi-font-size:
12.0pt'>The idea that the brain is implementing formal logic in some hidden way
isn�t very popular now, but philosophers seem to favour the idea that certain,
fairly specific ideas could be genetically coded. You argue against that in
Rethinking Innateness, but is it possible that a tiny proportion of the genome
does hard-code a handful of vital neural representations???<o:p></o:p></span></p>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<h2>Discarded</h2>

<p class=MsoNormal>Indeed, if anything I think he fails to recognise just <i
style='mso-bidi-font-style:normal'>how</i> inescapable these thoughts are, and
the extent to which they underly absolutely all thought, that all thought is
rational, whether pro-rational, anti-rational or simply neutral. We cannot
truly survey ourselves thinking, except by thinking.</p>

<h2>Questions</h2>

<p class=MsoNormal>merge evolution + connectionism???</p>

<p class=MsoNormal>how many neurons???</p>

</div>

<div style='mso-element:footnote-list'><![if !supportFootnotes]><br clear=all>

<hr align=left size=1 width="33%">

<![endif]>

<div style='mso-element:footnote' id=ftn1>

<p class=MsoFootnoteText><a style='mso-footnote-id:ftn1' href="#_ftnref1"
name="_ftn1" title=""><span class=MsoFootnoteReference><span style='mso-special-character:
footnote'><![if !supportFootnotes]>[1]<![endif]></span></span></a> Hebb, D.O.
(1949). <i>The organization of behavior</i>. New York: Wiley</p>

</div>

<div style='mso-element:footnote' id=ftn2>

<p class=MsoFootnoteText><a style='mso-footnote-id:ftn2' href="#_ftnref2"
name="_ftn2" title=""><span class=MsoFootnoteReference><span style='mso-special-character:
footnote'><![if !supportFootnotes]>[2]<![endif]></span></span></a> Fodor
defines a �module� in terms of nine features, of which I have mentioned two of
the most important. The others are: mandatory; central systems have limited
access to the representations computed by input systems; fast; informationally
encapsulated; input systems have &quot;shallow&quot; outputs; associated with
fixed neural architecture; exhibit characteristic and specific breakdown
patterns; their ontological development exhibits a characteristic pace and sequencing</p>

</div>

</div>

</body>

</html>
