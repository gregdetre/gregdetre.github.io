<!DOCTYPE html>
<html lang="en">

<head>
    

    <title>

The real reason we can’t define 'Artificial General Intelligence' -

Greg Detre
</title>
    <meta charset="utf-8" />
    <meta name="generator" content="gdwebgen" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <meta name="description" content="Greg Detre's personal website" />
    
    <link rel="stylesheet" href="/static/css/base.css">
    
<link rel="canonical" href="https://www.gregdetre.com/blog/the-real-reason-we-cant-define-artificial-general-intelligence">

</head>

<body>

    
    <div id="wide-img-header">
        
        <a href="/wide_img_header/IMG_5253.jpg">
            <img src="/wide_img_header/IMG_5253_sm.jpg" />
        </a>
        
    </div>
    

    
<nav aria-label="Breadcrumb">
    <ol class="breadcrumb">
        
        
        <li class="breadcrumb-item" title="Greg Detre">
            
            <a href="/">Greg Detre</a>
            
        </li>
        
        
        
        <li class="breadcrumb-item" title="Blog">
            
            <a href="/blog/">...</a>
            
        </li>
        
        
        
        <li class="breadcrumb-item" title="The real reason we can’t define 'Artificial General Intelligence'">
            
            <a href="/blog/the-real-reason-we-cant-define-artificial-general-intelligence">The Real Reason We Can’T Define 'Artificial General Intelligence'</a>
            
        </li>
        
        
    </ol>
</nav>


    
    <div class="nav_menu" <p>
        
        <a href="/about">About</a>
        
        <a href="/blog">Blog</a>
        
        <a href="/consulting">Consulting</a>
        
        </p>
    </div>
    

    <div id="main">
        

<h1>The real reason we can’t define 'Artificial General Intelligence'</h1>




<p>Could it be that the real reason we struggle to define Artificial General Intelligence (AGI) is that <strong>any clean, broad definition of general intelligence would exclude <em>us</em></strong>?</p>
<p>Intelligence is hard to pin down, but I like two related definitions:</p>
<ol>
<li>
<p>Flexible, goal-directed behaviour</p>
</li>
<li>
<p>Efficient skill acquisition</p>
</li>
</ol>
<p>So: learning how to do something without much to go on, and then applying it in new ways as needed.</p>
<p>We can certainly acquire new skills that we didn't evolve for. We are comparatively flexible. </p>
<p>(The AIs that <em>are</em> super-human, like AlphaZero, tend to be pretty narrow in applicability.) And our learning is comparatively sample-efficient. (For every book that a human child has read, GPT-4 has read 10,000.) We can occasionally generalise out of distribution in ingenious ways.</p>
<p>But. We struggle to transfer knowledge outside the learned context. We make mistakes even when we know better or in principle. We struggle to learn new concepts, languages, skills, habits - we struggle to change our ways, even when we want to. We behave sub-optimally, both wittingly and unwittingly, even when it's pointed out. In short, we struggle to learn how to do some things, and then even when we think we have learned, we struggle to apply them.</p>
<p>So, our intelligence is more general than the best AIs in 2024, by a good distance. But 'general intelligence' is a continuum rather than binary, and our intelligence is only somewhat general.</p>




        



        



        



        



    </div>
    <footer>
        <div class="bottom_nav">
            

            

<p>
    <i>
        First published: 2024-Oct-01
    </i>
</p>


<p>
    <i>
        Last updated: 2024-Oct-13
    </i>
</p>


        </div>
    </footer>
</body>

</html>