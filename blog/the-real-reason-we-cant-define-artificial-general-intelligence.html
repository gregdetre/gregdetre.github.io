<!DOCTYPE html>
<html lang="en">

<head>
    

    <title>

The real reason we can’t define 'Artificial General Intelligence' -

Greg Detre
</title>
    <meta charset="utf-8" />
    <meta name="generator" content="gdwebgen" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <meta name="description" content="Greg Detre's personal website" />
    
    <link rel="stylesheet" href="/static/css/base.css">
    
<link rel="canonical" href="https://www.gregdetre.com/blog/the-real-reason-we-cant-define-artificial-general-intelligence">

</head>

<body>

    
    <div id="wide-img-header">
        
        <a href="/wide_img_header/IMG_5253.jpg">
            <img src="/wide_img_header/IMG_5253_sm.jpg" />
        </a>
        
    </div>
    

    
<nav aria-label="Breadcrumb">
    <ol class="breadcrumb">
        
        
        <li class="breadcrumb-item" title="Greg Detre">
            
            <a href="/">Greg Detre</a>
            
        </li>
        
        
        
        <li class="breadcrumb-item" title="Blog">
            
            <a href="/blog/">...</a>
            
        </li>
        
        
        
        <li class="breadcrumb-item" title="The real reason we can’t define 'Artificial General Intelligence'">
            
            <a href="/blog/the-real-reason-we-cant-define-artificial-general-intelligence">The Real Reason We Can’T Define 'Artificial General Intelligence'</a>
            
        </li>
        
        
    </ol>
</nav>


    
    <div class="nav_menu" <p>
        
        <a href="/about">About</a>
        
        <a href="/blog">Blog</a>
        
        <a href="/consulting">Consulting</a>
        
        </p>
    </div>
    

    <div id="main">
        

<h1>The real reason we can’t define 'Artificial General Intelligence'</h1>




<p>Could it be that the real reason we struggle to define Artificial General Intelligence (AGI) is that any clean, broad definition of general intelligence would exclude <em>us</em>?</p>
<p>Intelligence is hard to pin down, but I like two related definitions:</p>
<ol>
<li>
<p>Flexible, goal-directed behaviour</p>
</li>
<li>
<p>Efficient skill acquisition</p>
</li>
</ol>
<p>Both have a sense of learning how to do something, and then applying it in other circumstances.</p>
<p>But look at us. We struggle to transfer knowledge outside the learned context. We make mistakes even when we know better or in principle. We struggle to change our ways, even when we want to. We behave sub-optimally, both wittingly and unwittingly. In short, we struggle to learn how to do some things, and then even when we think we have learned, we struggle to apply them.</p>
<p>It’s true that, at our best, we <em>are</em> more flexible, more sample-efficient, and occasionally better able to generalise out of distribution in ingenious ways than LLMs. And the AIs that <em>are</em> super-human (like AlphaZero) tend to be pretty narrow in applicability.</p>
<p>Of course, we are more general than the best AIs in 2024, by a good distance. But 'general intelligence' is not binary, nor are we unambiguous exemplars of it.</p>




        



        



        



        



    </div>
    <footer>
        <div class="bottom_nav">
            

            

<p>
    <i>
        First published: 2024-Oct-01
    </i>
</p>


<p>
    <i>
        Last updated: 2024-Oct-12
    </i>
</p>


        </div>
    </footer>
</body>

</html>