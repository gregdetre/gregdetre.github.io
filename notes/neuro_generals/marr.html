<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html>
  <head>
    <title>marr</title>
    <meta name="generator" content="muse.el">
    <meta http-equiv="Content-Type"
          content="text/html; charset=iso-8859-1">
    
    
<link rel="stylesheet" type="text/css" charset="utf-8" media="all" href="common.css" />
<link rel="stylesheet" type="text/css" charset="utf-8" media="screen" href="screen.css" />
<link rel="stylesheet" type="text/css" charset="utf-8" media="print" href="~print.css" />

  </head>
  <body>

    <!-- Page published by Emacs Muse begins here -->
<h2>David Marr</h2>

<h3>Part of</h3>

<p><a href="history.html">history</a></p>



<h3>Information processing</h3>

<ul>
<li>computational theory - an abstract formulation of what
(describing the function relating inputs to outputs) is
being computed and why (e.g. in terms of adaptive value)</li>

<li>algorithm - the particular algorithm that the system is
using, and how the system encodes (represents) the
information (especially what it makes explicit, and what
it leaves implicit) - the how</li>

<li>implementation - what í°∆hardwareí°« (whether
silicon-based or biological) is used to implement the
algorithms</li>
</ul>



<h3>Cerebellum</h3>
<a name="cerebellum" id="cerebellum"></a>
<a href="marr.html">marr</a> &amp; albus

<blockquote>
<p class="quoted"><a href="cerebellar%20cortex.html">cerebellar cortex</a> circuits involved in <a href="learning.html">learning</a> motor
skills</p>
</blockquote>

<blockquote>
<p class="quoted"><a href="climbing%20fibers.html">climbing fibers</a> -&gt; <a href="Purkinje%20cells.html">Purkinje cells</a></p>
</blockquote>

<blockquote>
<p class="quoted">modify their response to <a href="cerebellar%20mossy%20fibers.html">cerebellar mossy fibers</a> for a
prolonged period</p>
</blockquote>

<blockquote>
<p class="quoted">experimental evidence for <a href="climbing%20fibers.html">climbing fibers</a> causing <a href="LTD.html">LTD</a> in
the <a href="parallel%20fibers.html">parallel fibers</a>-<a href="Purkinje%20cells.html">Purkinje cells</a> <a href="synapse.html">synapse</a></p>
</blockquote>

<blockquote>
<p class="quoted">altering the strength of <a href="parallel%20fibers.html">parallel fibers</a>-Purkinje
cells synapses</p>
</blockquote>

<ul>
<li>&gt; select specific <a href="Purkinje%20cells.html">Purkinje cells</a> to program or correct
eye/limb movements

<p><a href="climbing%20fibers.html">climbing fibers</a> would provide an error signal during
movements</p>

<blockquote>
<p class="quoted">by detecting the differences between expected and
actual sensory inputs</p>
</blockquote></li>

<li>&gt; depress <a href="parallel%20fibers.html">parallel fibers</a> that are active concurrently

<blockquote>
<p class="quoted">allow correct movements (i.e. no <a href="climbing%20fibers.html">climbing fibers</a> error
signal) to emerge</p>
</blockquote></li>
</ul>





<h3>Vision</h3>
<h4><a name="vision" id="vision"></a>Approach</h4>

<ul>
<li>Visual analysis should be characterised as bottom-up
wherever possible, i.e. requiring as little high-level
knowledge (e.g. that we are in an wide open space, or
that we are underwater) about the scene as possible</li>

<li>The visual system does make general assumptions about
the way the world is, based on structural regularities
in our environment, e.g. that most of the visual field
is made up of smooth surfaces, that the light usually
comes from above.</li>

<li>Iterative algorithms are too slow, as a rule, to use in
visual processing</li>

<li>He sought an independent justification of a
computational theory or algorithm, besides just
psychological or neurophysiological data</li>
</ul>



<h4>Stages of processing</h4>

<p class="first">grey-level description as input</p>

<blockquote>
<p class="quoted">he ignored colour as being supplementary in most of his
explanations</p>
</blockquote>

<blockquote>
<p class="quoted">retinal two-dimensional array containing intensity
information only</p>
</blockquote>

<p>raw primal sketch</p>

<blockquote>
<p class="quoted">symbolically encodes the location and orientation of edge
segments, <a href="blobs.html">blobs</a> and bars in the image</p>
</blockquote>

<p>full primal sketch</p>

<blockquote>
<p class="quoted">groups these into boundaries</p>
</blockquote>

<p>2ÅΩ-D sketch</p>

<blockquote>
<p class="quoted">is a short-term <a href="memory.html">memory</a> store that contains the orientation
and approximate distance of surfaces from the viewer</p>
</blockquote>

<p>3-D model</p>

<blockquote>
<p class="quoted">object-centerd, three-dimensional representation of the
objects, which can then be combined with top-down
information to identify them</p>
</blockquote>



<h4>Stereopsis</h4>
<a name="stereopsis" id="stereopsis"></a>
see <a href="stereopsis.html">stereopsis</a>



<h3>Correspondence problem</h3>

<p class="first">problem of deciding which point on one
<a href="retina.html">retina</a> maps to which point on the other <a href="retina.html">retina</a>. Juleszí°«s
(1971) random dot stereograms show that this process does
not require monocular object recognition. A random dot
stereogram (RDS) consists of a pair of 2-D arrays of
(usually black and white) randomised pixels, each fed to one
eye. A section of one of the arrays has been slightly
shifted to the right or left, giving rise to a binocular
disparity that the <a href="brain.html">brain</a> interprets as a change in <a href="depth.html">depth</a> -
that section of the image convincingly appears to be on a
different plane to the viewer. Since there are no objects to
be recognised in these images, <a href="stereopsis.html">stereopsis</a> must be possible
without any top-down information at all (although there is
still some dispute over whether top-down information is
sometimes utilised when available).</p>

<p>The correspondence problem is a problem because of í°∆false
targetsí°«. For any pixel of a given intensity, there are
likely to be many corresponding pixels of the same intensity
with which it could be matched. The algorithm has to find a
global optimum (matching the maximum possible number of
pixels in the whole image) while not attempting to match
every pixel with every other possible pixel. We are seeking
an algorithm that probably works locally within the visual
field (since information that can be gained from retinal
disparity is restricted to the nearest distance the eyes can
focus at), is ideally non-iterative, and will find the
optimal (i.e. correct) solution extremely reliably.</p>

<p>Marr and Poggioí°«s <a href="stereopsis.html">stereopsis</a> theory uses three general
principles to help with the correspondence problem. They are
easiest to understand if we imagine that the visual field is
taken up with the image of a sphere with black spots on its
surface.</p>

<ol>
<li>compatibility - match black pixels with black spots,
and white with white</li>

<li>uniqueness - any pixel in one image can only be
matched with one pixel in the corresponding image</li>

<li>continuity - distance from the observer should vary
smoothly almost everywhere (except at boundaries of
surfaces)</li>
</ol>

<p>Marr and Poggioí°«s<sup><a name="fnr.3" href="#fn.3">3</a></sup> first í°∆co-operativeí°« algorithm used
<a href="inhibitory.html">inhibitory</a> connections along the line of sight to ensure
uniqueness (since there cannot be visible surface features
at different depths along the same line of sight), and
<a href="excitatory.html">excitatory</a> connections between contiguous pixels to ensure
continuity. Since this relies on an iterative sort of
constraint satisfaction procedure, and because it did not
tally with psychophysical evidence, Marr <a href="discarded.html">discarded</a> this
early algorithm.</p>

<p>Marr and Poggioí°«s<sup><a name="fnr.4" href="#fn.4">4</a></sup> second algorithm looks for matches
between zero-crossings (of second-order derivatives) at four
different levels of blurriness (using del-squared Gaussian
filters). The most blurred images highlight coarse features,
and can match disparities over fairly large areas (as is
necessary when objectsí°« depths could vary over a wide range
of distances). Having roughly established the <a href="depth.html">depth</a> of the
features, the same process can be carried out on a less
blurred channel, using the first results as a guide, and so
on for all four <a href="channels.html">channels</a>. The information from each channel
guides <a href="vergence.html">vergence</a> movements, so that í°»the range of
disparities being processed by the next narrowest channel is
always centerd around zeroí°…<sup><a name="fnr.5" href="#fn.5">5</a></sup>.</p>

<p>These ideas have since been developed in a number of
directions.</p>

<blockquote>
<p class="quoted">Mayhew and Frisby<sup><a name="fnr.6" href="#fn.6">6</a></sup> proposed a third algorithm, with a
binocular raw primal sketch. Their solution to the
correspondence problem emphasised figural continuity and
the relation between the outputs of the del-squared G
filters that are used to identify edge segments and bar
segments.</p>
</blockquote>

<blockquote>
<p class="quoted">apparently they have psychophysical evidence that
supports their algorithm over Marr and Poggio's</p>
</blockquote>

<blockquote>
<p class="quoted">Similarly, Prazdny replaced Marrí°«s continuity assumption
with a coherence principle, which only required that
neighbouring dispariites of elements corresponding to the
same 3D object be similar, so that locally similar
disparities should facilitate each other, while more
distant and dissimilar disparities should not interact.</p>
</blockquote>



<h3>References</h3>

<p class="first">Kandel and Schwarz, Principles of Neural Science, 3rd
edition, ch 30, pg 454</p>

<p>David Marr, Vision (1982), pg 36</p>

<p>Marr and Poggio (1976), í°∆Co-operative computation of stereo
disparityí°«, Science 194: 283-7</p>

<p>Marr and Poggio (1979), í°∆A computational theory of human
stereo <a href="vision.html">vision</a>í°«, Proceedings of the Royal Society of London
Series B, 204: 522-3</p>

<p>Garnham, Artificial Intelligence (1988)</p>

<p>Mayhew and Frisby (1981), í°∆Psychophysical and computational
studies twoards a theory of human <a href="stereopsis.html">stereopsis</a>í°«, Artificial
Intelligence, 17: 349-85</p>




<!-- Page published by Emacs Muse ends here --> 

<hr>

<script language="javascript" src="footer.js">

  </body>
</html>
