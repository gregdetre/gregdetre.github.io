<!DOCTYPE html>
<html lang="en">

<head>
    

    <title>

essay - email to steve larson 030410 2 -

Greg Detre
</title>
    <meta charset="utf-8" />
    <meta name="generator" content="gdwebgen" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <meta name="description" content="Greg Detre's personal website" />
    
    <link rel="stylesheet" href="/static/css/base.css">
    
<link rel="canonical" href="https://www.gregdetre.com/notes/essay - email to steve larson 030410 2">

</head>

<body>

    
    <div id="wide-img-header">
        
        <a href="/wide_img_header/IMG_5253.jpg">
            <img src="/wide_img_header/IMG_5253_sm.jpg" />
        </a>
        
    </div>
    

    
<nav aria-label="Breadcrumb">
    <ol class="breadcrumb">
        
        
        <li class="breadcrumb-item" title="Greg Detre">
            
            <a href="/">Greg Detre</a>
            
        </li>
        
        
        
        <li class="breadcrumb-item" title="Notes">
            
            <a href="/notes/">...</a>
            
        </li>
        
        
        
        <li class="breadcrumb-item" title="essay - email to steve larson 030410 2">
            
            <a href="/notes/essay - email to steve larson 030410 2">Essay - Email To Steve Larson 030410 2</a>
            
        </li>
        
        
    </ol>
</nav>


    
    <div class="nav_menu" <p>
        
        <a href="/about">About</a>
        
        <a href="/blog">Blog</a>
        
        </p>
    </div>
    

    <div id="main">
        

<h1>essay - email to steve larson 030410 2</h1>




<h1 id="email-to-steve-larson-re-minsky-ch-7-paper">Email to Steve Larson re Minsky ch 7 paper</h1>
<p>Greg Detre</p>
<p>Thursday, April 10, 2003</p>
<p>I agree that the various descriptions given of the unconscious are problematic and possibly inconsistent. I'm a little unhappy with the eliminativist view of consciousness (major adherents include: Dennett[1], Minsky, Sloman[2] etc.). Fortunately though, I think we can more or less ignore that whole discussion about whether there are such things as 'qualia' (i.e. mental states that have the distinctive quality that there is something it is like to experience them), if we talk instead (as you sensibly do) about 'awareness', i.e. whether or not certain information is available/accessible for higher-level processing. this kind of corresponds to Ned Block's[3] distinction between:</p>
<p><em>phenomenal consciousness</em> = the raw �feel� of experience (qualia)</p>
<p><em>access consciousness</em> = the accessibility of experience to verbal report and use in intentional control</p>
<p>When we're talking about computational theories, we're really only interested in this second (and more tractable) type. As I understand it, your solution is to add a second dimension to the Model 6, where the awareness somehow ebbs and flows according to the problem, and where processes at any level can be either conscious or unconscious (that is to say, we may or may not be aware of them). I feel that you could probably simplify this idea just by sticking with Minsky's Model 6 one-dimensional hierarchy, and saying that each process gets some sort of tag or value as it�s spawned, determining whether its contents are accessible to high-level probing and introspection.</p>
<p>After all, we know that there�s some information that's absolutely not available to me, no matter how hard I introspect (e.g. being able to see the blood vessels between my retina and the outside world), some that I can access if I try (e.g. the pattern of my breathing, or the distant hum of traffic), and some that I can only process when my attention is squarely focused upon it (I can't think of a good example of this - maybe programming). We usually talk in terms of different 'quantities' (for want of a better term) of awareness, as though there's a continuum, but given the diversity of computational processes underlying these different abilities, it's possible that the continuum masks a much richer underlying hierarchy of qualitatively different <em>types</em> of awareness. So, one upshot of looking at the kinds of Minskian agents that we�re aware of would be that we might be able to tease apart different types of awareness. This means that we should be looking at which kinds of computational processes (i.e. agents/resources/cascades) are accessible, and which aren't. I'm not actually convinced that a taxonomy along these lines is really possible, but it's kind of being implicitly attempted when researchers try and examine blindsight, lesions, stimulating neurons during brain operations etc.</p>
<p>I've never got much further in my thinking than this, but I suspect that Minsky might suggest that we look to computer science for inspiration when trying to describe different types of computational processes. We could conceivably try and distinguish stuff like:</p>
<ul>
<li>
<p>iterative vs recursive processes (or that indirectly call themselves)</p>
</li>
<li>
<p>processes that involve certain kinds of data structures, e.g. geometric, frames, lists/arrays</p>
</li>
<li>
<p>processes that use local copies of memory rather than referencing indirectly (I.e. pass by value vs reference</p>
</li>
<li>
<p>processes that are highly-specific in the tasks they perform vs domain-general processes</p>
</li>
<li>
<p>processes that mainly get called as opposed to processes that mainly delegate to other processes</p>
</li>
<li>
<p>processes that are massively inter-connected with other processes</p>
</li>
<li>
<p>processes that span multiple levels of abstraction</p>
</li>
<li>
<p>the kinds of search involved (e.g. depth vs breadth)</p>
</li>
<li>
<p>which processes spawned them</p>
</li>
<li>
<p>how high-level they are</p>
</li>
<li>
<p>how complex the task they�re performing is</p>
</li>
<li>
<p>whether the task they are performing is a high-priority one</p>
</li>
<li>
<p>what sort of operations are involved etc. etc.</p>
</li>
<li>
<p>how well the task can be separated into sub-tasks</p>
</li>
<li>
<p>the kinds of learning involved, e.g. reinforcement, classical conditioning, perhaps even analogical, statistical</p>
</li>
<li>
<p>whether language is involved</p>
</li>
<li>
<p>how closely connected to sensory or motor</p>
</li>
</ul>
<p>This is just a list of the top of my head. For starters, it might not be at all feasible right now, because we don�t have the foggiest clue how (or even really <em>if</em>) the brain actually implements the kinds of symbolic agents that Minsky speculates about. And of course, we should also take into account more traditional factors when looking for the neural correlate(s) of consciousness, e.g.</p>
<ul>
<li>
<p>where in the brain is active</p>
</li>
<li>
<p>what bits the active bits are connected to</p>
</li>
<li>
<p>which neurotransmitters and neuromodulators are floating around at the time</p>
</li>
<li>
<p>the current global, high-level (i.e. emotional) state</p>
</li>
<li>
<p>lesions, neuronal stimulation </p>
</li>
</ul>
<p>Anyway, this has digressed further than I intended. In summary, I agree that Minsky�s position on �unconscious processes� is unclear, but I�m not convinced that there�s a simple binary distinction between processes/agents that we�re aware of and those that we aren�t, that the continuum may even admit hierarchical categorisation of types of awareness, and that in the distant future this question could prove to be an entirely empirical one.</p>
<hr/>
<p>[1] See for example, �Quining qualia� � http://ase.tufts.edu/cogstud/papers/quinqual.htm</p>
<p>[2] �What is it like to be a rock?� � http://www.cs.bham.ac.uk/~axs/misc/rock/rock/</p>
<p>[3] See for example, http://www.nyu.edu/gsas/dept/philo/faculty/block/papers/Abridged%20BBS.htm</p>


<br />
<br />
<br />
<hr />



        



        

<small>
    <h1>Belongs to these <a href="/tag">tags</a></h1>
    <ul>
        
        <li><a href="/tag/consciousness.html">Consciousness</a></li>
        
        <li><a href="/tag/marvin-minsky.html">Marvin Minsky</a></li>
        
        <li><a href="/tag/philosophy.html">Philosophy</a></li>
        
    </ul>
</small>



        



        



    </div>
    <footer>
        <div class="bottom_nav">
            

            


<p>
    <i>
        Last updated: 2024-Oct-04
    </i>
</p>


        </div>
    </footer>
</body>

</html>