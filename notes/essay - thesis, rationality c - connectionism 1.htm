<html xmlns:o="urn:schemas-microsoft-com:office:office"
xmlns:w="urn:schemas-microsoft-com:office:word"
xmlns="http://www.w3.org/TR/REC-html40">

<head>
<meta http-equiv=Content-Type content="text/html; charset=windows-1252">
<meta name=ProgId content=Word.Document>
<meta name=Generator content="Microsoft Word 9">
<meta name=Originator content="Microsoft Word 9">
<link rel=File-List
href="essay%20-%20thesis,%20rationality%20c%20-%20connectionism%201_filelist.xml">
<title>Title</title>
<!--[if gte mso 9]><xml>
 <o:DocumentProperties>
  <o:Author>Greg Detre</o:Author>
  <o:LastAuthor>Greg Detre</o:LastAuthor>
  <o:Revision>2</o:Revision>
  <o:TotalTime>1574</o:TotalTime>
  <o:Created>2003-07-02T01:00:00Z</o:Created>
  <o:LastSaved>2003-07-02T01:00:00Z</o:LastSaved>
  <o:Pages>1</o:Pages>
  <o:Words>3507</o:Words>
  <o:Characters>19990</o:Characters>
  <o:Company>-</o:Company>
  <o:Lines>166</o:Lines>
  <o:Paragraphs>39</o:Paragraphs>
  <o:CharactersWithSpaces>24549</o:CharactersWithSpaces>
  <o:Version>9.2720</o:Version>
 </o:DocumentProperties>
 <o:OfficeDocumentSettings>
  <o:DoNotOrganizeInFolder/>
 </o:OfficeDocumentSettings>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:DrawingGridHorizontalSpacing>4.5 pt</w:DrawingGridHorizontalSpacing>
  <w:DrawingGridVerticalSpacing>12.25 pt</w:DrawingGridVerticalSpacing>
  <w:DisplayHorizontalDrawingGridEvery>0</w:DisplayHorizontalDrawingGridEvery>
  <w:Compatibility>
   <w:WW6BorderRules/>
   <w:FootnoteLayoutLikeWW8/>
   <w:ShapeLayoutLikeWW8/>
   <w:AlignTablesRowByRow/>
   <w:ForgetLastTabAlignment/>
   <w:LayoutRawTableWidth/>
   <w:LayoutTableRowsApart/>
  </w:Compatibility>
 </w:WordDocument>
</xml><![endif]-->
<style>
<!--
 /* Font Definitions */
@font-face
	{font-family:Wingdings;
	panose-1:5 0 0 0 0 0 0 0 0 0;
	mso-font-charset:2;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:0 268435456 0 0 -2147483648 0;}
@font-face
	{font-family:"Book Antiqua";
	panose-1:2 4 6 2 5 3 5 3 3 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:647 0 0 0 159 0;}
@font-face
	{font-family:Tahoma;
	panose-1:2 11 6 4 3 5 4 4 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:553679495 -2147483648 8 0 66047 0;}
 /* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{mso-style-parent:"";
	margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:12.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-language:EN-GB;}
h1
	{mso-style-next:Normal;
	margin-top:0in;
	margin-right:0in;
	margin-bottom:6.0pt;
	margin-left:0in;
	text-align:center;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	mso-outline-level:1;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:12.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	color:purple;
	mso-font-kerning:14.0pt;
	mso-fareast-language:EN-GB;
	mso-bidi-font-weight:normal;
	font-style:italic;
	mso-bidi-font-style:normal;}
h2
	{mso-style-next:Normal;
	margin-top:16.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	mso-outline-level:2;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:12.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	color:navy;
	mso-fareast-language:EN-GB;
	mso-bidi-font-weight:normal;
	font-style:italic;
	mso-bidi-font-style:normal;}
h3
	{mso-style-next:Normal;
	margin-top:16.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	mso-outline-level:3;
	tab-stops:right 451.45pt;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:12.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	color:green;
	mso-fareast-language:EN-GB;
	font-weight:normal;
	font-style:italic;
	mso-bidi-font-style:normal;}
h4
	{mso-style-next:Normal;
	margin-top:12.0pt;
	margin-right:0in;
	margin-bottom:3.0pt;
	margin-left:0in;
	text-align:justify;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	mso-outline-level:4;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:12.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:Arial;
	mso-bidi-font-family:"Times New Roman";
	mso-fareast-language:EN-GB;
	mso-bidi-font-weight:normal;}
h5
	{mso-style-next:Normal;
	margin-top:10.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	mso-outline-level:5;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:12.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	color:maroon;
	mso-fareast-language:EN-GB;
	font-weight:normal;
	text-decoration:underline;
	text-underline:single;}
h6
	{mso-style-parent:"Heading 5";
	mso-style-next:Normal;
	margin-top:9.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:.5in;
	margin-bottom:.0001pt;
	text-align:justify;
	text-indent:-.25in;
	mso-pagination:widow-orphan;
	mso-outline-level:6;
	mso-list:l3 level1 lfo10;
	tab-stops:list .5in;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:12.0pt;
	mso-bidi-font-size:11.0pt;
	font-family:"Times New Roman";
	color:olive;
	mso-fareast-language:EN-GB;
	font-weight:normal;
	mso-bidi-font-weight:bold;
	text-underline:#33CCCC;}
p.MsoToc1, li.MsoToc1, div.MsoToc1
	{mso-style-parent:"Heading 1";
	mso-style-next:Normal;
	margin-top:3.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	tab-stops:.75in right 451.45pt;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:11.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	font-variant:small-caps;
	color:purple;
	mso-font-kerning:14.0pt;
	mso-fareast-language:EN-GB;
	font-weight:bold;
	mso-bidi-font-weight:normal;
	font-style:italic;
	mso-bidi-font-style:normal;}
p.MsoToc2, li.MsoToc2, div.MsoToc2
	{mso-style-parent:"Heading 2";
	mso-style-next:Normal;
	margin-top:3.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:10.1pt;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	tab-stops:right 451.3pt;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	color:navy;
	mso-fareast-language:EN-GB;
	font-style:italic;
	mso-bidi-font-style:normal;}
p.MsoToc3, li.MsoToc3, div.MsoToc3
	{mso-style-parent:"TOC 2";
	mso-style-next:Normal;
	margin-top:3.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:20.0pt;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	tab-stops:right 451.45pt;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:9.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	color:teal;
	mso-fareast-language:EN-GB;
	font-style:italic;
	mso-bidi-font-style:normal;}
p.MsoToc4, li.MsoToc4, div.MsoToc4
	{mso-style-update:auto;
	mso-style-parent:"TOC 3";
	mso-style-next:Normal;
	margin-top:3.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:35.7pt;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	tab-stops:right 451.45pt;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:7.5pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	color:maroon;
	mso-fareast-language:EN-GB;
	mso-bidi-font-weight:bold;
	font-style:italic;
	mso-bidi-font-style:normal;}
p.MsoFootnoteText, li.MsoFootnoteText, div.MsoFootnoteText
	{margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-language:EN-GB;}
p.MsoCommentText, li.MsoCommentText, div.MsoCommentText
	{margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-language:EN-GB;}
p.MsoHeader, li.MsoHeader, div.MsoHeader
	{margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	tab-stops:center 239.75pt right 6.65in;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:11.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-language:EN-GB;
	font-style:italic;
	mso-bidi-font-style:normal;}
span.MsoFootnoteReference
	{vertical-align:super;}
span.MsoCommentReference
	{mso-ansi-font-size:8.0pt;
	mso-bidi-font-size:8.0pt;}
p.MsoListNumber, li.MsoListNumber, div.MsoListNumber
	{margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:.25in;
	margin-bottom:.0001pt;
	text-align:justify;
	text-indent:-.25in;
	mso-pagination:widow-orphan;
	mso-list:l0 level1 lfo8;
	tab-stops:list .25in;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:12.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-language:EN-GB;}
p.MsoDate, li.MsoDate, div.MsoDate
	{margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:right;
	mso-pagination:widow-orphan;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:11.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-language:EN-GB;
	font-style:italic;
	mso-bidi-font-style:normal;}
p.MsoDocumentMap, li.MsoDocumentMap, div.MsoDocumentMap
	{margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	background:navy;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:12.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:Tahoma;
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-language:EN-GB;}
p.Section, li.Section, div.Section
	{mso-style-name:Section;
	margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:center;
	mso-pagination:widow-orphan;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:12.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-language:EN-GB;
	font-weight:bold;
	mso-bidi-font-weight:normal;}
p.Heading0, li.Heading0, div.Heading0
	{mso-style-name:"Heading 0";
	mso-style-parent:"Heading 1";
	margin-top:6.0pt;
	margin-right:0in;
	margin-bottom:6.0pt;
	margin-left:0in;
	text-align:center;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	mso-outline-level:1;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	border:none;
	mso-border-alt:solid windowtext .5pt;
	padding:0in;
	mso-padding-alt:1.0pt 4.0pt 1.0pt 4.0pt;
	font-size:16.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Book Antiqua";
	mso-fareast-font-family:"Times New Roman";
	mso-bidi-font-family:"Times New Roman";
	font-variant:small-caps;
	color:purple;
	mso-fareast-language:EN-GB;
	font-weight:bold;
	mso-bidi-font-weight:normal;}
p.CommentSubject, li.CommentSubject, div.CommentSubject
	{mso-style-name:"Comment Subject";
	mso-style-parent:"Comment Text";
	mso-style-next:"Comment Text";
	margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:10.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-language:EN-GB;
	font-weight:bold;}
p.BalloonText, li.BalloonText, div.BalloonText
	{mso-style-name:"Balloon Text";
	margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	margin-bottom:.0001pt;
	text-align:justify;
	mso-pagination:widow-orphan;
	mso-layout-grid-align:none;
	punctuation-wrap:simple;
	text-autospace:none;
	font-size:8.0pt;
	font-family:Tahoma;
	mso-fareast-font-family:"Times New Roman";
	mso-fareast-language:EN-GB;}
@page Section1
	{size:595.3pt 841.9pt;
	margin:68.05pt 68.05pt 68.05pt 68.05pt;
	mso-header-margin:.5in;
	mso-footer-margin:.5in;
	mso-paper-source:0;}
div.Section1
	{page:Section1;}
 /* List Definitions */
@list l0
	{mso-list-id:-120;
	mso-list-type:simple;
	mso-list-template-ids:-1247397174;}
@list l0:level1
	{mso-level-style-link:"List Number";
	mso-level-tab-stop:.25in;
	mso-level-number-position:left;
	margin-left:.25in;
	text-indent:-.25in;}
@list l1
	{mso-list-id:1103186221;
	mso-list-type:hybrid;
	mso-list-template-ids:-97247734 134807567 134807577 134807579 134807567 134807577 134807579 134807567 134807577 134807579;}
@list l1:level1
	{mso-level-tab-stop:.5in;
	mso-level-number-position:left;
	text-indent:-.25in;}
@list l2
	{mso-list-id:1470240892;
	mso-list-type:hybrid;
	mso-list-template-ids:-318178384 1685484530 67698713 67698715 67698703 67698713 67698715 67698703 67698713 67698715;}
@list l2:level1
	{mso-level-tab-stop:.25in;
	mso-level-number-position:left;
	margin-left:17.85pt;
	text-indent:-17.85pt;}
@list l3
	{mso-list-id:1476406644;
	mso-list-type:hybrid;
	mso-list-template-ids:168605670 266271734 67698691 67698693 67698689 67698691 67698693 67698689 67698691 67698693;}
@list l3:level1
	{mso-level-number-format:bullet;
	mso-level-style-link:"Heading 6";
	mso-level-text:o;
	mso-level-tab-stop:.5in;
	mso-level-number-position:left;
	text-indent:-.25in;
	font-family:"Courier New";
	mso-bidi-font-family:"Times New Roman";}
@list l3:level2
	{mso-level-tab-stop:1.0in;
	mso-level-number-position:left;
	text-indent:-.25in;}
@list l4
	{mso-list-id:1746143482;
	mso-list-type:simple;
	mso-list-template-ids:-719658964;}
@list l4:level1
	{mso-level-tab-stop:.25in;
	mso-level-number-position:left;
	margin-left:.25in;
	text-indent:-.25in;}
ol
	{margin-bottom:0in;}
ul
	{margin-bottom:0in;}
-->
</style>
</head>

<body lang=EN-GB style='tab-interval:17.85pt'>

<div class=Section1>

<h1><span style='color:windowtext;font-weight:normal'>Is a naturalistic account
of reason compatible with its objectivity?<o:p></o:p></span></h1>

<h1><span style='color:windowtext'>Can rational objectivism be implemented in a
connectionist system (like the brain)?<o:p></o:p></span></h1>

<p class=MsoNormal align=right style='text-align:right'>Greg Detre</p>

<p class=MsoNormal align=right style='margin-top:2.0pt;text-align:right'>Tuesday,
January 29, 2002</p>

<p class=MsoNormal align=right style='margin-top:2.0pt;text-align:right'>Dr
Tasioulas</p>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<h2>Introduction</h2>

<p class=MsoNormal>At root, connectionism amounts to the thesis that the brain
is a dynamical system, a mathematically modellable complex of levers and
pulleys, or in this case, neurons and synapses. The high-level behaviour of the
system seems to emerge like magic out of a morass of low-level interactions,
just as the seemingly-centralised wheeling and coordination of a flock of birds
results from each bird paying attention to the position and speed of its
neighbours (local rules).</p>

<h3>Define connectionism</h3>

<p class=MsoNormal>More specifically, connectionism refers to the family of
theories that aim to understand mental abilities in terms of formalised models
of the brain. These usually employ large numbers of nodes (neurons), with
weighted inter-connections (synapses). The firing rate of a neuron is usually some
non-linear function (e.g. sigmoid) of its activity, which is calculated as the
weighted sum of the firing rates of neurons that synapse onto it. In this way,
activity is propagated in parallel from the input neurons eventually to the
output neurons.</p>

<p class=MsoNormal>Input neurons are defined as those whose activation is (at
least partially) determined by the external environment (in the case of the
brain, various sensory receptors), and output neurons are those which affect
some change in the system�s behaviour in that environment (e.g. motor neurons
connected to muscle) � hidden neurons are those whose activity is invisible to
the environment.</p>

<p class=MsoNormal>What makes neural networks interesting is their ability to
self-organise, or �learn�, by modifying their weights according to a learning
algorithm. The simplest are the Hebbian-type learning rules<a style='mso-footnote-id:
ftn1' href="#_ftn1" name="_ftnref1" title=""><span class=MsoFootnoteReference><span
style='mso-special-character:footnote'><![if !supportFootnotes]>[1]<![endif]></span></span></a>,
which are based on the principle:</p>

<p class=MsoNormal style='margin-left:17.85pt'>the synapse between two neurons should
be strengthened if the neurons fire simultaneously</p>

<p class=MsoNormal>This can be implemented in a pattern-associator, an
architecture for associating a set of input patterns with a set of
pre-specified output patterns. Innumerable improvements and revisions have been
employed, and the Hebbian rule really only works well for orthogonal (i.e.
uncorrelated) input patterns, but its human-like robustness and ability to
generalise are notable. When presented with a novel pattern which is similar
but not identical to a learned input pattern, its output will be similar or
identical to the learned output pattern. It can be seen to generalise to new
data, and form prototypes based on resemblances between input patterns, both of
which features had to be explicitly, inelegantly and inefficiently built into
previous symbolic models.</p>

<h5>Biological plausibility</h5>

<p class=MsoNormal>The field is polarised by the degree to which these
�artificial neural networks� are intended to be biologically-plausible, that
is, the degree to which a model corresponds to actual processes instantiated in
the brain.</p>

<p class=MsoNormal>This debate centres around the use of powerful, but
biologically unrealistic learning rules like back-propagation. </p>

<h5>Level of computation</h5>

<p class=MsoNormal>Some neuron-level models aim to simulate the processes going
on inside a neuron to an almost molecular level, while others ignore the
sub-neural computation, treating neurons as just simple devices for integrating
inputs.</p>

<h3>Relate rationality to the LOTH</h3>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<h5>Systematicity</h5>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<h5>Productivity etc.</h5>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<h3>Problems for connectionism</h3>

<p class=MsoNormal>There are various reasons why an arch-rationalist like Nagel
might have concerns about Smolensky�s PTC.</p>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<p class=MsoNormal>Why do connectionist systems seem unsuitable for implementing
rationality???</p>

<p class=MsoNormal style='margin-left:17.85pt'>analogue (probabilistic/statistical???)</p>

<p class=MsoNormal style='margin-left:17.85pt'>we don't evolve representations</p>

<p class=MsoNormal style='margin-left:17.85pt'>systematicity (cf Chomsky�s
argument about combinatorial explosion etc.???)</p>

<p class=MsoNormal style='margin-left:17.85pt'>generality (rationality seems to
be able to work in more or less any domain)</p>

<p class=MsoNormal style='margin-left:17.85pt'>Penrose � non-computable human
mental functioning</p>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<p class=MsoNormal>Is there hope that a connectionist system could implement
rationality???</p>

<p class=MsoNormal style='margin-left:17.85pt'>ah, but that�s where the
low-level non-linearity resolves into more or less discrete results at a high
level</p>

<p class=MsoNormal style='margin-left:17.85pt'>the DNA may constrain things
into representations, allowing the interactionist to more or less posit innate
ideas</p>

<p class=MsoNormal style='margin-left:17.85pt'>systematicity possible in
connectionist systems</p>

<p class=MsoNormal style='margin-left:17.85pt'>generality???</p>

<p class=MsoNormal style='margin-left:17.85pt'>Penrose???</p>

<p class=MsoNormal style='margin-left:17.85pt'>parallels between symbolic
approaches and rationality</p>

<p class=MsoNormal style='margin-left:35.7pt'>a connectionist system is a
Universal Turing machine, and so could just be the hardware implementation of a
symbolic rational mode</p>

<p class=MsoNormal style='margin-left:35.7pt'>symbolic-only approaches have
made little progress in modelling any aspect of the mind, including the sort of
broad rationality we�re talking about</p>

<p class=MsoNormal style='margin-left:17.85pt'>rationality seems so intimately
tied to things like creativity and analogy that maybe it requires some sort of
sub-symbolic system</p>

<p class=MsoNormal style='margin-left:17.85pt'>like evolution, connectionism is
about self-organisation, and so gives an alternative demonstration of how our
minds could be so adapted to our environment</p>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<h2>Discarded - connectionism</h2>

<h5>Understanding</h5>

<p class=MsoNormal>John Searle raised the debate of understanding with relation
to purely syntactic processing memorably and eloquently in his discussions of
the Chinese Room. I think he has been firmly rebuked even by the interlocutors
in his original paper (�Minds, brains and programs�), and will not </p>

<h3>Smolensky and the cognitive level</h3>

<p class=MsoNormal>The term, �connectionism� is used as a thesis about the
workings of the mind in two different ways, one making a much stronger claim
than the other.</p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal style='mso-list:l1 level1 lfo11;tab-stops:list .5in'>The
     stronger claim, as espoused by Smolensky, can be stated negatively: a
     symbolic, cognitive-level description cannot fully capture (i.e. specify
     in law-like terms) our mental activity. That is, if we want to fully
     understand (i.e. account for or predict) the workings of the mind, we
     cannot talk at the level of psychology, but must (at least partially)
     descend towards the neural level. Smolensky maintains that a sub-symbolic
     level consisting of non-semantically evaluable constituents or
     micro-features of symbols exists, above the neural level, at which we will
     be able to fully specify (i.e. capture nomologically) mental activity.</li>
 <li class=MsoNormal style='mso-list:l1 level1 lfo11;tab-stops:list .5in'>The
     weaker claim </li>
</ol>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<p class=MsoNormal style='margin-left:53.55pt'>does the weaker functionalism
connectionist claim have anything to say about the symbolic/sub-symbolic
debate???</p>

<p class=MsoNormal style='margin-left:53.55pt'>do I actually need to talk about
strong and weak claims at all???</p>

<p class=MsoNormal style='margin-left:53.55pt'><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<p class=MsoNormal>Following Smolensky�s �Proper Treatment of Connectionism�
(PTC),</p>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<h2>Points</h2>

<p class=MsoNormal>The weaker claim simply states that the brain is a
self-organising connectionist system � it is composed, at the neural level, of
nodes with weighted connections. Sensory input is transduced into action
potentials, propagated and processed, and eventually transduced into muscle
activity. As mentioned briefly above, there is some debate about the extent to
which sub-neuronal processes play a computational role. In effect, this is
little more than a fleshed-out reiteration of functionalism.</p>

<h3>Kim Plunkett stuff</h3>

<p class=MsoNormal>Could a connectionist system (even one as complex as the
brain) ever be truly rational???</p>

<p class=MsoNormal style='margin-left:17.85pt'>In two ways, this is a stupid
question. On the one hand, how can anyone know? � our current NN efforts are so
feeble in comparison to human rationality. On the other, humans appear rational
(questionably), and we have connectionist brains, so we must be. Well, Nagel
for one is prepared to argue that our current conception of mind almost
certainly needs to undergo at least one paradigm shift before we can make sense
of problems like the mind-body problem and how we can have access to such �universally
valid methods of objective thought�.</p>

<p class=MsoNormal style='margin-left:17.85pt'>Won�t there always be a
probabilistic aspect to its computation that would make it fallible or
non-rational to some extent, i.e. rational 99.9% of the time???</p>

<p class=MsoNormal style='margin-left:17.85pt'>An inherent part of true
rationality for Nagel is its generality:</p>

<p class=MsoNormal style='margin-left:35.7pt'><span style='font-size:9.0pt;
mso-bidi-font-size:10.0pt'>Our aim as thinkers and rational agents is to arrive
at principles that are �universal and exceptionless� � to be able to come up
with reasons that apply in all relevantly similar situations, and to have
reasons of similar generality that tell us when situations are relevantly similar.<o:p></o:p></span></p>

<p class=MsoNormal style='margin-left:35.7pt'>Can a connectionist system ever
be <i style='mso-bidi-font-style:normal'>generally</i> rational, since its
training data will always be limited, and so its synaptic organisation will be
geared towards that<span style='font-size:9.0pt;mso-bidi-font-size:10.0pt'><o:p></o:p></span></p>

<p class=MsoNormal><span style='mso-bidi-font-size:12.0pt'>&nbsp;<o:p></o:p></span></p>

<p class=MsoNormal>Is rationality adaptive??? it seems clear that having true
beliefs may well be more expensive and less fitness-enhancing than having
useful beliefs, and so much less likely to evolve.</p>

<p class=MsoNormal>Following on from this, Robert Nozick (developing from
Cosmides &amp; Tooby and others) has an interesting idea that we have evolved
to find certain chains of inference automatic and self-evident, i.e. that there
may be hard-wired, specialised inferential mechanisms for common past
situations that have been selected for. Thus, for example, the list of
philosophical problems we've been least successful with all mark assumptions
that evolution has built into us: the problem of induction, of other minds, of
the external world, of justifying rationality etc. These seem to me to be just
the sort of genetically pre-wired neural representations that are argued against
in Rethinking Innateness.</p>

<p class=MsoNormal style='margin-left:17.85pt'><span style='mso-bidi-font-size:
12.0pt'>The idea that the brain is implementing formal logic in some hidden way
isn�t very popular now, but philosophers seem to favour the idea that certain,
fairly specific ideas could be genetically coded. You argue against that in Rethinking
Innateness, but is it possible that a tiny proportion of the genome does
hard-code a handful of vital neural representations???<o:p></o:p></span></p>

<h2><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></h2>

<h2>Panicked new attempt Monday, February 04, 2002 1:44 AM</h2>

<p class=MsoNormal>Nozick�s account is attractive in a number of ways. It can
be accommodated with minimal metaphysical commitments, </p>

<p class=MsoNormal>Its price is that it does not really face Nagel head on �
Nozick is content to admit that he is not explaining rationality �from first
principles�(???) � he is presupposing a degree of rationality in order to
consider oneself rationally. And, as I will discuss later, this is the only
position that I think we <i style='mso-bidi-font-style:normal'>can</i> take as
philosophers. On the one hand, we face an empty, skeptical suspension of belief
since we recognise that in order to hold <i style='mso-bidi-font-style:normal'>any</i>
justified beliefs whatsoever, we first require a justified belief about our
ability to form such beliefs. And yet, in suspending our belief, we have
already recognised that this is the only <i style='mso-bidi-font-style:normal'>rational</i>
option. In this way, Nagel�s characterisation of �thoughts that we cannot get
outside of� is particularly appropriate. Indeed, if anything I think he fails
to recognise just <i style='mso-bidi-font-style:normal'>how</i> inescapable
these thoughts are, and the extent to which they underly absolutely all
thought, that all thought is rational, whether pro-rational, anti-rational or
simply neutral. We cannot truly survey ourselves thinking, except by thinking.</p>

<p class=MsoNormal>In a way, it�s obvious that we could never monitor our
entire brain � with what would we be doing the monitoring? Where can we stand
that we can view our position from any position but our own? Can we turn our
eyes back upon our own skull (in a more meaningful sense than just the
eyeball-rolling party trick)?</p>

<p class=MsoNormal>So we have little choice but to accept that simply being
able to frame the question of one�s own rationality is a sort of base condition
for rationality. Doubting is, of necessity, a kind of <i style='mso-bidi-font-style:
normal'>rational</i> thinking. Descartes� <i style='mso-bidi-font-style:normal'>cogito</i>
may thus serve instead to bootstrap us into knowledge of our own rationality.</p>

<p class=MsoNormal>Perhaps it�s not so much the doubting about questioning one�s
own rationality, as simply being able to conceive of rationality at all.
Perhaps the complex notion of rationality is its own key. Being able to
conceive abstractly of context-independent, formal, generalisable methods and
propositions, or perhaps the notions of context-independence, formality,
generalisability, method or proposition collectively form the tip of a
cognitive framework iceberg comprising a syntax-manipulating,
representation-of-representation mind, even a fallible, specialised, evolved one.</p>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<p class=MsoNormal>Define functionalism</p>

<p class=MsoNormal>I am going to contend that some variant on these claims will
remain the dominant way of thinking about the mind and brain for the
foreseeable future, and that this should inform our understanding of
rationality in a number of ways. To some degree, adherence to this picture
narrows down what we can be capable of as
connectionist/functionalist-implemented rationalists - most notably, it serves
as a constant reminder of our finitude (see Cherniak???).</p>

<p class=MsoNormal>At the same time though, it may helpfully flesh out our
conception of ourselves as rational beings, partly by restricting or
constraining the number and type of possible explanations, and partly by
providing a good idea of the sort of properties we should expect to find.</p>

<p class=MsoNormal>Hopefully, considering ourselves as
connectionist-rationalists might give us a new approach to the problem of
alternate rationalities (i.e. 'conceptual schemes'). I am not thinking of
'multiple realisablity' here - this is the term that functionalists use to mean
that the same abstract organisation, the same underlying function, and so the
same mental abilities, could be implemented in physically very different
systems (e.g. a silicon chip could be functionally identical to a biological
brain). Rather, I am thinking of the low-level differences between the brain of
every human on the planet, despite being very similar macroscopically. In terms
of the actual computation being performed, nobody thinks in exactly the same
way. It is an empirical question how similar our brains are - but it is
certainly clear that mapping an area from one brain to the corresponding
location in another brain is far from easy (as neuroimaging researchers
constantly find). It may be that these differences amount to more or less
identical computational processes at a higher level. One might imagine such
functionally irrelevant differences as being analogous to the difference
between, say, a + (b + c) and (a + b) + c. Perhaps, if we were able to say how
people�s brains differ in terms of the computations being performed, we might
eventually begin to trace a broad schema of computational approaches which qualify
as rational, to a greater or lesser degree. In fact, a growing number of
approaches seek an understanding of the mind in terms of numerous interacting
components, moving away from the �monolithic internal models, monolithic
control, and general purpose processing� of �classical AI� (Brooks et. al (MIT),
Dennett�s multiple drafts, Fodor�s modules).</p>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<p class=MsoNormal>There are certain problems with trying to square connectionism
with rationality. Some are relatively general difficulties with connectionism,
in its various forms. Others stem from a seeming incompatibility between the
two.</p>

<p class=MsoNormal>Perhaps the broadest criticism of all such approaches stems
from Godel's theorem, most famously advocated with relation to the mind-body
problem by Lucas, and more recently, Penrose. Godel's theory states that in a
formal system of above a certain complexity, there will always be
formally-undecidable, true propositions, i.e. statements that are true, but
which cannot be proved within the system. This thwarted attempts like Russell
and Whitehead's Principia Mathematica to found the whole of mathematics on a
minimal set of principles (axioms). It also poses problems for connectionist
systems. Part of the appeal of a connectionist system is that it can be seen as
a Universal Turing Machine. Consequently though, formally non-computable
functions cannot be implemented finitely by such a system. Penrose argues that
the brain (i.e. people) *can* do this, and so our minds must be more than
Turing machines. As he argues, there must be more going on in the brain than
we're currently aware of at the neural or even sub-neural level - he speculates
that there may be quantum effects in microtubules in the brain that allow us to
... If Penrose is right, then almost all of the debate currently centring
around the capabilities of purely connectionist systems becomes almost
irrelevant, because the power of such a quantum system could potentially be of
an unimaginably greater magnitude. The first questions would relate to what
limitations such a system would have, and why our brains are so much more
limited-seeming than one would expect of such a system.</p>

<p class=MsoNormal>There are a number of related issues specific to connectionism
to consider. To what extent could a connectionist system be as general in its
applicability as Nagel�s rationality requires? When we reason, or indeed form a
sentence, we relate a series of symbols (whether words, propositions, names
etc.???) inter-changeably together by syntax � although connectionist models
can be trained to be systematic, they can also be trained, for example, to
recognize �John loves Mary� without being able to recognize �Mary loves John� (the
problem of �systematicity�). When a connectionist system represents a
proposition as a vector of synaptic weights, is it really <i style='mso-bidi-font-style:
normal'>understanding</i> the proposition? </p>

<p class=MsoNormal>To an extent, these parallel the debate in evolutionary
epistemology about the extent to which true beliefs are adaptive, and that truth-tracking
could have been selected for. </p>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<p class=MsoNormal>The idea of the brain as a rational machine brings up the
two related issues of discreteness and generalisation.</p>

<p class=MsoNormal>The brain is a more or less analogue system. It is a
dynamical system operating in real time (as opposed to discrete time-steps), based
on continuous variables like membrane voltage potential, synaptic weight
strength etc. (although admittedly at the atomic level, the quantity of
neurotransmitter at a given synapse is discrete, but this is a moot point). It
seems intuitive that since the computations being performed by the system are
analogue, and the outputs also analogue, that a neural system could not give
discrete responses � at best, the system might respond with a very high
tendency in one direction or another, but the neurons are not binary, and do
not give �true� or �false� answers, only high or low firing rates. As a result,
the sort of binary formal logic that mathematicians, logicians and rationalists
employ seems inappropriate for such a system.</p>

<p class=MsoNormal>Computational models have demonstrated that simple logic
gates (like AND or OR) can be easily simulated by neural networks. Indeed, much
more complicated functions can be replicated too. However, these might be
considered to be misleadingly simple cases, since the number of possible
permutations is small enough to be contained inside the training set. The
system can learn, like a finite state machine, a set of prescribed absolute
responses for the given input patterns. This is clearly not an option for most
problems. One of the major strengths of a connectionist system is that it can
generalise. It forms prototypes from the data, and is able to gauge the
similarity between given patterns. As a result, it is able to respond appropriately
to novel patterns. This is the property that gives rise to �graceful
degradation�. Connectionist systems, unlike the programs running on most
desktop computers today, are robust. By this, I mean that unexpected, erroneous
or corrupt data does not bring the system to its knees. If you feed a neural network
damaged or incomplete data, it will settle into the closest attractor
available, based on the weight organisation that has arisen from its training.</p>

<p class=MsoNormal>A crucial aspect of a connectionist system�s dynamics
relates to its non-linearity. By this I mean that the activation function
relating its current activity is non-linear. This could be a simple binary
function, a threshold linear model, sigmoid or logarithmic. All that matters is
that it is not simply linear. This non-linearity gives rise to peculiar
dynamics at a high-level, i.e. ensembles of neurons collectively forming a
distributed representation, which can begin to seem more and more discrete.</p>

<p class=MsoNormal>Rationality, in order to �arrive at principles that are
universal and exceptionless � to be able to come up with reasons that apply in
all relevantly similar situations, and to have reasons of similar generality
that tell us when situations are relevantly similar�, seems to require too much
of a network. In a way, this is an empirically question: �Is the data set to
which our brains have been exposed sufficiently broad and representative for us
to be able to reason reliably about the areas to which we apply it?� It
requires an implausible stretch of the imagination to explain how our senses
could provide the data by means of which we could learn to reason
mathematically or logically.</p>

<p class=MsoNormal>At this point, we have to remember a very obvious point:
people�s reasoning improves. This is not simply a point about developmental
psychology. Clearly, our brains are undergoing various genetically-timed stages
of progression, especially during our earliest years, initially forming an
enormous profusion of synaptic connections that are subsequently pruned. This
is not what I am really referring to � as we progress through education, even
long beyond the point at which our brains are undergoing developmental (i.e.
internally-prescribed) changes, our ability to reason improves. We are
continually forming new conceptual spaces, and this improvement is incremental.
This is related to the reason that maths, for instance, requires an element of
trudging practice that cannot be avoided. An essential part of learning a new
theory or technique is practicing it, repeatedly, with different problems. In
this way, we are expanding our set of training data to be more representative
of a given problem domain, and in the process expanding the generalisation
ability of our reasoning.</p>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<h2>Conclusions</h2>

<p class=MsoNormal>If we�re as charitable as possible to our connectionist
account by saying that it wholly contains the symbolic approach within it, since
you can always implement the symbolic approach as a connectionist system
(officially � ignoring learning issues aside). Similarly, Smolensky has shown
that systematicity is not, in principle a insurmountable problem at all.</p>

<p class=MsoNormal>I think that a connectionist system, especially an evolved,
specialised, jury-rigged one like ours, will always be a little unpredictable
in its behaviour. We form representations </p>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<h2>Discarded</h2>

<p class=MsoNormal>Most computational models are conducted on serial machines
which can approximate, at a comparatively coarse temporal resolution, hugely
simplified neuron-models.<span style="mso-spacerun: yes">� </span></p>

<h2>Questions</h2>

<p class=MsoNormal>do functionalists have to be materialists??? yes, to the
extent that they hold that mental activity is describable as a (possibly
complex, non-linear, hidden-representation etc.) *function*, that is to say,
there is a determinate (and by implication, though perhaps not for sure,
determinable) relationship between (sensory) inputs and (motor) outputs. In
order to relate material inputs to material outputs, as is required by the
body, then the functionalist pretty much has to think in terms of a material
implementation of the intermediate function</p>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<p class=MsoNormal>rational objectivism is a bad name for what i'm talking
about - i'm not talking about fabric-of-the-universe(???) norms, so much as our
rational capacities</p>

<p class=MsoNormal><span style='mso-tab-count:1'>������ </span>in doing this,
and phrasing it like this, am i first assuming fabric-of-the-universe norms,
and how does this change and straitlace me, and relate to truth etc.???</p>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<p class=MsoNormal>why do 'states' matter so much to the functionalist???</p>

<p class=MsoNormal><span style='mso-tab-count:1'>������ </span>is this anything
to do with the fact that a Turing machine needs states for its computational
properties???</p>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<p class=MsoNormal>is the a + b + c example a good one???</p>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<p class=MsoNormal>to what extent is rationality a continuum???</p>

<p class=MsoNormal>what am i trying to do???</p>

<p class=MsoNormal>terminology!!!</p>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<p class=MsoNormal>is connectionism really part of our naturalistic
framework???</p>

<p class=MsoNormal style='margin-top:4.0pt;margin-right:0in;margin-bottom:0in;
margin-left:17.85pt;margin-bottom:.0001pt'>y, surely � it just depends whether
we�re talking about the strong or weak claim</p>

<p class=MsoNormal>in order for the discrete-like non-linearity to emerge, does
it have to be a distributed representation, or is the non-linearity (e.g. of
the activation function) enough???</p>

<p class=MsoNormal>is the fact that the brain is self-organising part of the
generalisation/systematicity issue???</p>

<p class=MsoNormal>are the problems of generality and systematicity related to
the difficulties of formal, context-independent symbols emerging in a
connectionist systems???</p>

<p class=MsoNormal>I suppose you can imagine that a neural net which has
learned to add two numbers together - but do those numbers have to be of a
certain size � well, they have to be representable within the input vector � is
that different from the way that we have limits on the size of numbers we can
hold in our heads??? well, maybe, but that�s why we have algebra</p>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

<p class=MsoNormal><![if !supportEmptyParas]>&nbsp;<![endif]><o:p></o:p></p>

</div>

<div style='mso-element:footnote-list'><![if !supportFootnotes]><br clear=all>

<hr align=left size=1 width="33%">

<![endif]>

<div style='mso-element:footnote' id=ftn1>

<p class=MsoFootnoteText><a style='mso-footnote-id:ftn1' href="#_ftnref1"
name="_ftn1" title=""><span class=MsoFootnoteReference><span style='mso-special-character:
footnote'><![if !supportFootnotes]>[1]<![endif]></span></span></a> Hebb, D.O.
(1949). <i>The organization of behavior</i>. New York: Wiley</p>

</div>

</div>

</body>

</html>
