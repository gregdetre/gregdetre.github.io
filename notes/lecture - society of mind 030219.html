<!DOCTYPE html>
<html lang="en">

<head>
    

    <title>

lecture - society of mind 030219 -

Greg Detre
</title>
    <meta charset="utf-8" />
    <meta name="generator" content="gdwebgen" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <meta name="description" content="Greg Detre's personal website" />
    
    <link rel="stylesheet" href="/static/css/base.css">
    
<link rel="canonical" href="https://www.gregdetre.com/notes/lecture - society of mind 030219">

</head>

<body>

    
    <div id="wide-img-header">
        
        <a href="/wide_img_header/IMG_5253.jpg">
            <img src="/wide_img_header/IMG_5253_sm.jpg" />
        </a>
        
    </div>
    

    
<nav aria-label="Breadcrumb">
    <ol class="breadcrumb">
        
        
        <li class="breadcrumb-item" title="Greg Detre">
            
            <a href="/">Greg Detre</a>
            
        </li>
        
        
        
        <li class="breadcrumb-item" title="Notes">
            
            <a href="/notes/">...</a>
            
        </li>
        
        
        
        <li class="breadcrumb-item" title="lecture - society of mind 030219">
            
            <a href="/notes/lecture - society of mind 030219">Lecture - Society Of Mind 030219</a>
            
        </li>
        
        
    </ol>
</nav>


    
    <div class="nav_menu" <p>
        
        <a href="/about">About</a>
        
        <a href="/blog">Blog</a>
        
        </p>
    </div>
    

    <div id="main">
        

<h1>lecture - society of mind 030219</h1>




<h1 id="lecture-society-of-mind">Lecture � Society of mind</h1>
<p>Greg Detre</p>
<p>Wednesday, February 19, 2003</p>
<p>wolfram has the same problem as types of computation � the theory�s not rich because almost all types of problem fall into the same overly-large category � wolfram�s book is an enormous failure because it doesn�t add anything new to the original 4-part classification scheme</p>
<p>SoM � causes + clauses</p>
<p>computer science is valuable because it�s a way of describing processes, and came up with loads of useful ideas like stacks and cache memory</p>
<p>although there was a pocket of mathematics called recursive function theory in the early 20th century previous to compsci</p>
<p>there is a class of machines just slightly weaker than turing machines but there�s no known use for them</p>
<p>Newell + Simon � the variety of learning in a general problem solver</p>
<p>nobody paid any attention to it, and they should have</p>
<p>Proust as one of the best sources of ideas</p>
<p>�The Mezzanine� by Nicholson Baker??? � subject of thought vs number of times thought occurred per year � novel about what he thought about for 15 minutes</p>
<p>tEM</p>
<p>�resources� are the new name for �agents�, because that has come to mean independent self-contained functional parts</p>
<p>top-down rather than bottom-up like SoM</p>
<p>Susumo Ono, �Duplication and diversity� � Nobel prize-winning genetics of spinal segments</p>
<p>4 closest relatives � chimps, baboons, orangutangs, gorillas</p>
<p>one conjecture of the main difference is that we have a stack that�s three deep, and theirs is only two deep</p>
<p>credit assignment</p>
<p>presumably you could get a bigger brain just by turning off the growth hormone later � but bigger brains use more energy, make you less mobile</p>
<p>more imporantly, the brains would just have been filled with junk and so the credit assignment would be that much harder</p>
<p>last year, theories about the cerebellum were blown apart, because it seems to be implicated in higher-level cognition</p>
<p>�don�t study neuroscience to learn anything, but rather because these people are lost and maybe I can help them� J</p>
<p>the important thing about language is the ability to make a parallel structure serial</p>
<p>we already have representations, even if not a lexicon, so it�s not simply the ability to label things that helps elevate man above animal</p>
<p>does that mean that if we had parallel languages, they�d lose their power???</p>
<p>maybe big brains were waiting for language, in order to speed up the learning process enough to make it work in time</p>
<p>perhaps language uses prepositions as a means of mapping similar concepts between realms (see Lakoff)</p>
<p>the Jungian archetypes don�t need to be innate, because they�re all based on the sort of basic universal rules that you need in order for cultures not to fall apart</p>
<p>maybe some of the old foundational mechanisms from our animal past are just holding us back</p>
<p>we don�t know if a dog can see objects</p>
<p>you might be able to isolate a sub-domain of common sense</p>
<p>e.g. blocksworld, or non-social</p>
<p>he doesn�t think that there�s a critical mass of CS knowledge necessary, so much as a critical mass architecture (e.g. that knows what is and is not worthwhile learning - context)</p>
<p>Colossus � D F Jones</p>
<p>he�s saying that before you get too precious about how much computational power there is in the brain, bear in mind that you can�t remember much beyond a 7-digit phone number J</p>
<p>he reckons that possibly once you�ve made an architecture, it takes a different type of engineer to make it reliable � but perhaps that approach is a mistake</p>
<p>ungrounded � little brain with a simple world, small number of states � neurologists should look for this</p>
<p>he thinks that we don�t do 3D spatial reasoning, only 2D, except by tricks</p>
<p>are there psych experiments to undermine this???</p>
<p>blind people can develop an equally rich spatial conception (with different auditory dimensions)</p>
<p>what happens to deaf children who don�t learn a sign language?</p>
<p>perhaps �liking� isn�t something positive, so much as one part of your brain over-riding other impulses</p>
<p>if everybody agrees, it must be a contagious mental disease (e.g. grounding) � though rarely, it�s actually true</p>
<p>didn�t think that Spielberg�s AI had a single good idea</p>
<h2 id="excerpts-from-tem">Excerpts from tEM</h2>
<p><em>"...Psychologically we must keep all the theories in our heads, and every theoretical physicist who is any good knows six or seven different theoretical representations for exactly the same physics. He knows that they are all equivalent, and that nobody is ever going to be able to decide which one is right at that level, but he keeps them in his head, hoping that they will give him different ideas for guessing."</em><a href="http://web.media.mit.edu/~minsky/E1/#_edn7"><em>[7]</em></a></p>
<h2 id="questions">Questions</h2>
<p>see questions doc</p>


<br />
<br />
<br />
<hr />



        



        

<small>
    <h1>Belongs to these <a href="/tag">tags</a></h1>
    <ul>
        
        <li><a href="/tag/intelligence-mind.html">Intelligence, mind</a></li>
        
        <li><a href="/tag/neuroscience.html">Neuroscience</a></li>
        
        <li><a href="/tag/cognitive-load.html">Cognitive load</a></li>
        
        <li><a href="/tag/artificial-intelligence.html">Artificial Intelligence</a></li>
        
        <li><a href="/tag/philosophy.html">Philosophy</a></li>
        
    </ul>
</small>



        



        



    </div>
    <footer>
        <div class="bottom_nav">
            

            


<p>
    <i>
        Last updated: 2024-Oct-04
    </i>
</p>


        </div>
    </footer>
</body>

</html>