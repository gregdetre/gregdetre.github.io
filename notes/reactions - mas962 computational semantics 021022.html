<!DOCTYPE html>
<html lang="en">

<head>
    

    <title>

reactions - mas962 computational semantics 021022 -

Greg Detre
</title>
    <meta charset="utf-8" />
    <meta name="generator" content="gdwebgen" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <meta name="description" content="Greg Detre's personal website" />
    
    <link rel="stylesheet" href="/static/css/base.css">
    
<link rel="canonical" href="https://www.gregdetre.com/notes/reactions - mas962 computational semantics 021022">

</head>

<body>

    
    <div id="wide-img-header">
        
        <a href="/wide_img_header/IMG_5253.jpg">
            <img src="/wide_img_header/IMG_5253_sm.jpg" />
        </a>
        
    </div>
    

    
<nav aria-label="Breadcrumb">
    <ol class="breadcrumb">
        
        
        <li class="breadcrumb-item" title="Greg Detre">
            
            <a href="/">Greg Detre</a>
            
        </li>
        
        
        
        <li class="breadcrumb-item" title="Notes">
            
            <a href="/notes/">...</a>
            
        </li>
        
        
        
        <li class="breadcrumb-item" title="reactions - mas962 computational semantics 021022">
            
            <a href="/notes/reactions - mas962 computational semantics 021022">Reactions - Mas962 Computational Semantics 021022</a>
            
        </li>
        
        
    </ol>
</nav>


    
    <div class="nav_menu" <p>
        
        <a href="/about">About</a>
        
        <a href="/blog">Blog</a>
        
        </p>
    </div>
    

    <div id="main">
        

<h1>reactions - mas962 computational semantics 021022</h1>




<h1 id="reactions-mas962-brooks-and-smith">Reactions � MAS962, Brooks and Smith</h1>
<p>Greg Detre</p>
<p>Sunday, October 20, 2002</p>
<h2 id="review-brooks-intelligence-without-representation">Review � Brooks, �Intelligence without representation�</h2>
<p><em>�Human level intelligence is too complex and little understood to be correctly decomposed into the right sub-pieces at the moment, and that even if knew the sub-pieces we still wouldn�t know the right interfaces between them.�</em></p>
<p>Brooks� central point is that most of the hard work of intelligence relates to the business of survival, in being able to do things like perceive, move around and react rapidly (often in pretty simple, sensible ways). When we look at human abilities like reasoning, maths or language, there is a temptation to assume that these can be replicated without the embodied trappings that allow us to operate in the world.</p>
<p>However, the representations and processing which underly these abilities are firmly rooted in less glamorous tasks, and it�s only by building systems incrementally, and testing them in the full complexity of the real world that progress is likely to be made.</p>
<p><em>�With a simplified world, it is very easy to accidentally build a submodule of the system which happens to rely on some of those simplified properties.�</em></p>
<p>In abstracting to some simplified or purified version of a problem, we run the risk of abstracting away the means of solution.</p>
<p><em>�There is no clean division between perception (abstraction) and reasoning in the real world.�</em></p>
<p>This point is made most forcibly by exposing the (almost certainly wrong) assumption that the representations we have available to us through introspection are the same as those which we employ unconsciously on everyday tasks. This is a lesson that cognitive psychology experiments teach over and over again.</p>
<p>Brooks proposes an alternative architecture, which dispenses with central planning and representation, and devolves all the perceptual and effector responsibility to individual layers, each specialised for a particular activity (defined as �a pattern of interactions with the world�). Because each layer is also responsible for deciding when to act for itself, the system has a kind of �Pandemonium� feel. The hope is that such systems are robust (i.e. generally cope well with surprises), allow for a multiple, complex hierarchy of goals, and should hopefully be easier for people to understand and manage.</p>
<p>The parallels with evolution were instructive � in a sense, AI researchers and the blind forces of Darwinism are in a similar boat. We have to make a bit of a trade-off between the massively parallel experimental resources of mother nature and our human teleological intelligence, but in both cases, we are seeking to build adaptable, robust systems that occupy a niche/fulfil a purpose while trying to deal with the inevitable complexity as best we can. Although this analogy should only be taken so far, the relative evolutionary timescales are instructive.</p>
<p>I really enjoyed the paper, and found myself largely sympathetic to its arguments. However, there are various issues I felt that he dealt with unsatisfyingly, especially relating to scaling all the way up to human-level intelligence. He seems to believe that it�s possible, although the fact that his robots (at the time) involved tiny handfuls of activity layers (3, 6 and 14) might bely his confidence.</p>
<p>My concern is that without any self-organisation, the designers of the system are required to understand and plan each component and its interfaces by hand, which I don�t think can ever work. I appreciate that different levels emerge, such that we can ignore the details of a lower level (like the obstacle-avoidance level) and simply rely on it in the design of our higher levels (like the wander/explore levels), but I�m not sure that this is entirely desirable for at least one good reason. One of the benefits of a connectionist system is that its own processing is entirely open/transparent to other components in the system. This can be a disadvantage, but it does make it much easier to build multiple (subtly different) representations for different purposes, e.g. in the visual system. By employing a design paradigm that sets the componentry and interfaces in stone, I don�t see how such systems could be adaptive or learn, and I don�t think human designers would be able to manage interfacing of human-level complexity. From what I understand of current projects, Brooks is employing connectionist components where they�re most appropriate, but I don�t know to what extent the system architecture as a whole is able to flex.</p>
<p>There is one further fact to note: we do clearly have neural representations, whether topographic or more abstract, scattered throughout the brain. I think that Brooks might be able to argue that these aren�t representations so much as isomorphisms. By this I mean that isomorphisms between various modules� internal structure and the domain of their activity might arise as artifacts of their particular learning algorithm (e.g. topographic representations might emerge simply as the state which minimises mean wiring length). In contrast, a representation is something manipulable, a predictive internal model of the world on which the function from inputs to outputs is based. Brooks discusses the contrast between the interpretable structure of layers and (implicit) representations along different lines.</p>
<p><em>�We believe representations are not necessary and appear only in the eye or mind of the observer.�</em></p>
<p>Having said this, I think it would take considerable work to flesh out Brooks� ideas to account for how intelligent systems can consider counterfactuals and future possibilities in the absence of some immediate feedback loop with the world. I�m sure it could be done, but perhaps only at the expense of most of the cleanness and revolutionary-seeming force of his argument. </p>
<h2 id="review-cantwell-smith-origin-of-objects-ch-6-flex-and-slop">Review � Cantwell Smith, �Origin of objects�, ch 6, �Flex and slop�</h2>
<p>Smith is trying to outline a metaphysics which doesn�t assume the subject-object split, but explains it. Since terms like �perception� and �conception� already carry the assumption of a direct object that is perceived or conceived, he introduces a new unitary term, �registration�. To register is to:</p>
<p><em>�parse, make sense of as, find there to be, structure, take as being a certain way, carve the world into�</em>(pg 191)</p>
<p>To say that �the sailor in the crow�s nest registered the island� means that there really is an island, and that the sailor ended up in an �intentional relationship� to it. He doesn�t unpack the notion of an �intentional relationship� really until later, but we should understand it as implying some sort of (asymmetric) engagement between both registrar and that being registered, and that the content of the registrar�s stare �is the island itself, not an impression of the island�.</p>
<p>He then introduces the crucial notions of flex and slop. I�m still unsure whether he considers them to be two words for the same messiness and weak inter-connectedness, or whether they have subtly different connotations.</p>
<p>He considers a hypothetical gear world, where every single cog is in connected to everything else as part of a monolothic machine. If one cog is twisted, the entire structure moves together in lock-step, though each cog may move at a different speed. Effects are propagated immediately and deterministically. Such a world wholly lacks flex and slop.</p>
<p><em>�[Our] world is fundamentally characterised by an underlying flex or slop � a kind of slack or �play� that allows some bits to move about or adjust without much influencing, and without being much influenced by, other bits�</em></p>
<p>The �butterfly effect� is not a counter-example to this assertion, since for the most part, such minute disturbances don�t amplify in this way, and even when they do, their effects take time and tend to be chaotic.</p>
<p>Given this flexy, sloppy world, we can sharpen what interests us about causality. </p>
<p><em>�Because of the dissipative nature of the playing field, an enduring entity cannot, at any given moment, be affected by things that, at that same moment, are beyond what I will call effective reach�</em>.</p>
<p>More importantly:</p>
<p><em>�flex and slop underwrite the very notion of connection, disconnection and the limits of effective reach � otherwise, there�d probably be no warrant for saying the world had parts at all�</em></p>
<p>As soon as effective reach limits which parts of the physical world can immediately affect an agent, we can start to talk about strategies for dealing with those parts of the world which are beyond effective reach, but still matter because of �past connections, present interests, future possibilities�. The most basic of these is illustrated by the �super-sunflower�, which continues to move in the direction of the sun�s trajectory, even when the sun is occluded, to be ready for it when it pops back out. We can see that this is a much more valuable skill for a rabbit that has lost track of a coyote, but makes an educated guess as to where the coyote will reappear.</p>
<p><em>�An internal mechanism has to compensate for what can no longer be relied on to be effectively provided by the environment�,</em></p>
<p><em>��this shouldering of effective responsibility by the s-region, to compensate for the break in effective coupling � is no less than the origin of reasoning, representation and syntax�</em></p>
<p>Because intentionality is based on non-effective tracking, intentionality is not an <em>effective</em> phenomenon, and will not have an <em>effective</em> explanation. Neither will objects, although Smith withholds complete explanation of why this must be so until later. He does mention that:</p>
<p><em>�being an object</em> cannot be a physically effective property <em>, since there is no way in which a temporally extended object could have a physical effect distinct from that of a non-temporally-extended instantaneous time-slice of that object�</em></p>
<p>and also that:</p>
<p><em>�abstraction, essential to the notion of an object, is like semantic reach in being physically transcendent�</em></p>
<p>He finally considers how we might individuate the subject and object. By individuate, he means �what allows us to say of one object that it is one; or two that they are two�. He discusses this in terms of abstraction, which �requires separation, in order that the s-region not be buffeted by irrelevant details�, and �[deconvolving] the deixis�, which is the means by which the self gathers together as a stable unity as a �long-term integral or aggregate of <em>that which it must compensate for, in order to stabilise the rest of the world�</em>. This is the</p>
<p><em>�precursor to the later process of shifting the registration of the object from egocentric to allocentric coordinates. This helps it to begin the long and tough process of triangulating on the object, and washing out the contribution of everything else�.</em></p>


<br />
<br />
<br />
<hr />



        



        

<small>
    <h1>Belongs to these <a href="/tag">tags</a></h1>
    <ul>
        
        <li><a href="/tag/artificial-intelligence.html">Artificial Intelligence</a></li>
        
        <li><a href="/tag/intelligence-mind.html">Intelligence, mind</a></li>
        
        <li><a href="/tag/philosophy.html">Philosophy</a></li>
        
        <li><a href="/tag/robustness.html">Robustness</a></li>
        
    </ul>
</small>



        



        



    </div>
    <footer>
        <div class="bottom_nav">
            

            


<p>
    <i>
        Last updated: 2024-Oct-04
    </i>
</p>


        </div>
    </footer>
</body>

</html>